{
  "source": "mailing_list",
  "list": "bitcoin-dev",
  "fetched_at": "2026-01-15T23:13:43.728380+00:00",
  "date": "2025-05-28",
  "threads": [
    {
      "title": "Re: [bitcoindev] Against Allowing Quantum Recovery of Bitcoin",
      "message_count": 2,
      "participants": [
        "Michael Tidwell",
        "waxwing/ AdamISZ"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/84ae7e2c-eb71-44fa-b3da-27731802f47an@googlegroups.com",
          "title": "Re: [bitcoindev] Against Allowing Quantum Recovery of Bitcoin",
          "author": "waxwing/ AdamISZ <ekaggata@gmail@com>",
          "date": "Wed, 28 May 2025 14:15:32 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2149 bytes --]\n\nSorry looks like I forgot to crosspost this reply to list:\n\nHi Sjors, list:\n\n> I brought this up [0], but it was later pointed out to me that it doesn't \nwork\n \n\nOh yes, doh. That's most unfortunate. While this is getting silly, I can't \nhelp wondering what happens, in the presence of an ECDLP breaker, to a \nbotched version of taproot that requires script-path spending and doesn't \nallow key-path.\n\nIt's interesting, imagine: honest keyholder creates Q = P_N + H(P_N||S)G \nwhere P_N means NUMS internal key. ECDLP breaker can just find DL of Q but \nif we disallow key-path spend they have to open a hash commitment to a \ntweak as per usual taproot rules.\n\nSo they need: Q = P_2 +H(P_2||S_2)G now, they know the full private key x_N \n+ H(P_N||S) for Q (and they may or may not know S, or be able to guess it, \nto get all the variables in that expression), but it seems to not help them \ngiven the commitment to P_2 in the hash, requiring them to choose P_2 \nbefore the hash.\n\nThey could of course do it with P_N itself, if that were allowed, hence the \n\"disable NUMS\" might make sense, in this scenario. Can't say I'm 100% sure \nof myself here, but it looks like that works.\n\nEven if I'm right, it's not so interesting; we already are assuming that a \nquantum attacker can't break hashes, that's behind a lot of the discussion \nhere, so of course it would make sense if we broke taproot to require it \nonly to use hashes (script path only), then it might come back to the same \nsecurity situation (which of course, is not actual security, since keys are \nalways revealed in spending). Or maybe we should start to think of really, \nreally worst case scenarios: what if a new quantum algorithm actually does \nefficiently find SHA2 preimages? :)\n\nThanks, AdamISZ/waxwing\n\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receivi",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2062,
            "has_nack": false,
            "has_ack": true
          }
        },
        {
          "url": "https://gnusha.org/pi/bitcoindev/dbe7018c-149f-4ead-be39-fa368eca06f0n@googlegroups.com",
          "title": "Re: [bitcoindev] Against Allowing Quantum Recovery of Bitcoin",
          "author": "Michael Tidwell <michael@tidwell@io>",
          "date": "Wed, 30 Apr 2025 08:40:41 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 37995 bytes --]\n\nI'm late, but want to share thoughts. I gathered from this thread the way \nmore pertinent and prerequisite idea is to formulate some idea for pqc safe \nschemes, before the idea of burning/freezing/other becomes actionable.\nOriginally I thought Matt's idea of a secure leaf that could be enabled to \nbe the only spend path seemed clever, but after thinking about it more, I \nthink it would be better to cleanly have a new address/ taproot version. \n\n1. We get public data to know how many coins are using the post-quantum \nsecured scheme. Allow better informed decisions on adoptions, planning, and \nunderstanding sentiment on the perceived threat.\n2. would have clean separation for users to know whether or not their \naddress is PQC secured.\n3. for people not worried about it, they wouldn't feel arm-bar'd into \nhaving longer descriptors and an unnecessary leaf.\n4. *unsure here*, but possible that library and wallet developers could \ntreat this with cleaner separation uX, UI and not worry about (legacy-tr) \nvs (pqc-tr) descriptions and script code. (To help users differentiate)\n5. We wouldn't need to worry about some roll out period or flag day where \nthe leafs become necessary or an enabled spend path.\n\nGiven that pqc transactions will likely require additional space and \ncomputational resources, we should be cautious about heavily incentivizing \nuncertain approaches (i.e. it may be advantageous to decide on something \nbefore having certainty about the optimal approach). Significant fee \ndiscounts may be needed once there's high confidence on the \napproach/method. However, enhanced security itself inherently serves as \npart of the explicit incentive, and maybe should be part of the incentive \ncalculation.\n\nOn Monday, April 7, 2025 at 6:34:54 AM UTC-4 Nadav Ivgi wrote:\n\n> One possible alternative to freezing/burning the coins entirely is letting \n> quantum attackers keep some small percent as a reward, but force th",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2062,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "Re: [bitcoindev] Post-Quantum commit / reveal Fawkescoin variant as a soft fork",
      "message_count": 1,
      "participants": [
        "Nagaev Boris"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAFC_Vt6gqV-8aoTKt2it1p9LAnvaADueHnC1cM6LQojZf6fjCw@mail.gmail.com",
          "title": "Re: [bitcoindev] Post-Quantum commit / reveal Fawkescoin variant as a soft fork",
          "author": "Nagaev Boris <bnagaev@gmail@com>",
          "date": "Wed, 28 May 2025 17:24:52 -0300",
          "body": "Hi Tadge,\n\nThanks for writing this up! The proposal is very thoughtful, and it's\ngreat to see concrete work on post-quantum commit/reveal schemes.\n\nI've been exploring a related approach based on a similar\ncommit/reveal idea. In my scheme, a user creates a QR output that\ncommits to a hash of a pubkey inside a Taproot leaf. This commitment\nis hidden until revealed at spend time. Later, when the user wants to\nspend a legacy EC output, they must spend this QR output in the same\ntransaction, and it must be at least X blocks old.\n\nhttps://groups.google.com/g/bitcoindev/c/jr1QO95k6Uc/m/lsRHgIq_AAAJ\n\nThis approach has a few potential advantages:\n\n1. No need for nodes to track a new commitment store\n\nBecause the commitment remains hidden in a Tapleaf until the spend,\nobservers (including attackers) don't see it, and nodes don't need to\nstore or validate any external commitment set. The only requirement is\nthat the QR output must be old enough, and Bitcoin Core already tracks\ncoin age, which is needed to validate existing consensus rules.\n\n2. Commitment can be made before the transaction is known\n\nSince the commitment doesn't include a txid, the user can precommit to\nthe pubkey hash far in advance, before knowing the details of the\neventual transaction. This allows greater flexibility: you can delay\nchoosing outputs, fee rates, etc., until spend time. Only knowledge of\nthe EC pubkey needs to be proven when creating the QR output.\n\n3. More efficient use of block space\n\nMultiple EC coins can be spent together with a single QR output,\nholding EC pubkey commitments in Taproot leaves. If EC coins share the\nsame EC pubkey (e.g., come from the same address), they can reuse the\nsame commitment.\n\nWould love to hear your thoughts on this variant. I think this one\nmight be a simpler, lower-overhead option for protecting EC outputs\npost-QC.\n\nBest,\nBoris\n\nOn Wed, May 28, 2025 at 2:28 PM Tadge Dryja <rx@awsomnet•org> wrote:\n>\n> One of the tricky things about securing Bitcoin against quant",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Proposal to solve the spam war: configurable data blob relay policy",
      "message_count": 1,
      "participants": [
        "Greg Sanders"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2a40a751-d0d1-4dc8-9dd5-67b7652ed8b8n@googlegroups.com",
          "title": "Re: [bitcoindev] Proposal to solve the spam war: configurable data blob relay policy",
          "author": "Greg Sanders <gsanders87@gmail@com>",
          "date": "Wed, 28 May 2025 06:16:20 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 5621 bytes --]\n\n> If we need two networks, one for stuff like what Citrea is doing and the \nother for finance with a technological fence around it, I'm all for it. Has \nCitrea heard of nostr?\n\nCitrea, like Lightning, is relying on Bitcoin's proof of publication to \nultimately move bitcoin. Moving the data elsewhere would change the L2's \nsecurity model drastically.\n\nGreg\n\nOn Tuesday, May 27, 2025 at 7:15:06 PM UTC-4 Dave Scotese wrote:\n\n> As far as I can tell, the resource being wasted is the bandwidth of those \n> who are (currently kind enough to be) maintaining the network. They are \n> giving away that bandwidth for free, and I think they ought to be \n> compensated for it, but until enough of it is \"wasted\", the demand for such \n> compensation will remain too low for that problem to be solved. Everyone \n> who broadcasts a transaction offers the miners the chance to earn a fee, \n> and those miners seem to me to be the only ones with the right incentive to \n> solve the problem (because if it gets bad enough, they don't get valuable \n> bitcoin transactions to mine quickly enough). I believe that in time, \n> miners will develop a way of privately compensating transaction relayers \n> for this reason. I would very much enjoy seeing the propagation of data \n> grow as a market on its own in which nerds like me could participate simply \n> by leaving their internet-connected machines on all the time and \n> maintaining the software that runs it.\n>\n> Protecting Bitcoin from becoming that market and perhaps crowding out its \n> financial utility might not be such a good idea, but distributing Bitcoin \n> technology has vastly lowered the cost of financial transactions for \n> everyone. If we need two networks, one for stuff like what Citrea is doing \n> and the other for finance with a technological fence around it, I'm all for \n> it. Has Citrea heard of nostr?\n>\n> Dave Scotese\n>\n> On Tue, May 27, 2025 at 10:18 AM Jonathan Voss <k98...@",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2085,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Sybil resistance in different coinjoin implementations",
      "message_count": 1,
      "participants": [
        "/dev /fd0"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/8fb3deaf-417c-4ec9-9d23-424c4926905an@googlegroups.com",
          "title": "[bitcoindev] Sybil resistance in different coinjoin implementations",
          "author": "/dev /fd0 <alicexbtong@gmail@com>",
          "date": "Tue, 27 May 2025 07:29:29 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 943 bytes --]\n\nHi Bitcoin Developers,\n\nI have written a post comparing the sybil resistance of joinmarket, joinstr \nand wabisabi. I did not include whirlpool in this post because its not used \nanymore. Although it won't be any different from wabisabi.\n\nIts not a long post but written after doing a lot of research. The results \nshow that joinmarket has good enough sybil resistance. However, joinstr \nprovides better solution.\n\nFeel free to share your feedback.\n\nLink: \nhttps://uncensoredtech.substack.com/p/sybil-resistance-in-coinjoin-implementations\n\n/dev/fd0\nfloppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/8fb3deaf-417c-4ec9-9d23-424c4926905an%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 1418 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1130,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Censorship Resistant Transaction Relay - Taking out the garbage(man)",
      "message_count": 1,
      "participants": [
        "John Carvalho"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAHTn92zkmfw2KwZCTRyGhnYPASWBUoLaxV65ASYpPeBUpX1SWw@mail.gmail.com",
          "title": "Re: [bitcoindev] Censorship Resistant Transaction Relay - Taking out the garbage(man)",
          "author": "John Carvalho <john@synonym@to>",
          "date": "Tue, 27 May 2025 12:37:36 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 15273 bytes --]\n\nI noticed your mention of a missing pubkey identity capability.\n\nA censorship-resistant key-based discovery mechanism is available, PKDNS,\nat github.com/pubky/pkarr (also /mainline and /pkdns), which essentially\nprovides public-key domains controlled by the keyholder.\n\nNo blockchains, just the largest, oldest, p2p network on earth, Mainline\nDHT.\n\nThis could be used to dynamically provide or update any endpoint, associate\nor disassociate keys, or create revokable account-based sessions, etc.\n\nThese links may address peoples' likely counterarguments:\n-\nhttps://medium.com/pubky/public-key-domains-censorship-resistance-explained-33d0333e6123\n- https://medium.com/pubky/mainline-dht-censorship-explained-b62763db39cb\n\nMaybe this helps you, or others looking for such primitives!\n\n--\nJohn Carvalho\nCEO, Synonym.to <http://synonym.to/>\n\n\n\nOn Tue, May 27, 2025 at 12:23 PM Peter Todd <pete@petertodd•org> wrote:\n\n> Recently proponents of transaction \"filtering\" have started sybil attacking\n> Libre Relay nodes by running nodes with their \"garbageman\" fork¹. This fork\n> falsely advertise the NODE_LIBRE_RELAY service bit, silently discards\n> transactions that would be relayed by real Libre Relay nodes, and does not\n> provide any. Additionally, they have made clear that they intend to ramp up\n> this sybil attack with the aim of preventing people people from getting\n> transactions that they disagree with mined:\n>\n>         The costs will increase even more once Libre Relay’s DoS attacks on\n>         bitcoin are countered by enough defensive nodes.\n>         -Chris Guida\n> https://delvingbitcoin.org/t/addressing-community-concerns-and-objections-regarding-my-recent-proposal-to-relax-bitcoin-cores-standardness-limits-on-op-return-outputs/1697/4\n>\n> They have also put effort into making the attack more than a simple proof\n> of\n> concept, e.g. by adding code that attempts to make it more difficult to\n> detect\n> attacking nodes, b",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 2,
            "text_length": 2086,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "[bitcoindev] Draft BIP: Well-Known Bitcoin Identity Endpoint",
      "message_count": 1,
      "participants": [
        "Aviv Bar-el"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAEbZFSsA49mnsVia7L-0k9S=oa93nCN4KudHdK8ZnSbboenohw@mail.gmail.com",
          "title": "[bitcoindev] Draft BIP: Well-Known Bitcoin Identity Endpoint",
          "author": "Aviv Bar-el <aviv57@gmail@com>",
          "date": "Mon, 26 May 2025 15:50:40 +0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1082 bytes --]\n\nHi all,\n\nI'd like to propose a new BIP titled \"Well-Known Bitcoin Identity Endpoint.\"\nThe goal is to improve the user experience for sending on-chain Bitcoin\npayments by allowing wallets to resolve a Lightning Address into associated\non-chain addresses and additional metadata.\n\nThe idea is to define a simple, HTTPS-based standard for retrieving payment\nand contact information via a .well-known endpoint,\ngeneralizing the approach used by Lightning Address to support more payment\ntypes and identity metadata.\n\nYou can find the draft BIP here:\nhttps://github.com/aviv57/paysats/blob/main/bip/BIPXXX.MD\n\nI’d appreciate any feedback or suggestions.\n\nThanks,\nAvivB\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAEbZFSsA49mnsVia7L-0k9S%3Doa93nCN4KudHdK8ZnSbboenohw%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1502 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1233,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Hashed keys are actually fully quantum secure",
      "message_count": 1,
      "participants": [
        "Nagaev Boris"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAFC_Vt4wjLV_iAHYDMcAJYP=PRo=jNWQzmrUfJUK2_GXTiPnjA@mail.gmail.com",
          "title": "Re: [bitcoindev] Hashed keys are actually fully quantum secure",
          "author": "Nagaev Boris <bnagaev@gmail@com>",
          "date": "Mon, 26 May 2025 07:03:01 -0300",
          "body": "Hey Conduition,\n\nIsn't this a bit of a chicken-and-egg issue? The EC signature signs\nthe second transaction, which depends on the QR output's txid, which\nin turn depends on the precommitted EC signature. One way to break\nthis circular dependency is to use the SIGHASH ANYONECANPAY modifier\nto exclude the QR output from the EC signature scope. Or an\ninscription can be used to commit to the EC signature without\naffecting the txid of the first transaction.\n\nThat said, I've been thinking about an alternative approach that might\nalso be more convenient in practice.\n\nWhat if we commit to the SHA256 of the EC public key instead of the EC\nsignature? If this hash is included in a QR output at least X blocks\nin advance, it offers the same security under the assumption that a\nquantum attacker can recover the private key from the public key.\n\nHowever, there's a problem: an attacker can observe the creation of QR\noutputs and create their own outputs committing to the same\nSHA256(pubkey) in advance. To prevent this, the commitment to the EC\npubkey hash must be hidden from observers. One way to achieve this is\nby embedding SHA256(pubkey) in a Taproot leaf. Since Taproot leaves\nare not visible on-chain until revealed, the attacker can't learn\nwhich pubkeys are being committed to. Once the commitment is revealed\nat spend time, it's too late for the attacker to make a QR output and\nwait out the delay. Multiple EC inputs of a transaction can reuse the\nsame QR input of the transaction.\n\nThe pubkey (and its SHA256 hash) is only revealed when spending an EC\noutput. A new consensus rule would require that such a spend be\naccompanied by a QR output, with a tapleaf committing to the SHA256 of\nthe same EC pubkey, created at least X blocks earlier and spent in the\nsame transaction. An attacker seeing the EC pubkey in the mempool\nwould have to create their own QR output committing to the same hash,\nmine it, wait X blocks, and then attempt an RBF — but by then, the\nlegitimate transaction would l",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2063,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Relax OP_RETURN standardness restrictions",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aCH8AdZeBAc0UVfT@erisian.com.au",
          "title": "Re: [bitcoindev] Relax OP_RETURN standardness restrictions",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Mon, 12 May 2025 23:47:45 +1000",
          "body": "On Thu, Apr 17, 2025 at 06:52:34PM +0000, 'Antoine Poinsot' via Bitcoin Development Mailing List wrote:\n> Bitcoin Core will by default only relay and mine transactions with at most a single OP_RETURN output, with a scriptPubKey no larger than 83 bytes. This standardness rule falls into the third category: it aims to mildly deter data storage while still allowing a less harmful alternative than using non-provably-unspendable outputs.\n> \n> Developers are now designing constructions that work around these limitations. An example is Clementine, the recently-announced Citrea bridge, which uses unspendable Taproot outputs to store data in its \"WatchtowerChallenge\" transaction due to the standardness restrictions on the size of OP_RETURNs[^0].\n\nThe reason for limiting OP_RETURNs to 80 bytes of data is to encourage\ndevelopers to store hashes on the chain, rather than the actual\ndata. Why store 1GB when you can commit to it with a 32B hash, and save\n99.9999968% in fees? In all this debate I haven't seen an analysis of\nother alternatives Citrea/Clementine might use, rather than storing 144\nbytes of data on chain.\n\nAs I understand it, the context in which they're using the data is the\nfollowing protocol:\n\n * we have three known groups: Operators, Watchtowers and Signers\n * we also have: Users and Challengers (who can be anyone)\n * we assume that there is at least 1 honest Operator, 1 honest Watchtower,\n   1 honest Signer, and 1 honest Challenger, and >50% honest hashrate\n\nWhen things go wrong, and one of the Operators tries to cheat, one way\nthey can do so is by publishing a claim that they posted a transaction\nin a Bitcoin block that's not actually in the Bitcoin block chain. At\nthat point, an honest Watchtower observers the claim, and produces a\nGroth16 proof that he has a more-work chain that does not contain the\nblock claimed by the Operator.\n\n * but what if the Operator was honest and the Watchtower was trying to cheat?\n\n * in that case, the claimed Groth16 proof can be e",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: Relax OP_RETURN standardness restrictions",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/qps_M7VTLROH7U1v1n_5snfjf-H-Gl-BX-V9qc1JSzzyqfsRoPrbaCzQAQFa1pU4w0cfXZHVnUta6Z7UryG1hUhtpcGXw1ZHiHOfl3HR2jo=@protonmail.com",
          "title": "[bitcoindev] Re: Relax OP_RETURN standardness restrictions",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 14 May 2025 15:54:55 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2948 bytes --]\n\nHi,\n\nThis proposal was heavily mediatized, and severe mischaracterizations of the change being proposed led to genuine concerns among the community. A better communication from my part could have avoided unnecessary worries among bitcoiners and a lot of wasted time to everybody.\n\nIn an attempt to right this wrong, i have collected objections community members have raised across the board (on Github, the Bitcoin development mailing list, X, podcasts, at conferences, ..) to address them in a single post.\n\nI just posted to Delving Bitcoin addressing all concerns and objections i could get my hands on: https://delvingbitcoin.org/t/addressing-community-concerns-and-objections-regarding-my-recent-proposal-to-relax-bitcoin-cores-standardness-limits-on-op-return-outputs/1697. These are actual objections and concerns raised by community members, taken literally with little or no reformulation to address the precise statement.\n\nAntoine Poinsot\nOn Thursday, April 17th, 2025 at 2:52 PM, Antoine Poinsot <darosior@protonmail•com> wrote:\n\n> Hi,\n>\n> Standardness rules exist for 3 mains reasons: mitigate DoS vectors, provide upgrade hooks, or as a nudge to deter some usages.\n>\n> Bitcoin Core will by default only relay and mine transactions with at most a single OP_RETURN output, with a scriptPubKey no larger than 83 bytes. This standardness rule falls into the third category: it aims to mildly deter data storage while still allowing a less harmful alternative than using non-provably-unspendable outputs.\n>\n> Developers are now designing constructions that work around these limitations. An example is Clementine, the recently-announced Citrea bridge, which uses unspendable Taproot outputs to store data in its \"WatchtowerChallenge\" transaction due to the standardness restrictions on the size of OP_RETURNs[^0]. Meanwhile, we have witnessed in recent years that the nudge is ineffective to deter storing data onchain.\n>\n> Since the ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position",
      "message_count": 1,
      "participants": [
        "Bob Burnett"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/BY5PR03MB51712A578A9098824DED13FE969EA@BY5PR03MB5171.namprd03.prod.outlook.com",
          "title": "Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position",
          "author": "Bob Burnett <bob.burnett@barefootmining@com>",
          "date": "Wed, 21 May 2025 18:12:52 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4268 bytes --]\n\nAnd yes, I understand how demand for such services makes sense, and I do not fault you for pursuing them. But they are a threat, and I think the Bitcoin ecosystem should think hard about how to avoid their emergence\n\nI appreciate your response/interaction/opinion.  I do believe you come to your position from your belief on what is in the best interests of Bitcoin, and I respect that.  I realize that you don’t know me, and I can only say that my position is also established with the same intentions.  With that said, I don’t think these types of services are a threat at all.  I think they are essential to a healthy mining network where miners can have some control over a portion of their future revenue streams, especially in the greatly reduced subsidy era we are about to enter.  And, I think the lack of a futures/forward market for blockspace is a major inhibitor to adoption and usage.  Its hard to build a business where access to block space is a necessity without any visibility to the future.  I believe this can be done in a manner that provides openness and transparency, and it would also give us for the first time visibility to future demand and pricing and I think that will be valuable to the enter ecosystem.   Again, thanks for the reply.\n\nFrom: Pieter Wuille <bitcoin-dev@wuille•net>\nDate: Wednesday, May 21, 2025 at 1:52 PM\nTo: Bob Burnett <bob.burnett@barefootmining•com>\nCc: Sjors Provoost <sjors@sprovoost•nl>, Bitcoin Development Mailing List <bitcoindev@googlegroups.com>\nSubject: Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position\nYou don't often get email from bitcoin-dev@wuille•net. Learn why this is important<https://aka.ms/LearnAboutSenderIdentification>\nHi Bob,\n\nOn Wednesday, May 21st, 2025 at 1:24 PM, Bob Burnett <bob.burnett@barefootmining•com> wrote:\n\nNone of my comments insinuate that deals would not be public or that all users and all miners would not have access to ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2076,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Removing OP_Return restrictions: Devil's Advocate Position",
      "message_count": 1,
      "participants": [
        "Bob Burnett"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/BY5PR03MB5171FCC38022BF80272729FD969EA@BY5PR03MB5171.namprd03.prod.outlook.com",
          "title": "Re: [bitcoindev] Re: Removing OP_Return restrictions: Devil's Advocate Position",
          "author": "Bob Burnett <bob.burnett@barefootmining@com>",
          "date": "Wed, 21 May 2025 02:10:13 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 13990 bytes --]\n\nFor those who don’t know me, I run a mining company called Barefoot Mining– not the biggest mining company but not the smallest either.  Whether I would be considered major or not can be judged by others.\n\nThat said, I suggest being very careful about projecting the current behavior of major miners as the norm or representative of the future.  We are extremely early in the development of the mining industry and there is a high likelihood that over the next few years that there will a dramatic change in the list of major miners – and there very well may be changes in the philosophies and priorities of these miners as well.\n\nI spent most of career in the personal computer industry going back to ’86 (most notably as the CTO of Gateway) and I learned many things from my experience.  One important thing was that the pace with which companies could rise to or fall from prominence was jaw-dropping.  Assuming that “major miners” was meant to mean a group that largely is comprised of pubcos, none of the major players in the mining industry have been doing it for long - with most going public very recently (’22 and ’23).   They but pups as companies and we’ve already seen a huge flameout or two.  The next three to five years will likely result in a few more flameouts and some large new entrants that may approach mining from a completely different perspective.  A second learning I will share from my PC development days was that predicting usages and user behavior is next to impossible.  The safest and most accommodating path is to give as much user optionality/configurability as possible.  My high-level recommendation is to work on paths that give users more choice not less.  This is applies to OP_RETURN but, even more importantly, I think it is the best design direction in general.\n\nTo offer what may be a new lens in which to view miners, I’ll share a bit of my philosophy and vision for my company.  I view Barefoot a",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Weak blocks give an advantage to large miners",
      "message_count": 1,
      "participants": [
        "\"James O'Beirne\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPfvXf+2wkB6MyN6Bogr8c6G3uZq255Ec90qC4y5WxuEGoCPrg@mail.gmail.com",
          "title": "Re: [bitcoindev] Weak blocks give an advantage to large miners",
          "author": "\"James O'Beirne\" <james.obeirne@gmail@com>",
          "date": "Wed, 7 May 2025 20:42:51 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3161 bytes --]\n\nThis analysis excludes two important points:\n\n1. If a small miner has a mempool that is marginally closer to a large\nminer's, they will connect blocks found by that miner more quickly, making\ntheir own mining operation more efficient.\n\n2. A small miner benefits from becoming aware of (potentially large,\nnon-standard, or directly submitted) transactions because they may want to\nmake use of it in their own block templates for more revenue.\n\nBandwidth is rarely a limiting factor for template creators (as there are\nmany more expensive pieces of hardware required to have a competitive\nmining operation), and so a miner may very reasonably decide that it's\nworth trading some bandwidth (in the form of received weak blocks) for the\nprospect of juicing their fee revenue and minimizing tip connection time.\n\n\nOn Mon, May 5, 2025 at 11:36 PM Peter Todd <pete@petertodd•org> wrote:\n\n> On Mon, May 05, 2025 at 07:18:57PM +1000, Anthony Towns wrote:\n> > I meant to mention this last email, but had forgotten where to find\n> > the link. Personally, I think Greg's \"relay extra transactions via weak\n> > blocks\" idea [0] from a year ago is an approach that should be considered\n> > here. The TLDR is that if there are miners out there with different\n> > relay policies than your node that are accepting transactions you'll\n> > reject (eg, lower fee, new tx versions, more complicated dependencies,\n> > ...) then once they find a relatively high PoW share, have the network\n> > relay that as a weak compact block, with full round-trips to gather\n> > any transactions that weren't in your mempool and add those txs to your\n> > extra pool to help with block reconstruction in the near future.\n> >\n> > [0] https://delvingbitcoin.org/t/second-look-at-weak-blocks/805/1\n>\n> Weak blocks give an advantage to large miners. Small miners, who rarely\n> find blocks, are also going to rarely find weak blocks, making the\n> feature mostly useless for them in t",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2063,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] BIP39 Extension for Manual Seed Phrase Creation",
      "message_count": 2,
      "participants": [
        "nerdyrugbyguy",
        "Eric Kvam"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/4c376336-1fe3-4b1c-b13b-8dcc2075e758n@googlegroups.com",
          "title": "Re: [bitcoindev] BIP39 Extension for Manual Seed Phrase Creation",
          "author": "nerdyrugbyguy <nerdyrugbyguy@gmail@com>",
          "date": "Sun, 25 May 2025 07:26:52 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 6495 bytes --]\n\nGreetings Pithosian,\n\nThank you (and everyone) for taking time to consider my suggestions.\n\nI flipped coins to create my seed phrase ten years ago.  I founded a \nbitcoin club, created printed guides, and taught the procedure to others.  \nEven out of a group of people with engineering degrees, it was too much.  \nMany people have limited math ability and most will never learn binary math \nor checksums.  Unfortunately bitcoin \"self custody\" is typically based on \ntrusting a black box.  The question is really whether bitcoin is for elites \nor plebs.\n\nThe UEFI application you're suggesting sounds like it might be similar to \nother existing tools that receive entropy input and output a seed phrase or \nlast word.  What format should be used for the entropy input? Typically hex \nor binary is used because we lack a standard format (encoding entropy with \nwords would be less error prone).  To be trustless and do what you suggest, \nit seems users would have to record their entropy in a non-standard format, \nobtain two independent tools, perform a non-standard import of their \nentropy into the first tool, record the seed phrase output, perform a \nnon-standard import of their entropy into the second tool, then confirm \nthat the output of the second tool matches. While not requiring the user to \nknow binary math, this is too much for most users and is error prone.\n\nI agree that the spec doesn't need to change, it's not broken and is well \nsuited for its intended purpose.  I'm proposing an extension.\n\nHere are the current options I'm aware of for seed generation:\n*#1* Use a \"white box\" tool (only an option for devs that can verify source \nand build their own tools)\n*#2* Trust a \"black box\" tool\n*#3* Non-standard entropy import into two independent \"black box\" tools and \ncross-check results\n*#4* Use binary math to determine initial words and most significant bits \nof last word.  Obtain least significant bits of last word ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2065,
            "has_nack": false,
            "has_ack": true
          }
        },
        {
          "url": "https://gnusha.org/pi/bitcoindev/CADXQin4VbtvyWDGYLJB0HyJ2+Eai-01CKt6J6UzXM9qtdGJbuw@mail.gmail.com",
          "title": "Re: [bitcoindev] BIP39 Extension for Manual Seed Phrase Creation",
          "author": "Eric Kvam <nerdyrugbyguy@gmail@com>",
          "date": "Sat, 24 May 2025 06:33:35 -0600",
          "body": "[-- Attachment #1: Type: text/plain, Size: 8132 bytes --]\n\nI dug up some past arguments regarding the BIP39 checksum.  Hopefully my\nproposal to import manually generated entropy with a 16 word seed phrase\navoids controversy because it doesn't conflict with the existing\n12/15/18/21/24 word seed phrase formats that are meant for transcribing\ncomputer generated entropy.\n\n   -\n   https://www.reddit.com/r/TREZOR/comments/1d47lxg/bip39_checksum_is_a_misfeature_trezor_should/\n   -\n   https://www.reddit.com/r/Bitcoin/comments/k761mf/fck_the_mnemonic_sentence_checksum/\n   -\n   https://bitcoin.stackexchange.com/questions/100376/should-the-bip-39-mnemonic-sentence-checksum-be-eliminated-from-the-standard-do\n   -\n   https://www.reddit.com/r/Bitcoin/comments/wh0s11/bip39_whats_the_benefit_of_the_checksum_word/\n\n\nUsing BIP39 to import manually generated entropy into a computer is a\nwork-around that has become a de-facto standard.  Some others, like me,\nhave found that the checksum does more harm than good when importing\nmanually generated entropy.  I can see that the checksum is quite helpful\nwhen transcribing seed phrases between two computing devices.  In lieu of a\nchecksum, users transcribing their 16 word phrase could: select their input\nfrom the full 2048 word list, select their input from 256 words but do it\ntwice, check the xpub derived from their seed phrase input.  Initial\nconfirmation of the xpub is critical to ensure that a compromised computing\ndevice can not cause users to send funds to an address they don't control.\nUsers might store the 16 word phrase, or discard it once they have\nconfirmed their xpub in favor of a format that is better for transcription\n(12 word phrase or seedQR).\n\nWhen I am onboarding no-coiners, getting them to create their seed phrase\nhas been a stumbling block.  Any friction during onboarding reduces the\nconversion rate.  Most people will not bother to learn what a hash is but\nalready understand randomness from games like poker and understand ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2065,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] jpeg resistance of various post-quantum signature schemes",
      "message_count": 1,
      "participants": [
        "\"'Bas Westerbaan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAMjbhoU=PCUwbhWFbqCbOdZc+ybmREJmmt1K1TuHrCTncKH6VA@mail.gmail.com",
          "title": "[bitcoindev] jpeg resistance of various post-quantum signature schemes",
          "author": "\"'Bas Westerbaan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 21 May 2025 12:32:33 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5422 bytes --]\n\nHi all,\n\nMy colleague Ethan asked me the fun question which post-quantum signature\nschemes have the following security property, which he called jpeg\nresistance.\n\nAttacker wins if for a (partially specified) signature and full message,\nthey can find a completed signature and public key, such that the completed\nsignature verifies under the public key.\n\nA naive hash-based signature is not jpeg resistant. Schoolbook Winternitz\none-time signatures, forest-of-trees few-time signatures, and Merkle trees\nall validate signatures (/authentication paths) by recomputing the public\nkey (/Merkle tree root) from the signature and the message, and checking\nwhether the recomputed public key matches the actual public key. That means\nwe can pick anything for the signature, and just set the public key to the\nrecomputed public key.\n\nThe situation is more subtle for actual standardized hash-based signatures.\nRFC 8391 XMSS doesn’t sign the message itself, but first hashes in (among\nothers) the public key. Basically the best we can do for XMSS (except for\nsetting the signature randomizer) is to guess the public key. Thus it’s\npretty much jpeg resistant.\n\nThe situation is different again for RFC 8391 XMSSMT. XMSSMT is basically a\ncertificate chain of XMSS signatures. An XMSSMT public key is an XMSS\npublic key. An XMSSMT signature is a chain of XMSS signatures: the XMSSMT\npublic key signs another XMSS public key; which signs another public XMSS\npublic key; …; which signs the message. Again the top XMSSMT public key is\nhashed into the message signed, but that only binds the first XMSS\nsignature. We can’t mess with the first signature, but the other signatures\nwe can choose freely, as those roots are not bound. Thus XMSSMT with two\nsubtrees is only half jpeg resistant and it gets worse with more subtrees.\n\nSimilarly SLH-DSA (FIPS 205, née SPHINCS+) is a certificate chain of (a\nvariant of) XMSS signing another XMSS public key, which si",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: jpeg resistance of various post-quantum signature schemes",
      "message_count": 1,
      "participants": [
        "\"'Bas Westerbaan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/e812604c-94a5-4f5f-87e8-71d178963d62n@googlegroups.com",
          "title": "[bitcoindev] Re: jpeg resistance of various post-quantum signature schemes",
          "author": "\"'Bas Westerbaan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 22 May 2025 05:57:33 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 8985 bytes --]\n\n\n\nOn Wednesday, May 21, 2025 at 10:58:00 PM UTC+2 Hunter Beast wrote:\n\nThank you for this! It's definitely informing how we approach development \nof BIP-360. SLH-DSA is concering, in that 7/8 arbitrary data would make it \nabout on par with the de facto witness discount. I don't want to sacrifice \nSLH-DSA because it's favored due to hash-based signatures having more \nconfidence due to not introducing as many novel security assumptions as are \nintroduced with lattice cryptography.\n\n\nAt present, lattices are the only viable approach to post-quantum key \nagreement in TLS. If come Q-day they're broken, then it's not just Bitcoin \nthat's in big trouble. If you do want the certainty of hashes, you might \nwant to consider XMSS: that's JPEG resistant. With parameters n=16, h=20, \nd=1, w=16 it has 32 byte public key and 880 byte signature can sign a \nmillion messages, and only requires 3,000 hashes for verification [1] \n(which can actually be reduced threefold.) The big downside is that if you \nuse the same OTS leaf twice, probably anyone can forge another signature on \nthat leaf. In this case you might make this mistake harder by keeping track \nof the last leaf that was used for each public key. If you see a public key \nsign using the same leaf a second time, you simply ignore the second \nsignature. This helps against an oopsie that's at least a few hours apart, \nbut not if you're using the same leaf twice in short succession.\n \n\nAnother concern regarding SLH-DSA might be its performance, it's an order \nof magnitude more costly to run than FALCON, which itself is an order of \nmagnitude more costly to run than secp256k1 Schnorr...\n\n\nI assume you're talking about signature size? Falcon-512 requires fewer \ncycles to verify than secp256k1. SLH-DSA's verification is a bit slower. \nThere is some flexibility: SLH-DSA today assumes that a signer will make \n2^64 signatures. If you drop that to say one million, then you can ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2075,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Unbreaking testnet4",
      "message_count": 1,
      "participants": [
        "pithosian"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/20250428114858.46B477C1126@smtp.postman.i2p",
          "title": "Re: [bitcoindev] Unbreaking testnet4",
          "author": "pithosian <pithosian@i2pmail@org>",
          "date": "Mon, 28 Apr 2025 11:48:58 +0000 (UTC)",
          "body": "On Sun, 27 Apr 2025 22:54:54 +0000 (UTC)\nJameson Lopp <jameson.lopp@gmail•com> wrote:\n> I'd suggest simply disabling the halving logic and making it a\n> perpetual 50 TBTC issuance. At that rate, it would still take ~8\n> years or so to surpass the 21M limit and I'd think that testnets\n> should be reset more frequently than that.\n\nOn Mon, 28 Apr 2025 11:06:55 +0000 (UTC)\nJameson Lopp <jameson.lopp@gmail•com> wrote:\n> Encoding an \"end of life date\" into testnets is actually an\n> interesting idea worth discussing. As far as I'm aware it's never\n> been done before on any network.\nWhat about having the halving act as a reset? Eg: don't reduce the\nmining reward AND disallow spends of UTXOs from before the last halving.\n\n> On Mon, Apr 28, 2025 at 2:11 AM Saint Wenhao <saintwenhao@gmail•com>\n> wrote:\n> \n> > > Demurrage might be asking a bit much in terms of deviation.\n> >\n> > If that's the case, then why signing all blocks in signet is not\n> > \"too much\"?\n> >\n> \n> Because signet isn't testnet? It gives up permissionless block\n> creation in return for predictability.\n> \n> \n> > Or why unlimited supply is not \"too much\"?\n> >\n> \n> It might be, but it might not be, given that the point of testnet is\n> for coins to be free for developers to acquire and use without fear of\n> financial loss. Thus scarcity isn't really an inviolable property of\n> testnet.\n> \n> \n> > All of these changes were put in the same basket of \"Require\n> > unanimous consent\", so why one kind of change is better or worse\n> > than the others? All of them deviates from the mainnet, and we\n> > probably wouldn't want anything like that on the original chain\n> > anyway.\n> >\n> > > I'd think that testnets should be reset more frequently than that.\n> >\n> > Then why don't we put any kind of reset logic into testnet5\n> > consensus rules? Because when nothing like that is present, then\n> > testnets can potentially run forever. Testnet3 is becoming an\n> > altcoin, and new testnets will also be, if no significant changes\n> >",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2037,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Unbreaking testnet4",
      "message_count": 1,
      "participants": [
        "pithosian"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/20250512201916.3818A7C1190@smtp.postman.i2p",
          "title": "Re: [bitcoindev] Re: Unbreaking testnet4",
          "author": "pithosian <pithosian@i2pmail@org>",
          "date": "Mon, 12 May 2025 20:19:16 +0000 (UTC)",
          "body": "> Not only that. It may also invalidate timelocked signatures, which\n> would be made around \"halving\".\n\nGood point. I was thinking about just hacking at the UTXO set as it\nconceptually seemed to make the change very localized, but timelocks\nprobably(?) rule the whole approach out.\n\nThe freely-spendable amount would be:\n\namount/2^(targetHeight/halvingBlocks-utxoHeight/halvingBlocks)\n\nOr the bitshift equivalent, where targetHeight is the current height,\nor in the case of timelocks, the locked height, but longer\ntimestamp-based timelocks can't be reasoned about very well with any\n'degrading coin' behaviour, and even your presigned, height locked\ntransaction might not get be confirmed before the next epoch if the\ntimelock approaches it.\n\nDoesn't modifying spendability have the same problem? When presigning\nyour timelocked transaction, you need to be aware of the amount you can\nactually spend come expiry of the timelock up-front, however the coin\ndegrades.\n\nIt also breaks lightning channels, I think.\n\nOn Mon, 12 May 2025 18:18:09 +0000 (UTC)\nSaint Wenhao <saintwenhao@gmail•com> wrote:\n\n> > Updating the entire UTXO set all at once would be pretty expensive,\n> \n> Not only that. It may also invalidate timelocked signatures, which\n> would be made around \"halving\". So, if you would sign something, when\n> block height will be set to 209,990, and timelock it into 20 blocks,\n> then at block height 210,010, it would be invalid, because of\n> incorrect amount.\n> \n> Which means, that stored UTXO amounts should be probably left\n> untouched, but rather spendability of the coins should be affected.\n> So: if someone received 50 tBTC, then that person should be able to\n> freely move 25 tBTC anywhere, but 25 tBTC can be enforced to go\n> directly into transaction fees (and so on, and so forth, so later it\n> would be splitted into 12.5 spendable tBTC, and 37.5 tBTC fees).\n> \n> And then, that kind of fees can be claimed directly by miners, or can\n> be simply burned, by just not claiming it, ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2041,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Public disclosure of one vulnerability affecting Bitcoin Core <29.0",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/UCY0pWHlfFg8YzQRMNBHyUIg15CJLI8gM4E-7eHvYmUhkE5mP9Bz71xcHbnyyie8V9ZOnbi6yyKy4rG9h4O8RVx6_tAWD5BV6W71SHHyJiY=@protonmail.com",
          "title": "Re: [bitcoindev] Public disclosure of one vulnerability affecting Bitcoin Core <29.0",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 16 May 2025 14:41:22 +0000",
          "body": "> You can find the advisory on the Bitcoin Core project website at https://bitcoincore.org/en/2025/03/31/disclose-cve-2024-52919.\n\nThe link was since updated to https://bitcoincore.org/en/2025/04/28/disclose-cve-2024-52919\n\n\nOn Monday, April 28th, 2025 at 3:00 PM, 'Antoine Poinsot' via Bitcoin Development Mailing List <bitcoindev@googlegroups.com> wrote:\n\n> \n> \n> Hi everyone,\n> \n> In accordance with our security disclosure policy, i am sharing today a low-severity security advisory affecting Bitcoin Core versions before 29.0 (released 2 weeks ago).\n> \n> You can find the advisory on the Bitcoin Core project website at https://bitcoincore.org/en/2025/03/31/disclose-cve-2024-52919.\n> \n> For more details about the Bitcoin Core security disclosure policy, see https://bitcoincore.org/en/security-advisories.\n> \n> Antoine Poinsot\n> \n> --\n> You received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\n> To view this discussion visit https://groups.google.com/d/msgid/bitcoindev/EYvwAFPNEfsQ8cVwiK-8v6ovJU43Vy-ylARiDQ_1XBXAgg_ZqWIpB6m51fAIRtI-rfTmMGvGLrOe5Utl5y9uaHySELpya2ojC7yGsXnP90s%3D%40protonmail.com.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/UCY0pWHlfFg8YzQRMNBHyUIg15CJLI8gM4E-7eHvYmUhkE5mP9Bz71xcHbnyyie8V9ZOnbi6yyKy4rG9h4O8RVx6_tAWD5BV6W71SHHyJiY%3D%40protonmail.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1825,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [Proposal] 64-bit arithmetic in Script",
      "message_count": 1,
      "participants": [
        "Christian Decker"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALxbBHWP=zOfT0+YM=4MgR6SEuT9CCFHQEuH_mkgtDKiRxpfog@mail.gmail.com",
          "title": "Re: [bitcoindev] [Proposal] 64-bit arithmetic in Script",
          "author": "Christian Decker <decker.christian@gmail@com>",
          "date": "Wed, 14 May 2025 10:27:54 +0200",
          "body": "Hi Chris,\n\nI was contacted by other ML members pointing out that the GSR may not\nhave announced on the ML. I was not aware, and would not have brought\nit up as a competing effort in such a case.\nApologies for the noise, and I hope that an update on the idea and\ncurrent status of the GSR will be published eventually :-)\n\nRegards,\nChristian\n\nOn Wed, May 14, 2025 at 10:24 AM Chris Stewart\n<stewart.chris1234@gmail•com> wrote:\n>\n> Hi Christian,\n>\n> Thank you for the interest in this proposal!\n>\n> I’d like to invite you, Rusty, or any other contributors to provide an update to the list on the status of GSR. The most recent public writing I’m aware of is Rusty’s blog post, which is now around 18 months old. Are there any newer materials — such as additional posts, WIP BIPs, or code — that we could review or experiment with? Even rough drafts would be helpful for prototyping and discussion.\n>\n> I’m not opposed to the broader goals of GSR, but I do think it’s a bit ambitious. That’s partly why I’ve focused my efforts on isolating what I believe is the most requested feature: 64-bit precision to enable amount locks.\n>\n> >arbitrary sized integers\n>\n> It would be helpful to see some concrete examples of opcodes that would require arbitrary precision, but wouldn’t be achievable with 64-bit arithmetic. Looking at the Elements project, there are a couple of examples — ECMULSCALARVERIFY and TWEAKVERIFY — which operate on 256-bit stack arguments. Notably, these opcodes don’t support composition with existing arithmetic opcodes like OP_ADD or OP_SUB; they simply verify cryptographic conditions. I would argue they do not actually require supporting more precision in Script as the stack arguments aren't parsed into CScriptNum.\n>\n> It could be useful to have a list of these potential opcodes that could be enabled in a single place to give other protocol developers an idea of what is enabled by arbitrary precision.\n>\n> >maybe you could join that effort for your use-cases too?\n>\n> Where c",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2056,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "RE: [bitcoindev] The Tragic Tale of BIP30",
      "message_count": 1,
      "participants": [],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/035301dbbba6$701dd490$50597db0$@voskuil.org",
          "title": "RE: [bitcoindev] The Tragic Tale of BIP30",
          "author": "<eric@voskuil@org>",
          "date": "Fri, 2 May 2025 17:09:05 -0400",
          "body": "Hi Ruben,\n\n> >The obvious solution to this problem is to not create the problem in the first\n> place.\n> \n> Yes, that is a fair point. Not removing the checkpoints is one way of ensuring\n> the consensus bug cannot be triggered.\n\nIt's more than that. We are contemplating a \"consensus bug\" that would cause a chain split because the BIP30 exceptions are no longer being covered by any checkpoint. The heights at which this would cause a split are well below all but 3 of the 14 checkpoints. For that to occur 11 formerly checkpointed blocks would first have to be popped, given the existence of a stronger chain capable of triggering the above bug. This implies 11 more chain splits, depending at which point nodes adopted the checkpoint soft fork(s), just to reach this bug, and up to 14 possible in total. It makes no sense to fix this bug without first fixing chain splits that would be triggered *over 200,000 blocks less deep* than this BIP30 bug. And the only way to fix those is to not remove the checkpoints - which renders this bug inert.\n\n> I'm agnostic about whether having\n> checkpoints is also a reason to forgo consensus checks such as BIP30 (or my\n> proposed alternative of checking the coinbase TXID for uniqueness and\n> ensuring no future collision).\n\nThere is certainly a reason, the checkpoints are consensus rules.\n\n> Even though checkpoints essentially force your node to halt if something were invalid up until that point, \n\nRight, if any other rule conflicted with them then the chain would stall forever at that point. That is not the applied meaning of these rules. The checkpoints declare that the blocks are required and therefore inherently valid. The reason we are having this conversation is the contemplated removal of the checkpoints, which also implies that other validation within covered blocks is not consensus.\n\n> I still think there is value in being able to verify that the rules were followed.\n\nLike them or not, checkpoints are the rules that are required to be",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2042,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
      "message_count": 1,
      "participants": [
        "Sergej Kotliar"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABZBVTBupMcBbOUtLbMaEmAiWGsMwisNW+k+bTUJGsUad2=ZZg@mail.gmail.com",
          "title": "Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
          "author": "Sergej Kotliar <sergej@bitrefill@com>",
          "date": "Thu, 20 Oct 2022 14:37:53 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 12590 bytes --]\n\nOn Thu, 20 Oct 2022 at 09:22, Anthony Towns <aj@erisian•com.au> wrote:\n\n> On Wed, Oct 19, 2022 at 04:29:57PM +0200, Sergej Kotliar via bitcoin-dev\n> wrote:\n> > The\n> > biggest risk in accepting bitcoin payments is in fact not zeroconf risk\n> > (it's actually quite easily managed),\n>\n> You mean \"it's quite easily managed, provided the transaction doesn't\n> opt-in to rbf\", right? At least, that's what I understood you saying last\n> time; ie that if the tx signals rbf, then you just don't do zeroconf no\n> matter what other trustworthy signals you might see:\n>\n>   https://twitter.com/ziggamon/status/1435863691816275970\n>\n> (rbf txs seem to have increased from 22% then to 29% now)\n>\n\nYeah. Our share of RBF is a bit lower than that as many RBF transactions\nare something other than consumer purchases, and most consumer purchases\ncan't do RBF\n\n\n> > it's FX risk as the merchant must\n> > commit to a certain BTCUSD rate ahead of time for a purchase. Over time\n> > some transactions lose money to FX and others earn money - that evens out\n> > in the end.\n>\n> > But if there is an _easily accessible in the wallet_ feature to\n> > \"cancel transaction\" that means it will eventually get systematically\n> > abused. A risk of X% loss on many payments that's easy to systematically\n> > abuse is more scary than a rare risk of losing 100% of one occasional\n> > payment. It's already possible to execute this form of abuse with opt-in\n> > RBF,\n>\n> If someone's going to systematically exploit your store via this\n> mechanism, it seems like they'd just find a single wallet with a good\n> UX for opt-in RBF and lowballing fees, and go to town -- not something\n> where opt-in rbf vs fullrbf policies make any difference at all?\n>\n\nSort of. But yes once this starts being abused systemically we will have to\ndo something else w RBF payments, such as crediting the amount in BTC to a\ncustodial account. But this option isn't available to your normal p",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aBmgk4nqULp2_5GA@erisian.com.au",
          "title": "Re: [bitcoindev] Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Tue, 6 May 2025 15:39:31 +1000",
          "body": "On Fri, May 02, 2025 at 08:06:18PM +1000, Anthony Towns wrote:\n> So the mempoolfullrbf default changed from false to true in 28.0 released\n> in October last year, which is advertised as being run by maybe 30%-40%\n> of the network now, and fullrbf transactions have been reportedly been mined\n> reliably since well before that.\n>\n> Any chance of an update on how that change has affected bitcoin/lightning\n> payment volume for you guys, or customer satisfaction (if payment\n> acceptance is delayed more often), or how much engineering/support time\n> was needed to adapt, or any other impact?\n\nThere was a related thread on X late last year that offers some relevant\ninformation for these questions:\n\n  https://x.com/MattAhlborg/status/1828436316930912364\n\nSome key points from that thread, IMO:\n\n * The \"relative volume\" metric shows a drop in bitcoin/lightning volume\n   from 30%-40% in 2022 to 25%-30% in late 2024\n\n * The \"monthly active users\" metric shows a drop in bitcoin/lightning\n   volume from about 50% to about 40% in a similar timeframe, as well as\n   a large switch from on-chain to lightning\n\n * The \"average payment size\" metric shows distinctly different behaviours\n   between on-chain bitcoin users and lightning users -- individual\n   on-chain payments are about 4x greater in value than individual\n   lightning payments\n\n * Bitrefill stopped accepting zeroconf transactions in Aug/Sep 2023; they\n   didn't indicate if this was due to seeing a rise in (attempted?) fraud,\n   or a purely preventative measure.\n\n * The charts show definite correlations between the decrease in on-chain\n   activity with fee spikes\n\n * The charts don't show obvious correlations between on-chain activity\n   and when bitrefill stopped accepting zeroconf transactions. At best\n   you could argue this shows up as volume not returning to on-chain\n   bitcoin after the fee spikes eased.\n\n * This may also be due to a rise in use of bitrefill accounts -- ie,\n   you send a bunch of money to top up your bit",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Graftleaf: Program Composition and Generic Delegation",
      "message_count": 1,
      "participants": [
        "Josh Doman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/0b5b560b-aa0c-4669-9621-67ccbecba516n@googlegroups.com",
          "title": "[bitcoindev] Graftleaf: Program Composition and Generic Delegation",
          "author": "Josh Doman <joshsdoman@gmail@com>",
          "date": "Mon, 5 May 2025 18:27:44 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 13399 bytes --]\n\n \n\n*TLDR: I'm exploring an idea to enable generalized program composition and \ncoin delegation, which seems to strike a nice balance between simplicity \nand flexibility.*\n\nHi all,\n\nI’ve been thinking recently about the optimal way to introduce delegation \nto Bitcoin. The idea of delegating one’s coins is not a new one. Some \nspeculate <https://bitcoinops.org/en/topics/op_codeseparator/> that OP_\nCODESEPARATOR was an early attempt by Satoshi to do delegation. More \nrecently, proposals like Graftroot \n<https://gnusha.org/pi/bitcoindev/CAAS2fgSnfd++94+40vnSRxQfi9fk8N6+2-DbjVpssHxFvYveFQ@mail.gmail.com/>\n and Entroot <https://gist.github.com/sipa/ca1502f8465d0d5032d9dd2465f32603>\n have been put forward, which would enable delegation (and re-delegation), \nbut only from key path spends and only to a locking script. In contrast, \nCSFS <https://github.com/bitcoin/bips/blob/master/bip-0348.md> would enable \ndelegation from script path spends, but it's limited, as it only \nfacilitates delegation within a pre-committed script.\n\nWhen considering delegation, what type of functionality is desirable? I’d \nargue that generalized delegation has two properties:\n\n   1. Delegation *from any valid spending path*\n   2. Delegation *to arbitrarily complex compositions of programs and \n   script*\n\nThe latter is important so that users can delegate to *addresses*, and not \njust public keys, while retaining the ability to add timelocks and other \nconditions.\n\nIn order to build this, we need two key features: 1) \"Generalized \nComposition,\" and 2) \"Generalized Delegation.\" Generalized composition \ninvolves the conjunction of programs and script, and delegation is merely \nthe addition of a second composition on-the-fly, if the primary one is \nsatisfied.\n\nIs there a simple and safe way to implement generalized composition and \ndelegation within Taproot? I think there is...\n\nI’d like to present a proof-of-concept that I came up with, wh",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2067,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] ColliderVM protocol for computation and L2 bridges",
      "message_count": 1,
      "participants": [
        "\"'Victor Kolobov' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAF0T6Xhf=Qb+B-3nBtR1Oiyk3gOO=o-8jdT0cJ6fRH=2azQvAg@mail.gmail.com",
          "title": "[bitcoindev] ColliderVM protocol for computation and L2 bridges",
          "author": "\"'Victor Kolobov' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sun, 4 May 2025 15:10:55 +0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1330 bytes --]\n\nI would like to update you about an alternative protocol to BitVM that we\nhave been working on, which we call ColliderVM. It uses the same trust\nassumptions as BitVM but without needing fraud proofs. By that it is\neliminating the need for a fraud-proof time window. All in all, some\nadditional work is needed to make this protocol practical.\n\nPerhaps some ideas here could also be of independent interest.\n\n\nHere is the link to the paper:\n\nhttps://eprint.iacr.org/2025/591\n\n(Please note that we erroneously used an incorrect estimate for BLAKE3\nscript size, but this will be fixed in the next version which is coming in\na few days):\n\nWe’ve also made a video explaining this protocol\n\nhttps://starkware.co/blog/avihu-levy-bitcoin-horizons-from-op_cat-to-covenants-hong-kong/\n\nDelving Bitcoin post with more details:\n\nhttps://delvingbitcoin.org/t/collidervm-protocol-for-computation-and-l2-bridges/1662\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAF0T6Xhf%3DQb%2BB-3nBtR1Oiyk3gOO%3Do-8jdT0cJ6fRH%3D2azQvAg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 6775 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1479,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Introducing Hourglass",
      "message_count": 1,
      "participants": [
        "Hunter Beast"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/db3d0ec4-90b8-44a4-b912-b98ec9083b10n@googlegroups.com",
          "title": "[bitcoindev] Introducing Hourglass",
          "author": "Hunter Beast <hunter@surmount@systems>",
          "date": "Tue, 29 Apr 2025 15:38:26 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 653 bytes --]\n\nThis is a proposal to mitigate against potential mass liquidation of P2PK \nfunds. The specification is pretty simple, but the motivation and \njustification for it is a bit longer.\n\nhttps://github.com/cryptoquick/bips/blob/hourglass/bip-hourglass.mediawiki\n\nFeedback welcome!\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/db3d0ec4-90b8-44a4-b912-b98ec9083b10n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 1273 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 807,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: Introducing Hourglass",
      "message_count": 1,
      "participants": [
        "Hunter Beast"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/4f35a82a-bedb-4d4d-9de2-2dbc340b18acn@googlegroups.com",
          "title": "[bitcoindev] Re: Introducing Hourglass",
          "author": "Hunter Beast <hunter@surmount@systems>",
          "date": "Sat, 3 May 2025 23:00:11 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2207 bytes --]\n\nTrading volume is a good perspective to view this through, actually. If an \nattacker decides to consolidate immediately, they could do so within just a \ncouple hours and suppress the Bitcoin price for a long time.\n\n> 1.7 million Bitcoin represents possibly about 1 week of global trading \nvolumes. Even assuming it is 1-2 months of trading volumes, the market can \nabsorb.\n\nHourglass spreads that 1 week of trading volume over a minimum of 8 months, \npossibly more.\n\n> Trying to manage the Bitcoin price via spending restrictions is a \nterrible idea.\n\nWhile I generally agree with this sentence, I think P2PK coins are an \nexceptional case.\n\n> In any case, the Bitcoin price routinely drops by upwards of 85%. It is \nnot a security concern. Price volatility is not a security.\n\nPrice volatility absolutely impacts security, and this would be an \nunprecedented event. We also haven't seen an 85% price drop in a long time.\n\nOn Saturday, May 3, 2025 at 5:55:28 AM UTC-6 Francis Pouliot wrote:\n\n>\n> Concept NACK.\n>\n> 1.7 million Bitcoin represents possibly about 1 week of global trading \n> volumes. Even assuming it is 1-2 months of trading volumes, the market can \n> absorb.\n>\n> Trying to manage the Bitcoin price via spending restrictions is a terrible \n> idea.\n>\n> In any case, the Bitcoin price routinely drops by upwards of 85%. It is \n> not a security concern. Price volatility is not a security. \n> On Tuesday, April 29, 2025 at 5:08:16 PM UTC-6 Hunter Beast wrote:\n>\n>> This is a proposal to mitigate against potential mass liquidation of P2PK \n>> funds. The specification is pretty simple, but the motivation and \n>> justification for it is a bit longer.\n>>\n>> https://github.com/cryptoquick/bips/blob/hourglass/bip-hourglass.mediawiki\n>>\n>> Feedback welcome!\n>>\n>\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiv",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 2,
            "text_length": 2039,
            "has_nack": true,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] SwiftSync - smarter synchronization with hints",
      "message_count": 1,
      "participants": [
        "Ruben Somsen"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPv7TjaM0tfbcBTRa0_713Bk6Y9jr+ShOC1KZi2V3V2zooTXyg@mail.gmail.com",
          "title": "[bitcoindev] SwiftSync - smarter synchronization with hints",
          "author": "Ruben Somsen <rsomsen@gmail@com>",
          "date": "Wed, 9 Apr 2025 12:10:21 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3481 bytes --]\n\nHi everyone,\n\nSwiftSync is a new validation method that allows for near-stateless, fully\nparallelizable validation of the Bitcoin blockchain via hints about which\noutputs remain unspent (<100MB total). All other inputs/outputs are\nefficiently crossed off inside a single hash aggregate that only reaches\nzero if validation was successful and the hints were correct.\n\nThe main observation is that it can be much easier to validate that a given\nUTXO set is correct than to compute it yourself. It allows us to no longer\nrequire a stateful moment-to-moment UTXO set during IBD and allows\neverything to be order independent. I'll briefly summarize the protocol,\nbefore sharing the link to the full write-up.\n\nEach output gets a boolean hint (e.g. committed into Bitcoin Core) about\nwhether or not it will still be in the UTXO set after validation completes.\nIf it does, we write it to disk (append-only - it won't be used until\nSwiftSync finishes). If it does not, we hash the UTXO data and add it to an\naggregate. For each input, we once again hash the UTXO data and remove it\nfrom the aggregate.\n\nAt the end, for every added output there should have been exactly one\nremoved input, bringing the end total of the aggregate to zero. If this is\nindeed the case, we will have validated that the hints, and the resulting\nUTXO set, were correct.\n\nE.g. For spent outputs A, B and inputs C, D we calculate hash(UTXO_A||salt)\n+ hash(UTXO_B||salt) - hash(UTXO_C||salt) - hash(UTXO_D||salt) == 0\n(proving (A==C && B==D) || (A==D && B==C)).\n\nThere is one missing step. The UTXO data is only available when processing\nthe output, but not when processing the input. We resolve this by either\ndownloading the outputs that were spent for each block (equivalent to the\nundo data, maybe 10-15% of a block), or we lean on assumevalid, making it\nsufficient to only hash the outpoints (which are available in both the\noutput and input) rather than the full UTXO da",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2060,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: SwiftSync - smarter synchronization with hints",
      "message_count": 1,
      "participants": [
        "Nagaev Boris"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAFC_Vt6BgUFt5+zbSKzHyN4Sk1nFw5hbXVcv_jdUzA5RJvwFBg@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: SwiftSync - smarter synchronization with hints",
          "author": "Nagaev Boris <bnagaev@gmail@com>",
          "date": "Sat, 3 May 2025 22:06:38 -0300",
          "body": "On Sat, May 3, 2025 at 9:07 AM Greg Maxwell <gmaxwell@gmail•com> wrote:\n>\n> On Saturday, May 3, 2025 at 11:55:28 AM UTC Sanket Kanjalkar wrote:\n>\n> > hash(UTXO_A||salt) + hash(UTXO_B||salt) - hash(UTXO_C||salt) - hash(UTXO_D||salt) == 0 (proving (A==C && B==D) || (A==D && B==C))\n>\n> What if instead of hash we encrypt with AES and modular add/subs? I cannot prove it; but I also don't see a clear way this is broken.\n>\n> 1. Sample random symmetric key `k`\n> 2. Instead of above; AES_k(UTXO_A) + AES_k(UTXO_B) - AES_k(UTXO_C) - AES(UTXO_D) == 0 =>  (proving (A==C && B==D) || (A==D && B==C))?\n>\n>\n> AES in CTR mode is, I'm not sure about other modes? Obviously CTR mode would be unsuitable! (I mean sure modular add/sub and xor are different operations but they are quite close).  I think that in many modes the collision resistance would have to at least be restricted by the birthday bound with the small block size. I think CMC might be needed to avoid that sort of issue.\n\nCan Haraka V2 [1] hash function be used? It is based on AES and\nsupports 256 or 512 bit inputs. UTXO (txid + index) has a fixed size\nand fits into 320 bits. We can use the 512 bit version and just leave\nthe remaining bytes zero.\n\n[1] https://github.com/kste/haraka\n\n-- \nBest regards,\nBoris Nagaev\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAFC_Vt6BgUFt5%2BzbSKzHyN4Sk1nFw5hbXVcv_jdUzA5RJvwFBg%40mail.gmail.com.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 1733,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "RE: [bitcoindev] Removing checkpoints in Bitcoin Core v30",
      "message_count": 1,
      "participants": [],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/035701dbbba7$807f23b0$817d6b10$@voskuil.org",
          "title": "RE: [bitcoindev] Removing checkpoints in Bitcoin Core v30",
          "author": "<eric@voskuil@org>",
          "date": "Fri, 2 May 2025 17:16:42 -0400",
          "body": "Hi Sjors,\n\n> In the context of BIP30 [0] Eric Voskuil brought up performance:\n\nI didn't originate the point on performance. I said (in the BIP30 thread):\n\n> One reference states that “assume valid” speeds IBD, but of course it does so by not validating.\n\nWhich was in response to your OP of this thread, which provided that reference, specifically:\n\n\"Assumed Valid Blocks: a feature designed to replace the secondary use of checkpoints for (optionally) speeding up Initial Block Download (IBD) by skipping validation of signatures in old blocks. This was deployed in Bitcoin Core 0.14\" - David A. Harding\n\nThis in turn references the following discussion:\n\n\"Bitcoin 0.5.0 built upon those checkpoints to speed up IBD by skipping verification of signatures in blocks that were earlier in the block chain than the most recent checkpoint.\"\n\nhttps://bitcoincore.org/en/2017/03/08/release-0.14.0/#assumed-valid-blocks\n\n> >  The top checkpoint is consensus for over 11 years and materially reduces\n> the validation cost of 295,000 blocks.\n> \n> I don't think performance should be a consideration when removing\n> checkpoints.\n\nTo be perfectly clear, I am not arguing against this hard fork because it reduces IBD cost. I’m pointing out that one of the arguments *in favor* of removing checkpoints is that \"assume valid\" now serves this \"secondary use\". However, as I pointed out, assume valid is not consensus, it achieves this outcome by trusting, not validating. The existing checkpoints are consensus - they provide this advantage when fully validating.\n\nI'm not suggesting that checkpoints need to be added to improve performance. I'm pointing out that removing them hurts performance. So performance is obviously not a reason to accept such a hard fork.\n\n> Afaik checkpoints were not introduced as a performance feature, but rather as\n> a DoS vulnerability fix.\n\nIt appears from the above discussion that there was more than one reason. However this isn't relevant. What matters is the consequences of ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] BIP Proposal: Define Bitcoin Subunits as Satoshis/Sats",
      "message_count": 1,
      "participants": [
        "Jakub Szwedo"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/3339434d-6a10-4ccf-b1dd-2aa9afee5864n@googlegroups.com",
          "title": "Re: [bitcoindev] BIP Proposal: Define Bitcoin Subunits as Satoshis/Sats",
          "author": "Jakub Szwedo <jakubszwedo@gmail@com>",
          "date": "Fri, 2 May 2025 13:54:26 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 4902 bytes --]\n\nHi,\n\nIf the author of the BIP would like to add some accessibility and voice/UI \nguidance mentioned by Lucas, a great open source resource created by \nBitcoin Design community exists on the topic:\n\nhttps://bitcoin.design/guide/designing-products/units-and-symbols/\n\nI hope it helps.\n\nBest,\nJakub\n\nOn Thursday, 1 May 2025 at 11:24:17 UTC+2 Lucas André wrote:\n\n> Maranatha!\n>\n> I propose a small addition that could improve this, particularly for users \n> relying on assistive technologies (like our boi Hal Finney once did).\n>\n> Specifically, I suggest adding a short section on *accessibility and \n> voice/UI guidance*. Your proposal does a solid job, but it doesn't yet \n> cover how these should be handled in screen readers, voice assistants, or \n> accessible interfaces. Below is a proposed section that could be added \n> under \"specification\" or introduced as a new non-normative section.\n>\n> To ensure clarity and inclusiveness in UIs and assistive technologies, the \n>> following recommendations apply:\n>>  \n>> Pronunciation:\n>> The abbreviation \"sat\" should be pronounced as /sæt/, and \"sats\" (plural) \n>> should be pronounced as /sæts/ (rhyming with \"cats\") by screen readers and \n>> voice assistants. \"Satoshi\" (singular) is pronounced /səˈtoʊʃi/. \"Satoshis\" \n>> (plural) is pronounced /səˈtoʊʃiz/. \n>\n>  \n>\n> Singular vs. Plural:\n>> \"1 sat\" should be read as \"one satoshi\" and \"100 sats\" as \"one hundred \n>> satoshis\" to preserve correct pluralization and meaning. When reading \n>> aloud: \n>\n>  \n>\n> \"1 sat\" → \"one satoshi\" → /wʌn səˈtoʊʃi/\n>> \"100 sats\" → \"one hundred satoshis\" → /wʌn ˈhʌndrəd səˈtoʊʃiz/\n>>  \n>> Readable Formats:\n>> Prefer full terms in accessibility modes (e.g., \"satoshis\" instead of \n>> \"sats\"), and group digits to assist parsing (e.g., \"12,345\" instead of \n>> \"12345\").\n>>  \n>> Contextual Labels:\n>> Interfaces should use clear alt-text or aria-labels such as: *alt=\"Transaction \n>> fee: 14 satoshis per ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/be3813bf-467d-4880-9383-2a0b0223e7e5@gmail.com",
          "title": "[bitcoindev] DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Thu, 17 Apr 2025 16:27:04 +0000",
          "body": "Hi list,\n\nCross-Input Signature Aggregation (CISA) has been a recurring topic here, aiming\nto reduce transaction sizes and verification cost [0]. Tim Ruffing, Yannick\nSeurin and I recently published DahLIAS, the first interactive aggregate\nsignature scheme with constant-size signatures (64 bytes) compatible with\nsecp256k1.\n\nhttps://eprint.iacr.org/2025/692.pdf\n\nRecall that in an aggregate signature scheme, each signer contributes their own\nmessage, which distinguishes it from multi- and threshold signatures, where all\nsigners sign the same message. This makes aggregate signature schemes the\nnatural cryptographic primitive for cross-input signature aggregation because\neach transaction input typically requires signing a different message.\n\nPrevious candidates for constant-size aggregate signatures either:\n- Required cryptographic assumptions quite different from the discrete logarithm\n   problem on secp256k1 currently used in Bitcoin signatures (e.g., groups with\n   efficient pairings).\n- Were \"folklore\" constructions, lacking detailed descriptions and security\n   proofs.\n\nBesides presenting DahLIAS, the paper provides a proof that a class of these\nfolklore constructions are indeed secure if the signer does _not_ use key\ntweaking (e.g., no Taproot commitments or BIP 32 derivation). Moreover, we show\nthat there exists a concrete attack against a folklore aggregate signature\nscheme derived from MuSig2 when key tweaking is used.\n\nIn contrast, DahLIAS is proven to be compatible with key tweaking. Moreover, it\nrequires two rounds of communication for signing, where the first round can be\nrun before the messages to be signed are known. Verification of DahLIAS\nsignatures is asymptotically twice as fast as half-aggregate Schnorr signatures\nand as batch verification of individual Schnorr signatures.\n\nWe believe DahLIAS offers an attractive building block for a potential CISA\nproposal and welcome any feedback or discussion.\n\nJonas Nick, Tim Ruffing, Yannick Seurin\n\n\n[0] See, e.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
      "message_count": 1,
      "participants": [
        "waxwing/ AdamISZ"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a9f133ff-1d8e-45a3-8186-79fb52bbd467n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
          "author": "waxwing/ AdamISZ <ekaggata@gmail@com>",
          "date": "Wed, 30 Apr 2025 08:54:46 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 4406 bytes --]\n\n\n> That partial signatures do not leak information about the secret key x_k \nis \nimplied by the security theorem for DahLIAS: If information would leak, the \nadversary could use that to win the unforgeability game. However, the \nadversary \ndoesn't win the game unless the adversary solves the DL problem or finds a \ncollision in hash function Hnon.\n\nOK, so that's maybe a theoretical confusion on my part, I'm thinking of the \nHVZK property of the Schnorr ID scheme, which \"kinda\" carries over into the \nFS transformed version with a simulator (maybe? kinda?). Anyway this is a \nsidetrack and not relevant to the paper, so I'll stop on that.\n\n> This is a very interesting point, probably out of scope for the paper. A \nsingle-party signer, given secret keys xi, ..., xn for public keys X1, ..., \nXn \ncan draw r at random, compute R := r*G and then set s := r + c1*x1 + ... + \ncn*xn. So this would only require a single group multiplication.\n\nI feel bad for saying so, but I absolutely do believe it's in scope of the \npaper :) If there is a concrete, meaningful optimisation that's both \npossible and sensible (and as you say, there is such an ultra-simple \noptimisation ... I guess that's entirely correct!), then it should be \nincluded there and not elsewhere. Why? Because it's exactly the kind of \nthing an engineer might want to do, but it's definitely not their place to \nmake a judgement as to whether it's safe or not, given that these protocols \nare such a minefield. I'd say even if there is *no* such optimisation \npossible it's worth saying so.\n\nI guess the counterargument is that it's suitable for a BIP not the paper? \nBut I'd disagree, this isn't purely a bitcoin thing.\n\nOn the third paragraph, yeah, as per earlier email, I realised that that \njust doesn't work.\n\nOn Wednesday, April 30, 2025 at 9:03:34 AM UTC-6 Jonas Nick wrote:\n\n> Thanks for your comments.\n>\n> > That side note reminds me of my first question: would i",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] [meta] moving conceptual discussion for policy changes",
      "message_count": 1,
      "participants": [
        "Sjors Provoost"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2294D284-77C1-4885-9585-E591FEE4878A@sprovoost.nl",
          "title": "Re: [bitcoindev] [meta] moving conceptual discussion for policy changes",
          "author": "Sjors Provoost <sjors@sprovoost@nl>",
          "date": "Wed, 30 Apr 2025 17:49:49 +0200",
          "body": "I think it's worth trying, but I don't think it's going to work.\n\nThere's always going to be people who deliberately link directly to a pull request with the goal of wreaking havoc.\n\nIt could just be normal online impulsive behaviour*, similar to road rage. Someone might first comment on the PR, but feels insufficient heard there. This (briefly) makes them angry and they want to share this frustration. The social media algorithm does the rest. By the time you cool down, the damage is done.\n\nBut it can also be done by people who know exactly how this stuff works.\n\n> Op 30 apr 2025, om 16:30 heeft 'Matthew Zipkin' via Bitcoin Development Mailing List <bitcoindev@googlegroups.com> het volgende geschreven:\n> \n> The comment brigade on the OPRETURN pull requests has gotten out of hand and I think we should consider adding a new process step for policy changes.\n\nThat said, people with good intentions should be given every opportunity to voice their concerns in a non-destructive way. It's fair to say that the mailinglist can be a high bar, especially if the social media link takes you to Github. Seeing your comment be moderated without a simple and immediate alternative can lead to extra frustration, it's good if we can prevent that. Since the mailinglist also has a moderation delay, this could add extra fuel to the frustration.\n\n> What I think we need is a second step between the mailing list and the pull request. GitHub \"discussions\" are probably the best format for this, either in bitcoin-core/meta or bitcoin/bitcoin. \n> \n> Taking a hint from Russ' comment in /meta#18, the discussion could be opened with position statements listing all the pro's and con's and most importantly, FAQs and busting myths like \"bigger opreturns make it harder to run a full node\".\n\nIf someone volunteers to write this, that's fine of course. But we should not set this as an expectation. The normal process is to propose on the mailing list and then implement in Bitcoin Core, which this PR followe",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Standard Unstructured Annex",
      "message_count": 1,
      "participants": [
        "Peter Todd"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aBBAe265_h9A_lNz@petertodd.org",
          "title": "Re: [bitcoindev] Standard Unstructured Annex",
          "author": "Peter Todd <pete@petertodd@org>",
          "date": "Tue, 29 Apr 2025 02:59:07 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1380 bytes --]\n\nOn Mon, Apr 28, 2025 at 12:25:08PM -0400, Russell O'Connor wrote:\n> Ah nevermind, I get it now.\n> \n> The contrapositive of this proposed standardness rule is that if one annex\n> is empty, then all annexes must be empty.  Therefore if on participants\n> signs an empty annex, then standardness would imply that all the annexes\n> must be empty.\n\nYou're almost correct.\n\nThere is a consensus distinction between having an annex, and not having\nan annex at all. That means a zero-byte annex is different from not\nhaving an annex at all.\n\nSo with my proposed rule, inputs can either have no annex at all (the\nstandard status quo), or an annex of zero or more bytes.\n\nIf any input has an annex, *all* inputs must have an annex. However, for\nefficiency, they're allowed to have a completely empty, zero-byte,\nannex. So basically an empty annex is just the defined way for an input\nto sign their approval of the use of annexes in that transaction (and\nsubsequent tx pinning risk).\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/aBBAe265_h9A_lNz%40petertodd.org.\n\n[-- Attachment #2: signature.asc --]\n[-- Type: application/pgp-signature, Size: 833 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1578,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Standard Unstructured Annex",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/8d5251c8-9381-4f35-9d3e-19ba46c8b31cn@googlegroups.com",
          "title": "Re: [bitcoindev] Re: Standard Unstructured Annex",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Wed, 9 Apr 2025 15:55:58 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 5000 bytes --]\n\nHi Peter,\n\n> Applications already using annexes who want to also take advantage of\n> new consensus features will of course have to upgrade their encoding\n> schemes to match. But I think that's fine.\n\nYes, I agree. I believe there is one more thing to falicitate any future\npotential encoding scheme transition for application.\n\nI.e you have the 1-byte : 0x00 | <random_payload_data>, and you could\nhave a an application-only versioning of the <random_payload_data> with\none more 1-byte, to give the evolvability to application to experiment\nwith multiple parsing format.\n\nSo you would have \"1-byte\" 0x00 | \"random_payload_data\" where \n\"random_payload_data\"\nis defined as 1-byte: <version_number> | \"random_payload_data\". That\nversion number shall only have application meaning, no consensus, it's\njust some kind of clear domain separation. AFAICT, the version number\ncould be always retrofitted for a non-0x00 tag-length-value consensus\nmeaning.\n\nIf it can be useful in any way, an old annex branch with a try of TLV:\nhttps://github.com/ariard/bitcoin/commit/84a897feb20c7df813e236d6bf98b69e241a4530\n\nIMHO, this was a very positive thing for taproot to have a lot of\nversioning and upgradeability paths (e.g leaves version, pubkey type, etc).\n\n> There is a possibility of a multi-party, annex-using, protocol where\n> someone does a pinning attack by re-signing their transaction with a\n> bigger annex. But witness-RBF in combination with replace-by-fee-rate\n> will fix this, so I'm not concerned. No such protocols actually exist\n> yet anyway, so we can figure that out later.\n\nCorrect given it's opt-in and that there will be witness-RBF support.\n\nNote, for witness support, where IIUC you have wtxidB allowed to\nreplace wtxidB if wtxidA's feerate > wtxidB and if annex size is\nunbounded, I think it works for multi-party protocols.\n\nFor witness re-composition problems, see:\nhttps://github.com/bitcoin/bitcoin/pull/19645#issuecomment-677",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2049,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] The Future of Bitcoin Testnet",
      "message_count": 1,
      "participants": [
        "Saint Wenhao"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/daecbe84-30e7-4ba8-aa60-596cb7c1658bn@googlegroups.com",
          "title": "Re: [bitcoindev] The Future of Bitcoin Testnet",
          "author": "Saint Wenhao <saintwenhao@gmail@com>",
          "date": "Fri, 25 Apr 2025 10:19:00 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2883 bytes --]\n\n> Should we plan for a reset of testnet?\n\nSurprisingly, it is a very good question. However, replacing testnet3 with \ntestnet4, by just dropping support for the old network, should not be \ncalled \"reset\", but rather \"abandon\". So, the question is: should we mine a \nnew Genesis Block, at height one, on top of the current Genesis Block from \ntestnet3, and trigger the biggest possible chain reorganization, where the \nwhole chain is reorged in a backward-compatible way?\n\nAlso I wonder, if that method of introducing testnet5, by doing it on top \nof testnet4's Genesis Block is worth considering. Because then, some \nplanned changes, like entirely dropping the difficulty reset, could be \npotentially turned from hard-fork into just a regular soft-fork, supported \nby hashrate majority.\n\nAnd of course, reorging everything is an edge case, that we may want to see \non any testnet first, before anyone will succeed with that on the main \nnetwork, if SHA-256 will ever be broken, and if re-hashing the whole chain \nwill be needed.\n\nponiedziałek, 31 marca 2025 o 22:41:20 UTC+2 Garlo Nicon napisał(a):\n\n> > 4. As a result, TBTC is being actively bought and sold; one could argue \n> that the fundamental principle of testnet coins having no value has been \n> broken.\n>\n> Now, some time passed, so we can look at the history, and get some \n> conclusions. In case of testnet4, the same thing happened. And some people \n> consider testnets as altcoins: \n> https://bitcointalk.org/index.php?topic=5536825.0\n> Which means, that if new testnets will be released in a similar way, then \n> none of them will be worthless.\n>\n> niedziela, 5 maja 2024 o 15:12:08 UTC+2 Peter Todd napisał(a):\n>\n> On Tue, Apr 30, 2024 at 11:46:59AM -0700, Matthew Bagazinski wrote: \n> > \n> > \n> > Unfortunately, the current form of Testnet is doomed to have value, just \n> > like BTC. Its scarcity makes it a valuable asset. And no reset will \n> change \n> > that. It will ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2047,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Bitcoin Core 29.0 Released",
      "message_count": 1,
      "participants": [
        "Gloria Zhao"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/7897498c-88ec-4c0f-b457-8410944e0ce1n@googlegroups.com",
          "title": "[bitcoindev] Bitcoin Core 29.0 Released",
          "author": "Gloria Zhao <gloriajzhao@gmail@com>",
          "date": "Mon, 14 Apr 2025 18:03:48 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 13128 bytes --]\n\nBitcoin Core version 29.0 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-29.0/>\n\nThis release includes new features, various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has \ncompletely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on \nmacOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL \nis\npossible, but it might take some time if the data directory needs to be \nmigrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and tested on operating systems using the\nLinux Kernel 3.17+, macOS 13+, and Windows 10+. Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them. It is not recommended to use Bitcoin Core on\nunsupported systems.\n\nNotable changes\n===============\n\n### P2P and Network Changes\n\n- Support for UPnP was dropped. If you want to open a port automatically,\n  consider using the `-natpmp` option instead, which uses PCP or NAT-PMP\ndepending on router support. (#31130)\n\n- libnatpmp was replaced with a built-in implementation of PCP and NAT-PMP\n  (still enabled using the `-natpmp` option). This supports automatic IPv4 \nport\nforwarding as well as IPv6 pinholing. (#30043)\n\n- When the `-port` configuration option is used, the default onion listening\n  port will now be derived to be that port + 1 instead of being set to a \nfixed\nvalue (8334 on mainnet).  This re-allow",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2040,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Post Quantum Signatures and Scaling Bitcoin",
      "message_count": 1,
      "participants": [
        "Ethan Heilman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAEM=y+VK2VwoTc3VbHFbARm9no6qJivrug+LPuGy_m8+PFELOA@mail.gmail.com",
          "title": "Re: [bitcoindev] Post Quantum Signatures and Scaling Bitcoin",
          "author": "Ethan Heilman <eth3rs@gmail@com>",
          "date": "Mon, 14 Apr 2025 15:35:33 -0400",
          "body": "> I'm happy to see thinking and discussion in this area.\n\nGetting this discussion going was exactly my intent. I'm not\npresenting so much a solution as we might want to do this at some\npoint what are problems and can we solve them?\n\n> If it turns out to be the case that PQ schemes need more on-chain size, but have lower per-byte computation cost, a reasonable argument could be made that a higher discount factor for PQ data is acceptable.\n\nI was focused on size because computation is pretty great for most PQ\nsignature schemes. PQ signatures are far cheaper to validate per byte\nand according to BIP-360 Falcon is cheaper than edDSA per signature\nverification.\n\nEdDSA Cycles to verify: 130,000\nFALCON-512 Cycles to verify: 81,036\n\nThis is one of the reasons I am very optimistic that Bitcoin will move\nto post-quantum signatures. If research shows that these signature\nschemes are sufficiently JPEG resistant, and I think it will, then a\ndiscount is very attractive.\n\n> I don't think pre-aggregation (beyond a single-transaction-wide one) is realistic, as it effectively breaks in-mempool transaction replacement, turning every pre-aggregated group of transactions that is being relayed together into an atomic package that must be taken or not as a whole.\n\nIn some circumstances it is possible you could aggregate (P+C1, P+C2)\ninto (P+C1+C2). If you can prove that P is the same in both\ntransactions thus the balance and authentication properties are\nmaintained. However I think what you have described is the shape of\nthe problem we need to solve.\n\nConsider transactions: T1, T1', T2, T3, T4, T5\nwhere T1 and T1' are double spends, i.e., spend the same output to\ndifferent outputs. If half the mempool aggregates TA = (T1, T2, T3)\nand the other half aggregates TB = (T1', T4, T5). TA and TB are\nmutually exclusive and transactions are needlessly dropped on the\nfloor. This is a currently existing griefing vector with coinjoins\ntoday and is an issue with mimblewimble aggregation. I don't think",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2061,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Reiterating centralized coinjoin (Wasabi & Samourai) deanonymization attacks",
      "message_count": 1,
      "participants": [
        "Yuval Kogman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAAQdECB2=FPiTkJ5HT813tcK1522j-J1+2=S=nir6kb33KoQjw@mail.gmail.com",
          "title": "Re: [bitcoindev] Reiterating centralized coinjoin (Wasabi & Samourai) deanonymization attacks",
          "author": "Yuval Kogman <nothingmuch@woobling@org>",
          "date": "Wed, 9 Apr 2025 04:16:35 +0200",
          "body": "On Mon, 7 Apr 2025 at 12:35, Javier Mateos <javierpmateos@gmail•com> wrote:\n> If the coordinator had malicious intentions in the beginning, these have been observed and brought to the table by a community that is always active and vigilant about these crucial issues. I believe this is already part of the healthy culture surrounding Bitcoin.\n\nI don't see a reason to believe the privacy weaknesses I have\ndescribed have been exploited, due to the complexity of the attack. If\nthey are/were exploited as discussed with Sjors above in the thread,\nusers should be able to find evidence of that in their debug logs in\nthe case of wasabi. In regards to samourai, as far as I know no\ncoordinator is operating, and whirlpool functionality has been removed\nfrom the fork that is still maintained.\n\nThat said, there also hasn't been much demand to actually fix these\nissues. They've been publicly documented for years.\n\n> -Overall Transparency: We need clear answers to questions such as: How are the residual funds calculated and allocated? Which wallet(s) are used? Ultimately, this information should be publicly verifiable on the blockchain.\n\nAs far as I know there are currently two compatible client\nimplementations, wasabi wallet and the btcpay coinjoin plugin. The\ntrezor feature was removed following the shutdown of the zksnacks\ncoordinator, as per\nhttps://blog.trezor.io/important-update-transitioning-from-coinjoin-in-trezor-suite-9dfc63d2662f\n\nIt's not verifiable on the blockchain. To the extent that on chain\ndata can be inferred, liquisabi.com provides estimate, but it's just a\nlikely interpretation (in that it's consistent with well known\nbehavior of the client and backend implementations), not proof,\nalthough there's no reason to doubt this information (see earlier in\nthe thread re acknowledgement of the figures' accuracy).\n\nThe source code for these clients is readily available, and has been\nthroughout. Backend code is also available, but it is not possible to\nverify what software",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 1,
            "text_length": 2094,
            "has_nack": true,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "Re: [bitcoindev] New Proposal：String Substring Search in Bitcoin Script - OP_ISSUBSTR",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/Z_VlNPeDS8Hk3Dyy@erisian.com.au",
          "title": "Re: [bitcoindev] New Proposal：String Substring Search in Bitcoin Script - OP_ISSUBSTR",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Wed, 9 Apr 2025 04:04:36 +1000",
          "body": "On Tue, Apr 01, 2025 at 12:25:26PM +0000, Pieter Wuille wrote:\n> On Monday, March 31st, 2025 at 4:41 PM, Javier Mateos <javierpmateos@gmail•com> wrote:\n> > The solution of splitting the string and using OP_CAT only works if the exact position of the substring is known. How would a case be handled where the substring could be in any position\n> Whoever produces the signature/witness for spending the coin always knows the position already, so the script can always be modified to instead take that position as an additional input.\n> This is a general principle: the point of scripts is verifying provided information, not computing it. As another example, this means that there is no need for a division or square root opcode if one has a multiplication opcode.\n\nI somewhat disagree with this: there are some concerns that are *easier*\nto express with different opcodes, and I think that's a factor worth\nconsidering.\n\nThis came up with the OP_CAT based proof-of-work faucet [0] -- the\nidea there is that you provide a signature and some nonce data, and\nwhen you combine the two and hash the result, that result begins with\nsome sufficient number of 0 bits (that then gets related back to a\nCHECKSEQUENCEVERIFY delay).\n\nOP_CAT is *sufficient* for testing this, because you just CAT the\nsignature and nonce together and hash them, and can then again CAT the\nthe 0-bits you expect together with some other data and check that all\nof those combined match the hash you calculated earlier.\n\nBut it would be more efficient, and a little easier to code, if you\ncould instead have used SUBSTR/LEFT to pull the initial bytes from\nthe calculated hash and check that those have the expected number of\nleading 0-bits. More efficient, because you don't have to supply all\nthe trailing bytes of the hash in the witness, and easier to code,\nbecause it's a bit more natural to think of manipulating the hash you\ncalculated, rather than having to put user-provided data together and\ncheck that that actually matched ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2086,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] secp256k1lab: a Python library for prototyping",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/d0044f9c-d974-43ca-9891-64bb60a90f1f@gmail.com",
          "title": "[bitcoindev] secp256k1lab: a Python library for prototyping",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Tue, 1 Apr 2025 08:41:37 +0000",
          "body": "Hello list,\n\nWe're pleased to announce the initial release of secp256k1lab, an INSECURE\nimplementation of the secp256k1 elliptic curve and related cryptographic schemes\nwritten in Python, intended for prototyping, experimentation and education.\n\nhttps://github.com/secp256k1lab/secp256k1lab\n\nFeatures:\n\n- Low-level secp256k1 field and group arithmetic.\n- Schnorr signing/verification and key generation according to BIP-340.\n- ECDH key exchange.\n\nWe developed secp256k1lab as part of our work on the ChillDKG work-in-progress\nBIP [0]. It is based on the secp256k1 implementation in the Bitcoin Core test\nframework.\n\nOur goal was to avoid including yet another custom Python implementation of the\nsecp256k1 curve in the ChillDKG reference code. Several existing BIPs (340, 324,\n327, and 352) already contain custom and sometimes subtly diverging\nimplementations of secp256k1. This library aims to provide a single, consistent\ninterface for secp256k1-related cryptographic specifications.\n\nAt the moment, secp256k1lab is included in the ChillDKG repository as a subtree.\nIt remains an open question what would be the best approach for including ChillDKG\n(with the secp256k1lab dependency) into the bips repository [1].\n\nWe welcome your feedback and contributions to this project.\n\nBest regards,\nThe current secp256k1lab maintainers: Sebastian Falbesoner, Jonas Nick, Tim\nRuffing\n\n[0] https://github.com/BlockstreamResearch/bip-frost-dkg\n[1] https://groups.google.com/g/bitcoindev/c/HE3HSnGTpoQ/m/Y2VhaMCrCAAJ\n     (We renamed secp256k1proto to secp256k1lab)\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/d0044f9c-d974-43ca-9891-64bb60a90f1f%40gmail.com.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 1985,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: secp256k1lab: a Python library for prototyping",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a378e1a6-3e0b-4c55-a6fb-58099eb97798@gmail.com",
          "title": "Re: [bitcoindev] Re: secp256k1lab: a Python library for prototyping",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Mon, 7 Apr 2025 19:16:37 +0000",
          "body": "Hi AdamISZ/waxwing,\n\nI discussed with the maintainers, and we do consider MuSig2 and adaptor\nsignatures to be in-scope. However, we don't currently plan to proactively add\nthese features ourselves.\n\nThe reason the library currently contains an implementation of BIP 340 and not\nonly raw elliptic curve operations is that we use BIP 340 in the ChillDKG\nreference code. So if there is demand to specify a scheme that is based on\nMuSig2 or adaptor signatures, then a similar reasoning would apply. MuSig2 would\nbe particularly easy to add because it already has a python reference\nimplementation and test vectors.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/a378e1a6-3e0b-4c55-a6fb-58099eb97798%40gmail.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1048,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    }
  ],
  "summary": {
    "total_threads": 42,
    "total_messages": 44,
    "unique_participants": 30
  }
}