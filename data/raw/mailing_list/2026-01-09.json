{
  "source": "mailing_list",
  "list": "bitcoin-dev",
  "fetched_at": "2026-01-16T00:47:14.531883+00:00",
  "date": "2026-01-09",
  "threads": [
    {
      "title": "Re: [bitcoindev] Bitcoin Core v30.2rc1 Released",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-Zqn7xxzGLwAHVV3fNC9SOehH54Q3XqO3qJZpQ6F2yXzSQ@mail.gmail.com",
          "title": "Re: [bitcoindev] Bitcoin Core v30.2rc1 Released",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Sat, 10 Jan 2026 00:03:58 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3790 bytes --]\n\nThe biggest contributions in this release (v30.2) comes from the user (\n*jestory*) who reported the bug and *davidgumberg *who confirmed it also\nexists in the bitcoin-wallet tool.\n\nBoth are missing from the credits section. Although I am not sure if\nreviews, testing etc. is considered a contribution.\n\n/dev/fd0\nfloppy disk guy\n\nOn Fri, Jan 9, 2026 at 5:27 PM fanquake <fanquake@gmail•com> wrote:\n\n> Bitcoin Core version v30.2rc1 is now available from:\n>\n>   <https://bitcoincore.org/bin/bitcoin-core-30.2/test.rc1>\n>\n> This release includes new features, various bug fixes and performance\n> improvements, as well as updated translations.\n>\n> Please report bugs using the issue tracker at GitHub:\n>\n>   <https://github.com/bitcoin/bitcoin/issues>\n>\n> To receive security and update notifications, please subscribe to:\n>\n>   <https://bitcoincore.org/en/list/announcements/join/>\n>\n> How to Upgrade\n> ==============\n>\n> If you are running an older version, shut it down. Wait until it has\n> completely\n> shut down (which might take a few minutes in some cases), then run the\n> installer (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on\n> macOS)\n> or `bitcoind`/`bitcoin-qt` (on Linux).\n>\n> Upgrading directly from a version of Bitcoin Core that has reached its EOL\n> is\n> possible, but it might take some time if the data directory needs to be\n> migrated. Old\n> wallet versions of Bitcoin Core are generally supported.\n>\n> Compatibility\n> ==============\n>\n> Bitcoin Core is supported and tested on operating systems using the\n> Linux Kernel 3.17+, macOS 13+, and Windows 10+. Bitcoin\n> Core should also work on most other Unix-like systems but is not as\n> frequently tested on them. It is not recommended to use Bitcoin Core on\n> unsupported systems.\n>\n> Notable changes\n> ===============\n>\n> ### Wallet\n>\n> - #34156 wallet: fix unnamed legacy wallet migration failure\n> - #34215 wallettool: fix unnamed createfromdump failure wal",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2048,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Follow-up regarding Motion to Activate BIP 3",
      "message_count": 1,
      "participants": [
        "Chris Stewart"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAGL6+mHiDBzcBp-2Bos33iKYNEN+RbgLKuD9+MF=GxPDETnz7w@mail.gmail.com",
          "title": "Re: [bitcoindev] Follow-up regarding Motion to Activate BIP 3",
          "author": "Chris Stewart <stewart.chris1234@gmail@com>",
          "date": "Thu, 8 Jan 2026 14:40:59 -0600",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2745 bytes --]\n\nI think there is a rough consensus for BIP3.\n\nOn Tue, Jan 6, 2026 at 6:53 PM Murch <murch@murch•one> wrote:\n\n> Dear colleagues,\n>\n> In early November, I asked whether there was support for adopting BIP 3\n> as the guideline for the BIPs Process.\n>\n> In response, about a dozen respondents stated support for activating\n> BIP 3. Some respondents raised concerns that resulted in changes to the\n> BIP or otherwise were addressed here on the mailing list. The adopted\n> changes were summarized here on the mailing list (see\n> https://groups.google.com/g/bitcoindev/c/j4_toD-ofEc/m/esV-XScYAAAJ). A\n> few respondents seemed to imply general support, but requested reversal\n> of the recently introduced LLM-policy, which has since been implemented.\n> As there was no further follow-up to raised concerns in over three\n> weeks, I posit that the concerns have been addressed satisfactorily.\n>\n> In detail, Ava Chow, David Gumberg, Jon Atack, Jonas Nick, Gloria Zhao,\n> Michael Ford, Ruben Somsen, Greg Sanders, and Antoine Poinsot explicitly\n> stated support for activating BIP 3 before the amendment.\n> Pieter Wuille supported activation conditional on the reversal of the\n> LLM-guidance.\n> Concerns by David Harding, Luke Dashjr, and Melvin Carvalho have been\n> addressed.\n> The amended proposal has been explicitly endorsed (again) by AJ Towns,\n> Tim Ruffing, and Pol Espinasa after the December 15th update.\n>\n> It is my perception that among those that commented, support for\n> activation significantly outweighed rejection, and that all concerns\n> have been addressed. As Melvin Carvalho pointed out, that I, as the\n> Author of the proposal, should not be the one to assess whether BIP 3\n> has rough consensus. I therefore request that others, especially\n> participants in the BIPs process, comment on whether they perceive there\n> to be rough consensus for activating BIP 3.\n>\n> Thanks,\n> Murch\n>\n> --\n> You received this message because you ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2062,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] BIP Idea: incrementalrelayfee in feefilter?",
      "message_count": 1,
      "participants": [
        "\"Matthew Husák\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a02be21c-2483-4753-b6db-4bd159e8c4e0n@googlegroups.com",
          "title": "Re: [bitcoindev] BIP Idea: incrementalrelayfee in feefilter?",
          "author": "\"Matthew Husák\" <matejocraftak@gmail@com>",
          "date": "Thu, 8 Jan 2026 10:13:05 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 5032 bytes --]\n\nHi Murch!\n\nthanks for such quick response.\n\nI think that we've been one of the first wallets to support such lower \nfees, so we faced the initial \"pain\" to find peers with the lower \nminrelaytxfee. That kinda made me feel that this has to change, because \nwhen we solved the peers config (with our desired minrelaytxfee setting) we \nrealized that many nodes (before the update)  forgot to change the \nminincrementalfee policy and since you can't check for peer's \nminincrementalfee it makes the adoption even harder, because it's almost \nimpossible to find peers on your own (you could sign a RBF tx bumped up to \nfee under 1sat/vb and try to send it to different peers, but thats far from \nideal :-D).\n\nI'm not sure if lowering the defaults will ever happen again, but I believe \nthat you should be able to see under what conditions other nodes relay, so \nthat you don't spam them with tx they don't want and so that the adoption \nis easier.\n\nI haven’t seen BIP 153 before, so I’ll read it and try to understand it. \nThat said, I have two ideas: the simplest is to expose \n incrementalrelayfee , and the second (I’d love your opinion on this) is \nadding the ability to configure the node to actively seek peers meeting \nspecific  minrelaytxfee  and  minincrementalfee  thresholds—since AFAIK it \ncurrently settles for ~10 outbound nodes of any config, this would let it \ntarget at least 2 high-quality peers with those minimums during discovery.\n\n(or I could be totally off with my ideas :-D but I hope its not that case)\n\nThanks!\nMatt\n\n\nDne středa 7. ledna 2026 v 20:54:11 UTC+1 uživatel Murch napsal:\n\n> Hi Matt,\n>\n> The feerate policy change was rolled out not just with the Bitcoin Core \n> 30.0 release, but also backported to Bitcoin Core 29.1. According to \n> e.g., Clark Moody’s dashboard, that means that over 30% of listening \n> nodes already use the lower incremental feerate (assuming they use the \n> default value). Per a quic",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2061,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Addressing remaining points on BIP 54",
      "message_count": 1,
      "participants": [
        "Matt Corallo"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/f68d7c20-5119-4159-8e42-f7c10597a789@mattcorallo.com",
          "title": "Re: [bitcoindev] Addressing remaining points on BIP 54",
          "author": "Matt Corallo <lf-lists@mattcorallo@com>",
          "date": "Thu, 8 Jan 2026 11:40:39 -0500",
          "body": "On 1/8/26 3:30 AM, Sjors Provoost wrote:\n> Hello Riard,\n> \n>> Thanks for the update. If I'm understanding correctly Luke's concern,\n>> currently the coinbase's scriptSig is used to store an extranonce. One\n>> has to observe first there is no consensus limit on the size of a\n>> transaction, which holds for the coinbase tx too, a fortiori there is\n>> no limit on the extranonce size a miner could fit in the scriptSig.\n> \n> \n> The coinbase scriptSig is limited to 100 bytes [0]. Some speculation as to\n> why [1].\n> \n> The main issue I see is complexity of implementation. The nLockTime is always\n> the last 4 bytes of a transaction, so an ASIC can roll it without having to\n> understand anything about serialisation.\n> \n> The scriptSig OTOH is variable length, so it needs to read the length byte in\n> order to figure out which 4 bytes are at the end. The pool or proxy then also\n> needs to ensure those 4 bytes are pre-initialised*.\n> \n> The approach suggested by Towns [4] of appending a 0-sat OP_RETURN output with\n> padding so a 4-byte nonce lands in the final 64-byte SHA256 chunk is probably\n> better, but not because like nLockTime it has a small hashing midstate\n> benefit. It's easier to implement.\n> \n> Compared to varying the end of the scriptSig, this can be easier for an ASIC\n> because it can update a fixed 4-byte field at a known offset from the end,\n> rather than having to parse variable-length fields (notably the scriptSig\n> length) to locate the bytes to roll.\n> \n> I think that extra complexity is doable and justifiable, but I've never built an ASIC.\n> \n> Note that today Stratum v1 simply splits the scriptSig [5] into two parts, as does\n> Stratum v2 [3], but presumably that's all done by the control board and it makes\n> sense to want to push rolling functionally into the ASIC silicon, where even\n> simple concatenation might be too involved - but updating bytes at known\n> positions is easy.\n> \n>> The point being made is that the nLocktime field of the coinbase\n>> transa",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2055,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: Addressing remaining points on BIP 54",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/05f5b0ee-b487-4733-9860-ac0705b6b901n@googlegroups.com",
          "title": "[bitcoindev] Re: Addressing remaining points on BIP 54",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Wed, 7 Jan 2026 20:29:28 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 9807 bytes --]\n\nHello Poinsot,\n\nThanks for the update. If I'm understanding correctly Luke's concern,\ncurrently the coinbase's scriptSig is used to store an extranonce. One\nhas to observe first there is no consensus limit on the size of a\ntransaction, which holds for the coinbase tx too, a fortiori there is\nno limit on the extranonce size a miner could fit in the scriptSig.\n\nThe point being made is that the nLocktime field of the coinbase\ntransaction could be used as a more efficient extra nonce due to\nthe positional location of nLocktime in a serialized coinbase being\none of the latest message block to be processed [0].\n\nNothing prevent a miner in already doing this and draw a speed advantage\nfrom the diminished computational work. I have not looked into CGminer code\nor one of its derivative forks, if there is an implemented option to do \nthat,\nbut yes there could be non-published existing mining firmware doing it. \nIIUC,\nBIP54 would nullify this theoretical \"speed advantage\" for all miners.\n\nNow, there could be an argument ecosystem-wise to let the nLocktime free,\nas who say speed advantage say less energy consumed network-wide (-- but\nisn't that a better outcome to maximize the energy burnt network-wide, even\nif it's probabilistic ?).\n\nOne alternative design would be to store the height commitment in the\ncommitment extension introduced by BIP141 [1]. In my understanding, as\nit has been pointed out by other minds in the design process about the\nactual proposal to put the height commitment in the nLocktime field, \nin the eventuality of more than 1 commitment being introduced, a naive\ndesign would come with the burden for non-upgraded nodes to have data\navailability to all the merkle path to validate a specific soft-forked\ncommitment. So a node could not just implement consensus validation rules\nfor SF #2, without getting the merkle tree data for SF #1.\n\nIt doesn't sound that this concern could be alleviated by making the",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2055,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Wallet Migration Failure May Delete Unrelated Wallet Files In Bitcoin Core 30.0 and 30.1",
      "message_count": 1,
      "participants": [
        "\"'Ava Chow' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/f498b9ad-c3e1-40bb-8325-4df6bbf74cd7@achow101.com",
          "title": "[bitcoindev] Wallet Migration Failure May Delete Unrelated Wallet Files In Bitcoin Core 30.0 and 30.1",
          "author": "\"'Ava Chow' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Mon, 05 Jan 2026 20:38:23 +0000",
          "body": "Hi all,\n\nWe have become aware of a wallet migration bug introduced in Bitcoin \nCore 30.0 and 30.1. Under rare circumstances, when the migration of a \nwallet.dat file fails, all files in the wallet directory may be deleted \nin the process, potentially resulting in a loss of funds. A fix is \nforthcoming and will be released as 30.2, but out of an abundance of \ncaution we have removed the binaries for affected releases from \nbitcoincore.org.\n\nAt this time, we ask users to not attempt wallet migrations using the \nGUI or RPC until v30.2 is released. All other users, including existing \nwallet users, are unaffected and can keep using existing installations.\n\nSpecifically, it requires the presence of a default (unnamed) wallet.dat \nfile, which has not been created by default since 0.21 (released 5 years \nago), that fails to be migrated or loaded. One condition that may \ntrigger this is when pruning is enabled, and the wallet was unloaded \nwhile pruning happened.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/f498b9ad-c3e1-40bb-8325-4df6bbf74cd7%40achow101.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1444,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Funding model question — unpaid exploratory work at intake",
      "message_count": 1,
      "participants": [
        "Chris Stewart"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAGL6+mFqwC8ySFs3A0xQSzyhqYa+5EH1_q5cBmvGCeu57KHqEg@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: Funding model question — unpaid exploratory work at intake",
          "author": "Chris Stewart <stewart.chris1234@gmail@com>",
          "date": "Sat, 3 Jan 2026 07:32:29 -0600",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5626 bytes --]\n\nHi Able One,\n\nI think this is an interesting topic. Over the past few years, I’ve been\nworking intermittently on proposals for 64-bit arithmetic [0] and amount\nlocks [1], which I think fall squarely into this category.\n\nIf I were sitting on a grant committee, I would want to see soft-fork\nproposals designed as modular components that can be reused as part of\nlarger soft forks. When the same functionality is reimplemented across\nmultiple proposals, that’s usually a strong signal that the feature is\nbroadly needed.\n\nThe work I cited above was inspired by the OP_TAPLEAFUPDATEVERIFY soft-fork\nproposal [2]. I deconstructed that larger proposal into smaller,\nindependent pieces. Two of those pieces were:\n\n   -\n\n   Adding 64-bit arithmetic to Script to properly handle satoshi amounts,\n   and\n   -\n\n   Introducing an opcode (OP_INOUT_AMOUNT) to push amounts onto the stack.\n\nAfter doing this, I realized that there are several other proposals in the\nspace that could reuse this same functionality [3][4][5].\n\nBecause of this, I think funding work on small, reusable components that\ncan be composed into “larger” soft forks could be both useful and\ninteresting.\n\nBelow are objective milestones that a grantee could complete, with funds\ndisbursed at each stage. Some of these milestones I’ve already achieved\nwith the cited proposals; others are still TODO:\n\n*Level 1:* Implement the proposal in a language of choice (Python, C++,\nRust, etc.).\n*Level 2:* Write a BIP describing the soft-fork proposal.\n*Level 3:* Implement the BIP in the latest Bitcoin Core release, including\nPython and/or C++ test cases.\n*Level 4:* Produce static test vectors for the BIP [6] and integrate them\ninto a second Bitcoin implementation (e.g., btcd, bitcoin-s, bcoin).\n*Level 5:* Validate the proposal by using it *inside* larger soft-fork\nproposals. This would involve forking existing soft-fork code, removing the\noriginal implementation of the relevant feat",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Bitcoin Core v30.1 Released",
      "message_count": 1,
      "participants": [
        "fanquake"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/d53934c0-39fd-41e9-b507-41ea0389cdecn@googlegroups.com",
          "title": "[bitcoindev] Bitcoin Core v30.1 Released",
          "author": "fanquake <fanquake@gmail@com>",
          "date": "Fri, 2 Jan 2026 08:07:31 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3450 bytes --]\n\nBitcoin Core version v30.1 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-30.1/>\n\nThis release includes new features, various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has \ncompletely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on \nmacOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL \nis\npossible, but it might take some time if the data directory needs to be \nmigrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and tested on operating systems using the\nLinux Kernel 3.17+, macOS 13+, and Windows 10+. Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them. It is not recommended to use Bitcoin Core on\nunsupported systems.\n\nNotable changes\n===============\n\n### Wallet\n\n- #33528 wallet: don't consider unconfirmed TRUC coins with ancestors\n\n### Build\n\n- #33580 depends: Use `$(package)_file_name` when downloading from the \nfallback\n- #33906 depends: Add patch for Windows11Style plugin\n- #32009 contrib: turn off compression of macOS SDK to fix determinism\n\n### IPC\n\n- #33229 multiprocess: Don't require bitcoin -m argument when IPC options \nare used\n- #33517 multiprocess: Fix high overhead from message logging\n- #33519 Update libmultiprocess subtree in 30.x branch\n- #33566 miner: fix empty mempool case for waitNext()\n- #33676 interfaces: enable cancelling running wai",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2041,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] BIP idea: Timelock-Recovery storage format",
      "message_count": 1,
      "participants": [
        "\"'Oren' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/8fefdd9e-8c71-4e11-9d90-ebbd8e25dc56n@googlegroups.com",
          "title": "[bitcoindev] BIP idea: Timelock-Recovery storage format",
          "author": "\"'Oren' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sun, 28 Dec 2025 06:21:48 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3114 bytes --]\n\nReposting here from BitcoinTalk \n<https://bitcointalk.org/index.php?topic=5569543.0>:\n\nAfter a short talk with Ava Chow during BTC++ Taiwan, I'm starting this \nthread to discuss whether my idea is BIP-worthy.\n\nMotivation for Timelock-Recovery plans:\nStoring seeds for recovery & inheritance is scary.\nPre-signed transactions to a secondary-wallet/custodian, are safer to \nhandle and backup due to their immutability.\nA single pre-signed transaction with a future nLocktime requires \"renewal\" \nwhen the nLocktime deadline is getting close, which could be annoying (i.e. \nif the seed is split over multiple geographic locations).\nCovenants/Vaults are still being debated, and could scare less-technical \nBitcoiners.\n\nSolution:\nPre-signing a pair of transactions:\n• Alert/Initiate Transaction: A consolidation transaction that keeps most \nfunds on the original wallet (except for a minimal amount that goes to \nanchor-addresses, for CPFP acceleration)\n• Recovery Transaction: A transaction that moves the Bitcoin from the \nconsolidated UTXO to the secondary-wallet(s), with an nSequence \nrelative-locktime that gives the user enough time to move the funds \nelsewhere (assuming they noticed that the Alert transaction was mined, and \nstill have the seed or signed an alternative transaction in advance).\n\nSimilar to a single pre-signed transaction with a future nLocktime, \nTimelock-Recovery plans will not include new funds that are added to the \nwallet, and will be revoked even if a tiny amount is spent. This mechanism \nis intended for wallets that are going to remain untouched for a long time.\n\nAn example implementation can be found in the Timelock Recovery plugin that \nI've implemented for Electrum <https://electrum.org> (merged since Electrum \nv4.6.0b1). Details and demo videos can be found at: \nhttps://timelockrecovery.com.\nThe plugin creates a UI for signing the two transactions, then saving them \neither in a PDF file (with de",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2056,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: BIP idea: Timelock-Recovery storage format",
      "message_count": 1,
      "participants": [
        "\"'Oren' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/e76b2eda-aa34-4e47-816f-0ca5d5835ea8n@googlegroups.com",
          "title": "[bitcoindev] Re: BIP idea: Timelock-Recovery storage format",
          "author": "\"'Oren' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 1 Jan 2026 08:49:05 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 11529 bytes --]\n\nOne more thing to mention - none of the hardware wallets that I've tested \nshow the custom nSequence fields to the user, and only some show a custom \nnLocktime.\nThey just agree to sign whatever nSequence/nLocktime was in the PSBT, even \nif they it's not one of the common values (i.e. nSequence of 0xFFFFFFFD - \n0xFFFFFFFF).\nThis is an issue regardless of my BIP idea, because a malicious virus could \nmanipulate the nSequence field before sending it to the hardware wallet, \nmaking the user sign transactions that would seem corrupt when they try to \nbroadcast them, but will become valid in the future.\nJust as users may wish to verify that all pre-signed transactions are valid \nusing some custom testmempoolaccept, they may also want to verify the exact \nrelative-locktime (nSequence) value on their hardware wallet.\n\nI wrote a PR for Specter-DIY to show this information, and wish for other \nwallets to follow: https://github.com/cryptoadvance/specter-diy/pull/321\n\nRegards,\nOren\n\n\nOn Thursday, January 1, 2026 at 6:22:40 PM UTC+2 Oren wrote:\n\n> Hi AdamSZ, list,\n> Thanks for showing interest in the BIP and happy new year.\n>\n> > Btw, do you think you should address directly the philosophy found in \n> Liana, and what setups they have decided to expose? (i.e. what's the delta, \n> here).\n> Yes, I think it's a good idea to talk about the advantages and \n> disadvantages of pre-signed transactions vs script-based wallets. I'll add \n> it to the Motivation section.\n>\n> > Should the BIP actually be something with more flexibility in \n> transaction structure, so as to cover more use-cases?\n> I think it's good to limit the structure of the transactions, so that \n> different services could easily integrate this feature.\n> One guy that I talked to suggested building a more sophisticated sequence \n> of transactions with multiple wallets, for example that after 90 days the \n> Bitcoin will move to his wife's wallet, from which there",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2060,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] The Cat, BIP draft discussion.",
      "message_count": 1,
      "participants": [
        "Greg Maxwell"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAAS2fgQLKD1-DomvniTHLTvw52yeaKmOG-K__TnZeYJ+c2hYFA@mail.gmail.com",
          "title": "Re: [bitcoindev] The Cat, BIP draft discussion.",
          "author": "Greg Maxwell <gmaxwell@gmail@com>",
          "date": "Mon, 15 Dec 2025 16:04:27 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 8747 bytes --]\n\nOn Mon, Dec 15, 2025 at 10:35 AM Nona YoBidnes <pepehodler@gmail•com> wrote:\n\n> Here, your argument runs completely opposite of the claim that \"the miner\n> fees are the filter\". You appear to be claiming that dping nothing about\n> spam, making it easier for spammers and being more accommodating to them is\n> the way to go. Unfortunately, that's the approach we have taken for the\n> last 3 years while spam only gets worst.\n>\n\nOn what basis do you claim that spam has 'only gotten worse'--  the\nexisting setup is incredibly effective against spam, essentially blocking\nall forms of pointless data storage that aren't made more valuable by the\nlimitations.  What does go in, goes in at extremely high costs to the\nspammer.\n\nOf what concern is this residual traffic to Bitcoin use?  It doesn't\nincrease node resource use as that's governed by the capacity limits, in\nfact because it's generally much easier to process it speeds up block\nprocessing.  It's substantially a non-issue.\n\nThe proposed gain is some negligible one time reduction in utxo disk space.\n>\n>\n> Between 40 and 50% of the UTXO set is comprised of spam UTXOs with dust\n> amounts. Even more conservative estimates put it at 30%. The Cat would\n> remove those spam NMUs from the UTXO set. I hardly view that as negligible.\n>\n\nIt is negligible-- it's just a one time constant fraction.  It will not\nincrease the set of devices that can run a node in any meaningful sense.\nWhat improvement it provides could also be alternatively achieved through\nlocal only technical changes like changing how the data is stored.\n\nFurthermore, The Cat would send a strong signal to spammers: you are not\n> welcomed on Bitcoin, we are rugging you, and we might do it again. This\n> likely would reduce future spam activity on Bitcoin, further protecting the\n> UTXO set.\n>\n\nAs I've pointed out, it won't stop their NFTs.  They'll simply make a new\nrule in their NFT indexers that says that deleted N",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2048,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: The Cat, BIP draft discussion.",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/c87a50a4-1a1b-4aee-bc1f-bd1c91d675d1n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: The Cat, BIP draft discussion.",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Tue, 30 Dec 2025 06:36:26 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 22054 bytes --]\n\nHi list,\n\n> Which brings me to my disagreement, which I know is not shared by a \nnumber of contributors here: just as it is hard to define spam on Bitcoin, \nit's also very hard to define it in a discussion forum like this one. \nMaking suggestions which *I* think are terrible, or detrimental, on a list \nlike this, should never be disallowed here. Notions of motivation of \ncontributors (such as they are paid by such and such a company) should not \nbe relevant. Everything should be open to discussion which is \nimplementation-technical (so obviously not e.g. threats of violence or \nthings that bring legal liability to participants or have zero relevance to \nBitcoin's technical development) even if it's philosophy-motivated. And \nblocking should be reserved either as an anti-DOS measure if volume gets \nout of control, or if it brings dangers as per the previous parenthetical.\n\nI'm fully sharing waxwing reasonable opinion. While I can understand gmax's \nsentiment being fed\nup with poor coin confiscation proposals again and again on the mailing \nlist, the cure would be\nworst than the disease. Maybe, I'm very voltairean here, but you don't \nfight ill-founded opinions.\nby persecuting their authors (--otherwise, down the road you take the risk \nof seeing the bastille\npopped up). Rather than you fight them back by doing the work to persuade \nand to convince those\nideas you find stupid are indeed *objectively* stupid.\n\nTo me, it's a sign of strength and confidence that Bitcoin and its \ndevelopment process can\nwithstand and endure the most \"outrageous\" controversies. For sure, I have \nbeen enough times\nin the shoes of someone who has to champion controversial changes (cf. \n`mempoolfullrbf`) to not\nnegate that the strength of the process is kinda traded on the back of the \ndevs, but this is not\naltering my mind on what I think should be *ideally* the development \nprocess in terms of openess\nand publicity.\n\nMy humble op",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2052,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Unbreaking testnet4",
      "message_count": 1,
      "participants": [
        "Saint Wenhao"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CACgYNOLc=c5jx8jWGbCczKkLhPNq_+gLNxKi3Tf50-oPQhWuRQ@mail.gmail.com",
          "title": "Re: [bitcoindev] Unbreaking testnet4",
          "author": "Saint Wenhao <saintwenhao@gmail@com>",
          "date": "Thu, 25 Dec 2025 08:21:00 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4402 bytes --]\n\n> The given rationale for a difficulty reset was to let developers\noccasionally mine blocks on their laptop.\n\nThis rationale is partially solved by Signet faucets. Miners constantly\nsweep coins from signet addresses like\ntb1pruektj90gg8nysa7yuk07w7ucwlywrf4p02lq3sz49f05xd00djscyt2fw,\ntb1pffsyra2t3nut94yvdae9evz3feg7tel843pfcv76vt5cwewavtesl3gsph, or\ntb1pf2v25yk7m8mv203pvjusmk2a8r6tu8p59nhvwux86ck3s3pp0nkqt30dvt.\n\nThe only missing thing, is buying a given coinbase transaction, or block,\nby a given user. Because now, it is centralized in the hands of signet\ncreators. However, if it would be possible to pay the same or greater\namount, as set in the coinbase transaction (which now means 25 sBTC or\nmore) and be rewarded with some block, or coinbase transaction, then it\nwould pretty much cover it.\n\nBecause when it comes to being rewarded, it is covered by the mining\nfaucet. The only missing part is the control, related to manually\nconstructing a block. As far as I know, this is the only case, where\ntesters need to switch from signet to testnet: to test some aspects of\nmining.\n\n> I propose to fix this by removing the difficulty reset rule from testnet4\nthrough a flag day hard fork on 2026-01-01.\n\nThis date is quite close. Even if we add a week or two, it is quite likely,\nthat either something will be deployed in the nearest future, or it won't\nhappen at all, and we will be stuck with what we have.\n\nFor now, I switched from testnet4 to signet, but I wonder, how it will turn\nout.\n\nAlso, using some constructions, based on OP_CAT, or something similar, may\nbe enough, to mine both at the same time, through Merged Mining. Which\nwould then mean, that people could try to mine testnet4 blocks, and also\nhit signet coins from faucets, with the same power.\n\npon., 31 mar 2025 o 22:50 'Antoine Poinsot' via Bitcoin Development Mailing\nList <bitcoindev@googlegroups.com> napisał(a):\n\n> Good point on not having the flag day on a hol",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2037,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Hash-Based Signatures for Bitcoin's Post-Quantum Future",
      "message_count": 1,
      "participants": [
        "Olaoluwa Osuntokun"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAO3Pvs_cetTGP54zDzJJGRPeN7gXrRYGZZYk4mRYnhJQnwotdA@mail.gmail.com",
          "title": "Re: [bitcoindev] Hash-Based Signatures for Bitcoin's Post-Quantum Future",
          "author": "Olaoluwa Osuntokun <laolu32@gmail@com>",
          "date": "Tue, 9 Dec 2025 16:41:48 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 13469 bytes --]\n\nHi y'all,\n\nconduition wrote:\n> I'm personally hoping that we'll find a way to derive child pubkeys using\n> lattices (ML-DSA) and/or isogenies (SQIsign), but I haven't heard of any\n> solid proposals yet.\n\nThis paper [1] proposes a variant of Dilithium (dubbed DilithiumRK, RK for\n'randomized keys' presumably) that enables BIP-32-like functionality. It\nachieves this by getting rid of a public key compression step in the OG\nalgorithm that results in a loss of homomorphic properties. There're\nalgorithmic changes required (eg: a new public network param is needed\nwhich is used for seed/key generation), so it isn't vanilla FIP 204.\n\nAside from the deviation from the standard, the scheme introduces some\nadditional trade offs:\n\n  * Signatures arger as signatures carry a new error hint\n\n  * Signing is 2.7x slower\n\n  * Verification is 1.75x slower\n\nThere's also a published BIP-32-like like scheme for Falcon signatures [2].\nI'm\nless familiar with the details here, but the signature size blows up to\n~24KB compared to ~666 bytes for normal Falcon signatures.\n\n-- Laolu\n\n[1]: https://cic.iacr.org/p/2/3/3\n\n[2]: https://link.springer.com/article/10.1186/s42400-024-00216-w\n\n\nOn Mon, Dec 8, 2025 at 10:49 PM 'conduition' via Bitcoin Development\nMailing List <bitcoindev@googlegroups.com> wrote:\n\n> Great work Jonas and Mikhail, glad to see more eyes and ears surveying\n> these schemes and their potential. Also shameless plug for some of my\n> prior work <https://conduition.io/code/fast-slh-dsa/> on related topics\n> <https://conduition.io/cryptography/quantum-hbs/>.\n>\n> The post-quantum HD wallet derivation problem is one i've been thinking\n> about a lot lately. Due to the lack of algebraic structure in SLH-DSA it's\n> gonna be impossible to fully emulate BIP32 with that scheme alone. I'm\n> personally hoping that we'll find a way to derive child pubkeys using\n> lattices (ML-DSA) and/or isogenies (SQIsign), but I haven't heard of any\n",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2073,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Hash-Based Signatures for Bitcoin's Post-Quantum Future",
      "message_count": 1,
      "participants": [
        "david torrealba"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/769f97ee-7874-44cd-acdd-a9d283f79430n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: Hash-Based Signatures for Bitcoin's Post-Quantum Future",
          "author": "david torrealba <davidtorrealba123@gmail@com>",
          "date": "Wed, 24 Dec 2025 07:02:21 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3570 bytes --]\n\n\n\nHi everyone,\n\nI've been following the discussion regarding the trade-offs of Post-Quantum \nsignature sizes and their performance impacts on low-power devices.\n\nI wanted to share some practical insights from the *Cellframe* project that \nmight be relevant to these benchmarks. We have been running a C-based \nblockchain implementation that natively supports multiple NIST-candidate \npost-quantum algorithms (including *Crystal-Dilithium/ML-DSA* and others \ndiscussed here) for several years.\n\nSince our core is written in C with a focus on hardware optimization \n(specifically targeting low-end embedded devices alongside high-performance \nnodes), we have gathered significant real-world data regarding:\n\n   1. \n   \n   Memory Footprint: The actual dynamic RAM usage differences between \n   Lattice-based vs. Hash-based signatures on constrained hardware.\n   2. \n   \n   Verification Time*:* Concrete signing/verification times on low-power \n   ARM architectures when the code is highly optimized in C.\n   \nIf the working group is interested, we would be happy to share our \nbenchmarks and optimization techniques to help validate the theoretical \nconstraints currently being discussed for Bitcoin's PQ transition. We \nbelieve our experience dealing with the signature size overhead in a live \nproduction environment could provide a useful reference point.\n\nBest regards,\n\nEl sábado, 20 de diciembre de 2025 a las 8:04:18 UTC-4, Erik Aronesty \nescribió:\n\n> this scheme has no mitm attack or replay attack because of the use of \n> covenants to secure each step in the chain\n>\n> The best part about starting with something like this is that we can have \n> a safe quantum vault, too useful covenants that are broadly helpful for \n> other vaulting schemes, while we develop a proper library that is both \n> performant and efficient for quantum signatures.  \n>\n> secp256k1 has been optimized to the point where timing attacks are \n> challenging,",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] QRMVL: Modular Verification Layer for Post-Quantum Hash-Based Signatures",
      "message_count": 1,
      "participants": [
        "Karin Eunji"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/3f2c308b-13c2-47c9-b39e-861236601476n@googlegroups.com",
          "title": "[bitcoindev] QRMVL: Modular Verification Layer for Post-Quantum Hash-Based Signatures",
          "author": "Karin Eunji <karin.blockdev@gmail@com>",
          "date": "Tue, 23 Dec 2025 23:10:59 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3243 bytes --]\n\nHi all,\n\nRegarding the recent discussion on commit-based approaches:  \nI agree with the general direction. Using commitments at each stage \nnaturally prevents MITM-style substitution and eliminates replay attacks by \nconstruction. As several participants noted, this makes it a safer and more \nincremental starting point than moving directly to full quantum-safe \nsignature\nschemes.\n\nOne strength of beginning with a commit-and-reveal path is that it allows \nthe ecosystem to develop a quantum-resilient vault mechanism and a broadly \nuseful covenant primitive without introducing\npremature trust assumptions. It also provides time to build a well-audited, \nperformance-optimized\nlibrary for quantum-safe commitments before addressing the much more \ncomplex migration to PQ\nsignatures.\n\nBy comparison, quantum-safe signature libraries are not yet engineered \nanywhere near the maturity\nof secp256k1, which is optimized to the point where timing side channels \nare extremely difficult to\nexploit. Moving too quickly toward full PQ signatures seems unnecessary at \nthis stage.\n\nIn parallel with this discussion, I have been working on a complementary \nframework focusing on the\nverification bottlenecks and scalability issues of hash-based PQ signatures \nin Bitcoin. The design,\ncalled **QRMVL (Quantum-Resilient Modular Verification Layer)**, aims to \nprovide a soft-fork–compatible,\nincremental path toward PQ validation while preserving current validation \nsemantics.\n\nKey components of QRMVL include:\n• Hybrid hash-based signatures (stateful LMS + stateless SPHINCS+)  \n• A STARK-style Linear Hash Tree (LHT) enabling parallelizable Merkle \nverification  \n• Deterministic UTXO-bound LMS index to avoid state-reuse problems  \n• A fail-fast node pipeline designed to reduce PQC DoS exposure  \n• Tiered P2PQS levels (Lite / Standard / High)  \n• Fully backward-compatible witness extensions (v2/v3) with no txid \nmodifications  \n\nResources \n",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 2,
            "text_length": 2086,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] [BIP Proposal] Add sp() output descriptor format for BIP352",
      "message_count": 1,
      "participants": [
        "Sebastian Falbesoner"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/59b1879d-b43d-41ac-9b3e-3e65cf31d4e5n@googlegroups.com",
          "title": "Re: [bitcoindev] [BIP Proposal] Add sp() output descriptor format for BIP352",
          "author": "Sebastian Falbesoner <sebastian.falbesoner@gmail@com>",
          "date": "Mon, 22 Dec 2025 12:47:10 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 20224 bytes --]\n\nHi Craig,\n\na few comments about the cost of label scanning, as this topic comes up\nrepeatedly:\n\n> The problem with this approach is that scanning for each additional label\n> adds incrementally and non-trivially to the computational burden.\n\nI think this statement is a misconception or at best only half of the truth,\nlikely based on the assumption that all existing and future SP wallets would\nimplement scanning using the same method.\n\n> For each label, there is an EC point addition and comparison against all\n> taproot outputs for an eligible transaction.\n\nIterating through labels and calculating taproot outputs to match for is \nonly\none way to implement scanning. Another one, as laid out in BIP-352 [1], is \nto\ndo it backwards: for each taproot output, subtract the output candidate and\ncheck if the result is in the label cache. One advantage of this approach is\nthat its scanning cost is independent of the number of labels to scan for, \nas\nthe lookup time in the cache is constant and efficient if a proper data\nstructure is used.\n\nTo prove that point, I've extended the scanning benchmark of the libsecp SP\nmodule PR #1765 [2] with an _actual_ label cache using a third-party hash\ntable implementation [3]:\nhttps://github.com/theStack/secp256k1/commit/f9f41adcedaca98aa4f3f65e2782e25b2124bf85\n\nThe scanning time is measured with three different label cache sizes: no\nentries (i.e. empty lookup function stub, no hash-map involved), one entry\n(\"tiny\"), and one million entries (\"huge\"). Running the benchmark for \nscanning\na transaction with 10 taproot outputs leads to the following output:\n\n$ ./build/bin/bench sp_scan_with_labels\nBenchmark                               ,    Min(us)    ,    Avg(us)    ,   \n Max(us)\n\nsp_scan_with_label_cache_empty_L=0      ,    61.3       ,    61.4       ,   \n 61.4\nsp_scan_with_label_cache_tiny_L=1       ,    61.6       ,    61.6       ,   \n 61.7\nsp_scan_with_label_cache_huge_L=1000000 ,",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Draft BIP: DustSweep – policy-only UTXO dust compaction",
      "message_count": 1,
      "participants": [
        "Defenwycke"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X8cJLJChvv3-QSGA8j5MVwgYxn1BAUeugTTgiqUWzEK_Q@mail.gmail.com",
          "title": "Re: [bitcoindev] Draft BIP: DustSweep – policy-only UTXO dust compaction",
          "author": "Defenwycke <cal.defenwycke@gmail@com>",
          "date": "Mon, 22 Dec 2025 19:33:01 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 16817 bytes --]\n\nHello Murch.\n\n\nThanks for taking the time to follow up and for spelling out the incentive\nconcerns so clearly.\n\n\nYou’re right - the recent reduction of the default minimum relay feerate to\n0.1 sat/vB materially changes the economic backdrop I was assuming. Under\nthose conditions, most consolidation is already cheap enough that a\nprotocol- or policy-level mechanism no longer makes sense, and the\nremaining friction is better addressed at the wallet/UX layer rather than\nthrough miner or relay rules.\n\n\nI agree with your point that Bitcoin policy should not rely on miners\nselling blockspace below market value, and that any mechanism that only\nencourages behavior without enforceable constraints is unlikely to be\njustified.\n\n\nI’m going to step back from this direction and reconsider the problem in a\ndifferent scope. I appreciate the careful read and the candid feedback. it\nwas helpful in clarifying where the real boundary lies.\n\n\nKind regards\n\n\nDefenwycke\n\n\n\nOn Mon, 22 Dec 2025 at 19:06, Murch <murch@murch•one> wrote:\n\n> Hi Defenwycke,\n>\n> You replied to every line of my email, except the most relevant one.\n>\n> Murch wrote:\n>  > All that said, at the new minimum feerate of 0.1 s/vB, a 148 vB P2PKH\n> input costs 15 sats, a 68 vB P2WPKH input costs 7 sats, and a 57.5 vB\n> P2TR input costs 6 sats.\n>\n> Your proposal prescribes an entire new class of transactions that are\n> managed by separate rules in a separate data structure. You propose to\n> charge 5 sats per input for those transactions, and prescribe that\n> miners should include such transactions even when they lose money by\n> doing so: at elevated feerates. Especially at high feerates, it is\n> irrational for miners to follow your proposal of selling blockspace\n> below value.\n>\n> This idea is made completely obsolete by the recent lowering of the new\n> minimum feerate. The most common inputs (P2WPKH) only cost <7 sats at\n> the new minimum feerate, and the ones th",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 3,
            "text_length": 2073,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Draft BIP: DustSweep – policy-only UTXO dust compaction",
      "message_count": 1,
      "participants": [
        "Defenwycke"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X8GtJtAgcvvPZW2Ovxt31CzGtn9tssqTSZ4BeQ_bL6pxg@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: Draft BIP: DustSweep – policy-only UTXO dust compaction",
          "author": "Defenwycke <cal.defenwycke@gmail@com>",
          "date": "Fri, 12 Dec 2025 20:17:28 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5466 bytes --]\n\nHello Jonathan,\n\nThanks for the thoughtful feedback — that makes sense.\n\nI started with a very narrow definition mostly to make the invariant\nobvious and easy to reason about. Every DustSweep tx should monotonically\nreduce the UTXO set and never meaningfully compete with the fee market. As\nlong as that holds, I’m not particularly attached to any one parameter.\n\nI agree that requiring 100% dust inputs and exactly one output is probably\noverly strict in practice. A majority dust requirement and an output/input\nratio cap seem like reasonable ways to preserve the incentive (net UTXO\nreduction) while making it more usable for real wallets.\n\nMy main goal here is to give operators something that’s safe to run and\npredictable in behaviour — cheap, bounded, and only active when blockspace\nwould otherwise go unused. I’m happy to adjust thresholds or relax\nconstraints as long as those properties remain intact.\n\nAppreciate you taking the time to look at it.\n\nKind regards,\n\nDefenwycke\n\nOn Fri, Dec 12, 2025 at 6:16 PM Jonathan Voss <k98kurz@gmail•com> wrote:\n\n> Interesting proposal. Something like that would be helpful, but perhaps it\n> would be more useful if it was not quite so narrowly defined. For example,\n> instead of requiring all inputs be dust-class UTXO, it could require a\n> minimum of 80% dust-class inputs; instead of exactly one output, it could\n> be max_outputs = floor(n_inputs / 5) to keep a maximum output/input ratio\n> of 1/5. This could allow for better aggregation of dust outputs into\n> economically meaningful, monetary outputs than the narrower definition\n> while maintaining the incentives for meaningfully reducing UTXO set size.\n>\n> I would run this policy on my node. Hashers should ultimately be okay with\n> this policy since someone among them also has to run full nodes, and it\n> would provide an additional (albeit very small) fee source when block space\n> demand is low.\n>\n> On Thursday, December 11, 20",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 3,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Major BIP 360 Update",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgK_kccO3SEfCZCJ6V2CCumE8+A5Ks5U31dgAoF_KcjP5A@mail.gmail.com",
          "title": "Re: [bitcoindev] Major BIP 360 Update",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Sat, 20 Dec 2025 21:05:45 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3551 bytes --]\n\nThis is amazing!  I have always been concerned about the exposure of public\nkeys (mostly because of the greater potential for implementation bugs, not\nquantum).\n\nBetween BIP360 and something like TXHASH, it's possible to make quantum\nsafe scripts and multi-step commit-reveal vaults that don't relay solely on\nsignatures at all.  And we can do so while closing broader security issues\n(allowing people to more easily mine for implementation flaws), and\nexpanding capabilities with lightweight, proven tech.\n\nI would personally love to move BIPs 360,119,346 forward as a comprehensive\n\"quantum-readiness\" plan.\n\nThese can keep Bitcoin safe and vaulted behind commitments and hashes...\nuntil the industry stabilizes on PQ signatures and an appropriately\nhardened, efficient, proven and reliabile library, like libsecp256k1 is for\nECC.  That is likely to take much longer, especially considering how\nrecently SIKE was broken, and the structural correlations found in SPHINCS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Fri, Dec 19, 2025, 6:32 PM Hunter Beast <hunter@surmount•systems> wrote:\n\n> After reviewing community feedback, Ethan Heilman and I have enlisted the\n> help of a third co-author, Isabel Foxen Duke\n> <https://x.com/isabelfoxenduke>, in an editorial role to lead and execute\n> a clean sheet rewrite of BIP 360.\n>\n> Because previous revisions introduced meaningful technical changes, we\n> determined that a full rewrite, rather than incremental edits, was\n> warranted to improve clarity, internal coherence, and to better articulate\n> our intentions for managing potential quantum-related risks.\n>\n> Consistent with its previous version, this proposal does not introduce\n> post-quantum signature schemes. Instead, BIP 360 proposes the addition of a\n> new output type with the key path spend removed, which is thus protected\n> from hypothetical breaks of Elliptic Curve Cryptography (ECC).\n>\n> We have renamed this proposed output type \"Pay-to-Tapscri",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2038,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] CTV activation meeting #1 Notes",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-Zr9JnLcohdUQRufM42OwROcOh76fA1xjtqUkY5=otqfwg@mail.gmail.com",
          "title": "[bitcoindev] CTV activation meeting #1 Notes",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Sat, 20 Dec 2025 06:58:42 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 920 bytes --]\n\nHi everyone,\n\nWe organized an IRC [meeting][0] in #ctv-csfs-activation channel on 18\nDecember 2025 to discuss the activation parameters for BIP 119. Everyone\nagreed to use BIP 9 with conservative parameters.\n\nActivation parameters and notes: https://ctv-activation.github.io/\n\nPlease let me know if you do not agree with parameters and prefer different\ndates.\n\n[0]: https://groups.google.com/g/bitcoindev/c/JZR5cUgpfUs/m/VA9ljVQSCwAJ\n[1]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki\n\n/dev/fd0\nfloppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-Zr9JnLcohdUQRufM42OwROcOh76fA1xjtqUkY5%3Dotqfwg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1482 bytes --]",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 1080,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] op_ctv still has no technical objections",
      "message_count": 1,
      "participants": [
        "\"'moonsettler' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/ZDIGYB4Jcy6DGEkUGxEIBgmD0WhaNQh8X3ovu6bVwnBQ4jCQS84dkG22oLR0XJmgG0emYj9eg1mwU3I0gZtKfpovVCjlXh5FsfO0UmelT-c=@protonmail.com",
          "title": "Re: [bitcoindev] op_ctv still has no technical objections",
          "author": "\"'moonsettler' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 19 Dec 2025 14:58:19 +0000",
          "body": "Hi All,\n\nJust a small remark\n\n> lnhance is more comprehensive. but also it's so much harder to reason about three separate op codes and what the attack surface could be.\n\nIt's 4 opcodes, but ofc it's safe to ignore INTERNALKEY when it comes to unexpected interactions.\nWe have spent basically a whole year on walking in circles with various opcode combos.\n\nWe came up with a set of threshold rules that make sense as an evaluation framework:\n- Fine-grained introspection\n- State-carrying covenants\n- Bigint operations\n- New arithmetic capabilities using lookup tables\n\nThese are key \"ingredients\" to exogenous asset protocols that are script interactible and novel bridge\nconstructions, that might interact badly with mining decentralization.\n\nMany other proposals instantly violate some or all of them, not LNhance.\nTo this day I haven't seen anyone come up with anything remotely scary with CTV+CSFS+PC.\n\nI would like to encourage people to take the time and try to come up with anything \"nasty\".\n\nBR,\nmoonsettler\n\n\nSent with Proton Mail secure email.\n\nOn Thursday, November 27th, 2025 at 10:18 AM, Erik Aronesty <erik@q32•com> wrote:\n\n> It's been many years and there's been a lot of discussion about various covenants\n> I think one of the biggest problems is everyone has to insist on their baby is the best baby.\n>\n> op_ctv is quite literally not the best at anything. That's the whole point. It's non-recursive, can't be used for strange or dangerous things, and can be used to emulate a lot of other opcodes.\n>\n> It's adequate. And I don't think we want anything \"better\" than adequate the first time around. lnhance is more comprehensive. but also it's so much harder to reason about three separate op codes and what the attack surface could be.\n>\n> I don't think it's possible to optimize a series of covenants for all possible scenarios. Easy to make them too powerful and now nodes are doing too much work and we're attracting the kind of network activity that nobody wants.\n>\n> Fortunatel",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Re: op_ctv still has no technical objections",
      "message_count": 1,
      "participants": [
        "\"'conduition' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2914ad6f-7e1a-42b6-9c25-87ac48c63228n@googlegroups.com",
          "title": "[bitcoindev] Re: op_ctv still has no technical objections",
          "author": "\"'conduition' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 27 Nov 2025 18:04:28 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2607 bytes --]\n\nAs someone who has had a merely passive interest in covenants tech, I can \nconfidently say that OP_CTV is probably the only covenants proposal whose \neffects I can confidently say I fully grasp. It's also easy to explain to \nothers. Not saying i'm not in favor of more complex multi-pronged upgrades \nlike LNHANCE, just saying I don't fully understand their opcode interplay \nenough to say yay/nay. Which is maybe an under-represented argument in \nfavor of plain OP_CTV.\n\nregards,\nconduition\n\nOn Thursday, November 27, 2025 at 1:18:03 AM UTC-8 Erik Aronesty wrote:\n\n> It's been many years and there's been a lot of discussion about various \n> covenants \n>\n> I think one of the biggest problems is everyone has to insist on their \n> baby is the best baby. \n>\n> op_ctv is quite literally not the best at anything.  That's the whole \n> point.  It's non-recursive, can't be used for strange or dangerous things, \n> and can be used to emulate a lot of other opcodes. \n>\n> It's adequate.  And I don't think we want anything \"better\" than adequate \n> the first time around. lnhance is more comprehensive.  but also it's so \n> much harder to reason about three separate op codes and what the attack \n> surface could be.\n>\n> I don't think it's possible to optimize a series of covenants for all \n> possible scenarios.  Easy to make them too powerful and now nodes are doing \n> too much work and we're attracting the kind of network activity that nobody \n> wants.  \n>\n> Fortunately the risk of CTV is fairly low.  It's always possible to turn \n> it off (no new tx)... if there's a game theory issue. \n>\n> I don't think there's any particular rush, but we could lose a lot of fees \n> and support for miners if Bitcoin continues to do what it is doing now... \n> scaling almost entirely in custodial systems.  That's also just not the \n> Bitcoin that anyone loves.\n>\n> At this point it feels like it's \"perfect is the enemy of the good\".  \n>\n> We have ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Secondary mailing list for moderated emails",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-ZqQGkEJXxVPSMmXYC1qTafAFShx=2QrMS5mkm-y6M=+nQ@mail.gmail.com",
          "title": "[bitcoindev] Secondary mailing list for moderated emails",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Fri, 19 Dec 2025 17:11:13 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 874 bytes --]\n\nHi everyone,\n\nThe old bitcoin-dev mailing list had a secondary mailing list for moderated\nemails:\nhttps://lists.ozlabs.org/listinfo/bitcoin-dev-moderation\n\nI have created a similar list for bitcoindev@googlegroups.com, with the\nemail address\nbitcoin-dev-moderation@googlegroups•com. If your email is moderated and you\ncannot see it on\nhttps://groups.google.com/g/bitcoindev/, please resend it with the\nmoderation list email address\nin the Cc or Bcc.\n\n /dev/fd0\n floppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-ZqQGkEJXxVPSMmXYC1qTafAFShx%3D2QrMS5mkm-y6M%3D%2BnQ%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1450 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1046,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Peer Feature Negotiation",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aUUXLgEUCgGb122o@erisian.com.au",
          "title": "[bitcoindev] [BIP Proposal] Peer Feature Negotiation",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Fri, 19 Dec 2025 19:13:18 +1000",
          "body": "Hello world,\n\nI've been thinking recently about a few ideas that would benefit\nfrom new p2p messages, namely template sharing [0], updating the\nbip324-one-byte-message-types [1], and sharing recent stale blocks [2].\nThat's made me want to make sure that we've got a good way of negotiating\nnew features, and revisiting the ideas from the 2020 thread [3] has me\nstill liking the \"FEATURE\" message idea [4].\n\nAs such, and with Ava's recent exhortation that everyone should be\nwriting BIPs [5] in mind, I've written a BIP:\n\nhttps://github.com/ajtowns/bips/blob/202512-p2p-feature/bip-peer-feature-negotiation.md\n\nSample code, though that part isn't really very interesting:\n\nhttps://github.com/ajtowns/bitcoin/commit/80301f0040fe6048a85b89d0fdf0ffcca836a1d0\n\nThe BIP is perhaps a bit over-engineered at this point for what it does,\nbut I figure better to be over-engineered than under-. And in any event,\nthere was some degree of breakage with the SENDADDRV2's deployment [6,7]\nwhich would be good to avoid repeating. In any event, the BIP text has\na bunch more background, etc.\n\nComments welcome.\n\nCheers,\naj\n\n[0] https://github.com/bitcoin/bitcoin/issues/33691\n\n[1] https://github.com/bitcoin/bips/pull/1378#discussion_r2585766526\n\n[2] https://github.com/bitcoin-data/stale-blocks\n    The idea behind sharing stale blocks (or headers) more proactively,\n    is it better insight into the orphan rate, and whether hashrate\n    is extending the chain vs potentially creating a reorg; and also\n    potentially makes syncing to the new tip after a reorgs more\n    efficient, as you'll have already downloaded the parent of the new tip\n\n[3] https://gnusha.org/pi/bitcoindev/CAFp6fsE=HPFUMFhyuZkroBO_QJ-dUWNJqCPg9=fMJ3Jqnu1hnw@mail.gmail.com/\n\n[4] https://gnusha.org/pi/bitcoindev/20200821023647.7eat4goqqrtaqnna@erisian.com.au/\n\n[5] https://x.com/btcplusplus/status/2000489894515253529\n\n[6] https://github.com/btcsuite/btcd/issues/1661\n\n[7] https://github.com/bitcoin/bitcoin/pull/20564\n\n-- \nYou received th",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2053,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Perhaps the simplest possible quantum-security upgrade",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgLR+vjYrUXuJ-k3FZ9=ZnOj3f3w2qB==M7-yrbQYx_h2A@mail.gmail.com",
          "title": "[bitcoindev] Perhaps the simplest possible quantum-security upgrade",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Wed, 17 Dec 2025 12:57:42 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3408 bytes --]\n\nWas thinking about this and I realized that a quantum-resistance scheme\ndoesn't technically need a new \"signature\" - because those constraints\n(generality) are far harder than needed for Bitcoin's \"proof of utxo\nownership\".\n\nInstead of new signatures, I propose a chain-native authorization primitive\nwhose security is bounded by the same economic assumptions as transaction\nfinality itself. The objective is a quantum migration path that can be\ndeployed immediately, does not require large witnesses, remains cheap to\nvalidate, and does not rely on assumptions stronger than those already\nrequired to trust confirmed spends.\n\nThe construction relies on a minimal new introspection primitive rather\nthan a wholesale redesign of Script. A single opcode exposes a\nchain-derived challenge tied to the spent output, defined as the block hash\nat a selectable offset from the block in which the UTXO was created. The\noffset is fixed by the locking script and can be chosen to reflect the\nvalue at risk. Larger offsets correspond to deeper confirmation depth and\nhigher economic resistance to manipulation (an enforced confirmation wait).\nExisting timelock opcodes already enforce the required delay; the only\nmissing element is access to this chain-defined value.\n\n*This is commit–challenge–response (Σ-protocol–derived) authentication*,\nbut the challenge is provided by *the future chain*.   This is a well known\nscheme.\n\nAuthorization is conjunctive, not alternative. A valid spend must satisfy\nboth a traditional signature check and a delayed, chain-conditioned\nhash-based proof. The traditional signature preserves today’s security\nassumptions and compatibility, while the chain-conditioned proof adds a\nquantum-resistant requirement that cannot be bypassed by a quantum\nadversary. Either condition alone is insufficient. This ensures the scheme\nis strictly at least as secure as current authorization and strictly\nstronger against quantum-cap",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2068,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: Perhaps the simplest possible quantum-security upgrade",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgKcRN6QOKFdvMDdrZVcFGu+hrrCMiB+B9HVdM2RXphQAQ@mail.gmail.com",
          "title": "[bitcoindev] Re: Perhaps the simplest possible quantum-security upgrade",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Thu, 18 Dec 2025 08:11:13 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4185 bytes --]\n\nI wrote the python code for this.  It was a little trickier to get it right:\n\nhttps://gist.github.com/earonesty/ea086aa995be1a860af093f93bd45bf2\n\nSpender publishes an ephemeral anchor tx committing to a future secret\nwithout revealing the secret in one block.\n\nSpender publishes the revealed secret and spend in a future block.\n\nNew opcode needs to verify that the anchor tx was published at least N\nblocks prior to the spend block.\n\nThis creates the necessary information asymmetry without being a true\nsignature, relying on asymmetry-over-time to protect against quantum\nthreats.\n\n\n\nOn Wed, Dec 17, 2025 at 12:57 PM Erik Aronesty <erik@q32•com> wrote:\n\n> Was thinking about this and I realized that a quantum-resistance scheme\n> doesn't technically need a new \"signature\" - because those constraints\n> (generality) are far harder than needed for Bitcoin's \"proof of utxo\n> ownership\".\n>\n> Instead of new signatures, I propose a chain-native authorization\n> primitive whose security is bounded by the same economic assumptions as\n> transaction finality itself. The objective is a quantum migration path that\n> can be deployed immediately, does not require large witnesses, remains\n> cheap to validate, and does not rely on assumptions stronger than those\n> already required to trust confirmed spends.\n>\n> The construction relies on a minimal new introspection primitive rather\n> than a wholesale redesign of Script. A single opcode exposes a\n> chain-derived challenge tied to the spent output, defined as the block hash\n> at a selectable offset from the block in which the UTXO was created. The\n> offset is fixed by the locking script and can be chosen to reflect the\n> value at risk. Larger offsets correspond to deeper confirmation depth and\n> higher economic resistance to manipulation (an enforced confirmation wait).\n> Existing timelock opcodes already enforce the required delay; the only\n> missing element is access to this chain-def",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Does GCC preclude a soft fork to handle timestamp overflow?",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a7m01C4Xm3-WF9Slrg1b2G8OaZiCXKQncrHW4kD5iVrNq8E-yde2W4pF1ZIU6PeiU-jUeyDCsFntfrTw28wW38iIkBeo6OENzlWUsL-hetc=@protonmail.com",
          "title": "Re: [bitcoindev] Does GCC preclude a soft fork to handle timestamp overflow?",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 17 Dec 2025 14:55:40 +0000",
          "body": "Hi Josh,\n\nInteresting observation!\n\nI am of the opinion that the header timestamp overflow is one of those things\nthat are better addressed through a backward-incompatible consensus change. As\npointed out earlier in response to your post, the MTP rule would prevent a chain\nsplit by making sure the legacy chain halts.\n\nFurthermore, even if it was a goal to fix the timestamp overflow through a soft\nfork, the issue will arise so far in the future that it does not justify making\ninferior protocol decisions to fix bugs that exist today (and that could become\nmore problematic within the next decade).\n\nYou came up with a clever hack to address the DoS concern, which somewhat\nreminds me of forward blocks. It makes it possible to still validate cumulative\nwork from a chain of headers, but it relies on actively exploiting Timewarp\nthere. This is unfortunate in itself but also means breaking timestamp-based\ntimelocks which, as people pointed out here and on your Delving thread, entails\nfreezing coins that rely on them.\n\nTherefore my preference is to fix properly Timewarp with BIP 54, and properly\ndeal with the timestamp overflow when (if?) necessary.\n\nBest,\nAntoine Poinsot\n\n\nOn Monday, December 15th, 2025 at 2:30 PM, Josh Doman <joshsdoman@gmail•com> wrote:\n\n> > your idea is to have the header nTime used for difficulty adjustment enforced in the coinbase tx.\n> Correct. As written, BIP54 makes that soft fork impossible, leaving a hard fork as the only option to resolve nTime overflow.\n> \n> > I was about to write this email myself, but then I realized that since BIP 113, timelocks are based on MTP time, and any soft-fork mechanism that messes with MTP time will destroy existing transaction's timelock semantics.\n> \n> Yes, it's unfortunate. There is certainly a tradeoff. On the one hand, there is a risk of coin confiscation, if the soft fork isn't signaled early enough (a few decades in advance is probably sufficient). On the other hand, there are material benefits to avoiding a h",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Motion to Activate BIP 3",
      "message_count": 1,
      "participants": [
        "Mat Balez"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABd6=MPtx9rN2ZtTz7CbT-zb-3qVUecZZrmb56aFyCSVeLxsEQ@mail.gmail.com",
          "title": "Re: [bitcoindev] Motion to Activate BIP 3",
          "author": "Mat Balez <matbalez@gmail@com>",
          "date": "Thu, 20 Nov 2025 12:14:09 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 14565 bytes --]\n\nMore and more of writing by all humans, including BIP proposers, will\ninevitably involve AI in some more or less significant way. I don't expect\npeople to reliably express the degree to which AI was used to inform the\nthinking behind the BIP, or the writing itself. I'm not aware of any common\nstandard we would use to express those things. Adversarially, we have to\nassume people won't do it if it's not in their interests.\n\nRather, I think the expectation should be that BIP proposers are entirely\nresponsible for submitting high quality BIPs and they take ownership for\nwhat they are submitting (submitting garbage burns your rep, always has and\nalways will). BIP reviewers should simply assume for all BIPs that AI was\nlikely used significantly to create them, and judge BIPs only on the merit\nof the ideas and content.\n\nBecause of the advent of LLMs (and their inevitable continued improvement)\nthis will almost certainly result in an increased number of BIPs being\nadvanced, many of low (slop-filled) quality but also, hopefully, more high\nquality ones as well—proposals that might not otherwise have seen the light\nof day and/or proposals themselves being strengthened with better\narguments, ideas and language.\n\nThe solution to such a rise in volume IMO is that BIP reviewers should also\nequip themselves with LLMs and other AI-powered tools to help\nfilter/triage/assess BIPs to get a handle on the rise in noise level. Yet,\njust like BIP proposers, the onus should be on BIP reviewers to take\nownership for the quality of the decision-making around BIP quality and\nthat it not ever be entirely automated but retain \"human in the loop\"\njudgment—at least for the foreseeable future—just made more efficient and\neffective through the use of AI.\n\nOn Thu, Nov 20, 2025 at 1:47 AM Oghenovo Usiwoma <eunovo9@gmail•com> wrote:\n\n> > I think it makes sense to request that submissions should state if - and\n> to what degree - AI has been use",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2042,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Motion to Activate BIP 3",
      "message_count": 1,
      "participants": [
        "Greg Sanders"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/899eb548-3e3b-4b85-8ae0-1e64d15f1b86n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: Motion to Activate BIP 3",
          "author": "Greg Sanders <gsanders87@gmail@com>",
          "date": "Thu, 13 Nov 2025 10:54:20 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 7475 bytes --]\n\nMakes sense to me, and this e-mail can be a reference point if there's \nfuture discussion.\n\nWith what little review I've done, I think this makes sense to activate!\n\nGreg\n\nOn Wednesday, November 12, 2025 at 7:30:59 PM UTC-5 Murch wrote:\n\n> Hey Greg,\n>\n> Two sections from BIP 3 stand out as relevant here, “BIP Ownership“ and \n> “Deployed Process BIPs”.\n>\n> From “Fundamentals > BIP Ownership”:\n> > “[…] As a BIP progresses through the workflow, it becomes \n> increasingly co-owned by the Bitcoin community.”\n>\n> While Deployed BIPs are considered final and changes should be avoided, \n> the section has a subsection that specifically addresses Process BIPs.\n>\n> From “Workflow > Progression through BIP Statuses > Deployed > Process \n> BIPs”:\n> > “A Process BIP may change status from Complete to Deployed when it \n> achieves rough consensus on the Bitcoin Development Mailing List. A \n> proposal is said to have rough consensus if its advancement has been \n> open to discussion on the mailing list for at least one month, the \n> discussion achieved meaningful engagement, and no person maintains any \n> unaddressed substantiated objections to it. Addressed or obstructive \n> objections may be ignored/overruled by general agreement that they have \n> been sufficiently addressed, but clear reasoning must be given in such \n> circumstances. Deployed Process BIPs may be modified indefinitely as \n> long as a proposed modification has rough consensus per the same criteria.”\n>\n> More specific rules supersede general rules, so this subsection on \n> Process BIPs should hopefully clearly override the general description \n> in “Deployed”. It follows from these two sections that the BIP Authors’ \n> right to decide about changes to their BIP is moderated by the community \n> interests. I would consider especially Process BIPs to be dominantly \n> owned by the community rather than the Authors once they are Deployed. \n> The quoted section s",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2046,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [Discussion] Year 2106 Timestamp Overflow - Proposal for uint64 Migration",
      "message_count": 1,
      "participants": [
        "Henry Romp"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPnXYtPdbFwc1mOsP2eHQBwuJhn2XxLCWC-pt6+N-bu3BRRbiA@mail.gmail.com",
          "title": "Re: [bitcoindev] [Discussion] Year 2106 Timestamp Overflow - Proposal for uint64 Migration",
          "author": "Henry Romp <151henry151@gmail@com>",
          "date": "Mon, 15 Dec 2025 14:09:50 -0500",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3513 bytes --]\n\nAh, I see you're right—once MTP reaches 2^32 - 1, no valid timestamp can\nexceed it, making the next block mathematically impossible.\nI was wrong about the halt. I still maintain my other points about timeline\nand opportunity costs.\n\n\nHenry\n\n\n\n*Henry Romp802-458-7299 <8024587299>*\n*151henry151@gmail•com <151henry151@gmail•com>*\n\n\n\nOn Mon, Dec 15, 2025, 04:59 Garlo Nicon <garlonicon@gmail•com> wrote:\n\n> > The blockchain won't \"halt\" at overflow, it will have validation\n> problems.\n>\n> These \"validation problems\" will be quite serious. For example: it will be\n> possible to produce a chain with a bigger chainwork, and pass it to the old\n> nodes.\n>\n> Which means, that the chain can go forward for the new nodes, while being\n> perceived as a constantly reorged, by the old implementation.\n>\n> And then, the question is: do we want to design a new soft-fork in a way,\n> where it would be seen as constantly-reorged chain by the old nodes?\n>\n> > The overflow doesn't automatically stop the chain.\n>\n> It will, because overflowed timestamps from 1970 will be rejected by all\n> old nodes.\n>\n> > At that point there are no more valid blocks that can be appended to the\n> chain.\n>\n> As long as the chainwork won't overflow, you can always reorg the old\n> blocks. If that reorg will be deterministic, and accepted by hashrate\n> majority, then it will be seen only by old nodes. New nodes can see a\n> stable chain, always going forward, beyond 0xffffffff.\n>\n> Anyway, it will be just one-bit increment per 136 years.\n>\n> niedz., 14 gru 2025 o 15:09 'Russell O'Connor' via Bitcoin Development\n> Mailing List <bitcoindev@googlegroups.com> napisał(a):\n>\n>> On Sat, Dec 13, 2025 at 5:05 AM Henry Romp <151henry151@gmail•com> wrote:\n>>\n>>> The blockchain won't \"halt\" at overflow, it will have validation\n>>> problems. The overflow doesn't automatically stop the chain. Nodes would\n>>> continue with wrapped-around timestamps (though this would cause ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 0,
            "text_length": 2091,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Add PSBT_IN_SP_TWEAK field",
      "message_count": 1,
      "participants": [
        "\"'nymius' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/R53cG3TeXgXDUUS4kH_q226GlaFCjI0DZVT6mdTQzSQdj3RnNqWA-bFT7uGgGQFJG6938kDGvDJVoFQj8ItEMsJ6NyOjCTvpVEarYiyW6-8=@proton.me",
          "title": "[bitcoindev] [BIP Proposal] Add PSBT_IN_SP_TWEAK field",
          "author": "\"'nymius' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Mon, 15 Dec 2025 08:00:01 +0000",
          "body": "[-- Attachment #1.1.1: Type: text/plain, Size: 5112 bytes --]\n\nHi all,\nI'm working on the implementation of silent payments in BDK.\n\nBDK's transaction creation process is structured around PSBTs. Because of this, a stable implementation of silent payments in the project depends of the specifications of BIP 352 for this format. BIP 375 and BIP 374 are core component for this.\n\nHowever, there is a need for the inclusion of silent payments tweaks in PSBTs to spend silent payment outputs, which was considered before [1][2] but never specified.\n\nI would like to propose the following as a base for a new BIP proposal addressing this gap:\n\n### Abstract\n\nThis document proposes additional fields for BIP 370 PSBTv2 that allow for BIP 352 silent payment tweaks to be included in a PSBT of version 2. These will be fields for scripts that are relevant to the spending of silent payment outputs, but may be also useful to other protocols using taproot tweaks not following BIP 340 spec.\n\n### Motivation\n\nBIPs 352 specify silent payments protocol, which provides a new way to create P2TR outputs and spend them. The existing PSBT fields are unable to support silent payments without changes, due to the new method by which outputs are created. BIP 375 and complementary BIP 374 specify how to create outputs locked with silent payment keys using PSBTs. But they don't specify how to unlock these outputs in a transaction. Therefore new fields must be defined to allow PSBTs to carry the information necessary for tweaking taproot keys without following the BIP 340 tagging scheme.\n\n### Specification\n\nThe new per-input types are defined as follows:\n\n| Name              | \\<keytype\\>               | \\<keydata\\> | <keydata\\><br>Description | \\<valuedata\\>    | \\<valuedata\\><br>Description                                                                                 | \\<Versions Requiring Inlusion\\> | \\<Versions Requiring Exclusion\\> | \\<Versions Allowing Inclusion\\> |\n| ----------------- | --------",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2055,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Splitting more block, addr and tx classes of network traffic",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALZpt+Hx9vFwNQd6qGSFMWXU=A6j82m6ZjJg3JaHK26WW0UQZw@mail.gmail.com",
          "title": "[bitcoindev] Splitting more block, addr and tx classes of network traffic",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Thu, 4 Dec 2025 22:33:43 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3714 bytes --]\n\nHi list,\n\nSurfacing an old idea concerning the network-level and the current meddling\nof block,\ntx and addr messages traffic generally all over one network link.\nHistorically, for\nexample, if you consider bitcoin core by default connections are going to\nbe FULL_RELAY.\nOver the last years, there has been few improvements to separate network\nlinks by types\ne.g with the introduction of dedicated outbound BLOCK-RELAY connections\n[1], without the\nsegregation at the network-level between the class of traffic really being\npursued, or at\nleast more flexibility in network mechanisms to signal to a node's peers\nwhat categories\nof messages will be processed on a given link.\n\nPreviously it has been shown that leveraging tx-relay's orphan mechanism\ncan allow to map\na peer's network-topology [2] (sadly, one trick among others). Being able\nto infer a peer's\n\"likely\" network topology from tx traffic, one can guess the peers used to\ncarry block-relay\ntraffic. From the PoV of an economical node, dissimulating the block-relay\ntraffic is a very\nvaluable to minimize the risks of escalation attacks based on\nnetwork-topology (e.g for\nlightning nodes [3]).\n\nSegregating more network traffic by class of messages sounds to suppose 1)\nbeing able to signal\namong the {ADDR, ADDRV2} service bits if block, addr or tx relay is\nsupported on a link to be\nopened for a pair of a (net_addr, port) or alternatively 2) if network link\nare open blindly\nwith peers, being to signal in the VERSION message or with a dedicated\nmessage what class of\nmessage is supported. There is already a signaling mechanism in the VERSION\nmessage to\ndisable tx-relay (i.e `fRelay`), however there is no signaling to disable\nblock-relay over a link.\nAlternatively, it has been proposed in the past to add a new early message\namong all the other\nhandshake messages between the VERSION / VERACK flow, but it has never been\nimplemented [4].\n\nFor bitcoin backbone, started to nativ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2074,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: Splitting more block, addr and tx classes of network traffic",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/7cceae55-0885-4a66-9e1f-55e1537e2e17n@googlegroups.com",
          "title": "[bitcoindev] Re: Splitting more block, addr and tx classes of network traffic",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Sun, 14 Dec 2025 18:10:14 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 8730 bytes --]\n\n \n\nHi Defenwycke,\n\nI'm already working on a native multi-process architecture where the traffic\nclasses are isolated on different runtimes, and the \"old\" block store is \nshared.\nAll the points, you made about explicit signaling and the drawbacks are \nvalid,\nand one of the latest time the idea to add a signaling bit for full-rbf \npeers\ncame up, privacy concerns were raised.\n\nThe drawback for the multi-process, multi-socket design approach is to \nmultiply\nthe number of inbound sockets consumed by a peer, though in the case of a \n\"cold\nblock\" archive process it's the inbound peer initiating the connection.\n\nBandwidth-consumption wise, getting messages like BIP 0338 this is still an\noutbound bandwidth win for your full-node peers adopting it, and more \ngenerally\nfor any ingress filtering at the network-level.\n\nBest,\nAntoine\nOTS hash: e1b51b6a80bc77a1cd9e65b1fb74e9b5f52b93473d9e1f1390015eae70674b4c\nLe mercredi 10 décembre 2025 à 18:12:32 UTC, defenwycke a écrit :\n\n> Hello Antoine,\n>\n> This is an interesting problem, and introducing finer-grained traffic \n> classes certainly makes sense. The three areas that stand out to me are \n> peer declaration, topology inference and system bottlenecks.\n>\n> Peer declaration: \n>\n> Explicit signalling of specialised roles (Example - I only relay \n> hot-blocks) to peers increases the fingerprint/profile. We already see \n> topology inference attacks via relay behaviour; adding public role \n> declarations may expand that surface. Nodes can already drop or \n> deprioritise whatever they wish locally, so explicit signalling may not be \n> necessary.\n>\n> Topology inference:\n>\n> Since topology inference can be drawn from tx-relay timing and relay \n> behaviour, an internal class-based model also allows the node to randomise \n> acceptance, forwarding, and scheduling behaviour per class. Even small \n> amounts of deliberate jitter or probabilistic message handling make it far \n> harder for",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2078,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Feedback on a simple 2-path vault design (2-of-2 + CLTV recovery) and use of pruned nodes for UTXO retrieval",
      "message_count": 1,
      "participants": [
        "victor perez"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAHyc38=a=7fCgPg10e=jkpiUA8qiJf+DAaoOaNcP1JajjsZTtw@mail.gmail.com",
          "title": "Re: [bitcoindev] Feedback on a simple 2-path vault design (2-of-2 + CLTV recovery) and use of pruned nodes for UTXO retrieval",
          "author": "victor perez <svcrobotics@gmail@com>",
          "date": "Sun, 14 Dec 2025 11:40:27 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 12246 bytes --]\n\nHi Antoine,\n\nThank you very much for your detailed reply—it's extremely helpful.\n\nFollowing your advice, I'm going to simplify my work and first focus on a\nsingle spending path: a clean 2-of-2 (A + B) multisig, signed with two\nLedgers. My goal is to get this flow stable end-to-end (descriptor\ncreation, UTXO handling, PSBT flow, hardware signing, broadcast) before\nadding the recovery path with a timelock.\n\nJust to clarify the scope: my application is not meant to be a second\nLiana. It's an educational and experimental Ruby on Rails environment that\nI use to better understand Bitcoin in practice.\n\nThe app combines several independent modules:\n\n  - A vault module, where I experiment with descriptors, Miniscript/Taproot\nconstructions, PSBTs, and hardware signing.\n  - A BRC-20 and on-chain analytics module, which helps me explore data\nintelligence by extracting and analysing blockchain data.\n  - A donation module in sats connected to my BTCPay Server.\n  - Various dashboards for visualizing Bitcoin data.\n\nI should mention that I am currently not using regtest. All my experiments\nare done directly on mainnet with real BTC, because it helps me stay fully\naware of real-world constraints and forces me to design things carefully.\nThat said, based on your recommendations, I will start integrating regtest\ninto my workflow so I can iterate faster and test edge-cases more safely.\n\nYour pointers toward Bitcoin Core's wallet API, BDK, Miniscript, and\nhardware-wallet policies give me a very clear roadmap for progressing in a\nstructured way.\n\nThanks again for your time and guidance—it truly helps.\n\nBest regards,\nVictor\n\n\nLe sam. 13 déc. 2025, 18:03, Antoine Poinsot <darosior@protonmail•com> a\nécrit :\n\n> Hi Victor,\n>\n> > If you have any recommendations on what pitfalls to avoid or reading\n> material on robust recovery designs, I’d be glad to hear them.\n>\n> Since you mentioned that your purpose was educational, i would recommen",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2126,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Reducing RAM requirements with dynamic dust",
      "message_count": 1,
      "participants": [
        "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/Q4RLVZW6OK88aVcalvUK7KJJIKOXckKhB7a5zTN7LTxA-jzal3587k4yUiIMjcIBoqLI0eK4uQLZtjJGsbj1R8zsfaMDM-RGSw2V9KI6AAw=@proton.me",
          "title": "[bitcoindev] Reducing RAM requirements with dynamic dust",
          "author": "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sat, 06 Dec 2025 16:08:45 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 10005 bytes --]\n\nGiven the increasing RAM requirements, due to the increasing UTXO set, I suggest seeing the UTXO set size as a controlled variable. A feedback mechanism sets a dynamic dust level, below from which UTXOs are removed/discarded and thus freeing RAM.\n\nBelow is an overview essay better expressed by grok, which can also be seen in here:\nhttps://hackmd.io/P-2lzGb8TiC86IOE3OGiYA?view\n\n# Enhancing Bitcoin's Scalability: A PID-Inspired Approach to Managing UTXO Set Growth\n\n## Abstract\n\nBitcoin’s UTXO set is currently an unbounded accumulator that risks long-term centralization as node RAM requirements grow without limit. Existing fee incentives have proven insufficient against sustained low-value output creation (e.g., inscriptions, tokenized assets, dust-heavy protocols). This article proposes a soft-fork mechanism that treats UTXO set size as a controlled variable: a slowly rising target size is defined, and a PID-style feedback controller, updated every difficulty epoch, dynamically raises a minimum-value floor beneath which old UTXOs become unspendable. The result is bounded, predictable growth of the UTXO set with ample warning periods, no hard caps on monetary use, and strong resistance to bloat attacks—all while remaining fully compatible with a soft-fork deployment.\n\n## Introduction\n\nBitcoin, the pioneering decentralized digital currency, operates as a complex dynamic system governed by consensus rules that ensure security, immutability, and permissionless participation. At its core, Bitcoin maintains a distributed ledger known as the blockchain, which records all transactions in a sequence of blocks. Each transaction involves inputs and outputs: inputs reference previously unspent outputs from prior transactions, while outputs create new spendable units called Unspent Transaction Outputs (UTXOs). The UTXO set represents the aggregate state of all currently spendable coins in the network, serving as a critica",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2057,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Reducing RAM requirements with dynamic dust",
      "message_count": 1,
      "participants": [
        "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/ASHweqfTSVKBPOY2P4UCyK7k7C28OWcQx2SfP9Ovqv2xifZo6SJYpwYLQTjvXTuf7lCa6fqeP92n47L6EokhlA7gHguLLgzHBQMY87rQDQk=@proton.me",
          "title": "Re: [bitcoindev] Re: Reducing RAM requirements with dynamic dust",
          "author": "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 12 Dec 2025 22:22:51 +0000",
          "body": "Thanks both Eric and Erik for the replies. I can't answer whether RAM requirements due to UTXO would indeed be a problem or not. I think a worse-case performance could be considered assuming a \"no-RAM\" environment.\n\nThis being said, I wanted to share some insights still related to the dynamic dust mechanism (the essay).\n\n1. This proposal could be named \"dynamic dust\" plus \"dust sweeping\". Dynamic dust refers to the dust level being defined by the controller at every epoch, and dust sweeping refers to deprecation of utxos below that dust threshold.\n\n2. The grace period for the sweep, individual for each transaction, allows for a new perspective. This is, again, better portrayed by Grok:\n\n## Annex: Addressing Concerns of Confiscation in UTXO Deprecation\n\nWhile the proposed PID-inspired mechanism for UTXO set management offers a pathway to enhanced scalability, it has elicited valid criticisms, particularly regarding its confiscatory nature. Deprecating low-value UTXOs could be perceived as an involuntary seizure of assets, undermining Bitcoin's principles of ownership and immutability. This concern merits careful consideration, as any protocol change must preserve user trust and avoid arbitrary interventions.\n\nThe proposal maintains a degree of neutrality by evaluating UTXOs solely based on their satoshi (SAT) value, without interpreting their content or purpose. This objective criterion minimizes subjective judgments, applying uniformly across all outputs regardless of their origin or use case.\n\nA key mitigating factor lies in the incorporation of a grace period—typically spanning 6 to 12 months—during which owners of affected UTXOs can consolidate or spend them without direct penalty. This window transforms the deprecation process from outright confiscation into a dynamic incentive structure, favoring resource allocation in a constrained system. In Bitcoin's ecosystem, users already incur ongoing costs for participation, such as transaction fees, which can render lo",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2065,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] A safe way to remove objectionable content from the blockchain",
      "message_count": 1,
      "participants": [
        "Peter Todd"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aTl8Y7p4qtYAsHbP@petertodd.org",
          "title": "Re: [bitcoindev] A safe way to remove objectionable content from the blockchain",
          "author": "Peter Todd <pete@petertodd@org>",
          "date": "Wed, 10 Dec 2025 13:57:55 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2902 bytes --]\n\nOn Tue, Dec 09, 2025 at 11:32:48AM -0800, Boris Nagaev wrote:\n> Hi waxwing/AdamISZ,\n> \n> On incentives: agreed that \"good\" only matters if it's an equilibrium. The \n> aim is to shape early design choices so the incentive-compatible \n> equilibrium includes DA and forced publication, rather than slipping into a \n> DA-weak equilibrium where only a few parties hold full data.\n\nExactly.\n\nFurthermore I want to be clear that in this context, the existence of strong ZK\nmath is an *exploit* on the Bitcoin protocol, in much the same way that a\nmathematical advancement that could be used to break SHA256 preimage security\nis also an exploit on the Bitcoin protocol.\n\nIt may be the case that the power of ZK techniques is sufficiently strong that\nBitcoin needs to be redesigned to mitigate them; there is even a small chance\nthat this is not possible and Lightning/HTLCs eventually become insecure due to\nit. No different than how there is a small chance that quantum computing\nrelevant to cryptography turns out to be real and numerous protocols become\ninsecure due to it.\n\n> > what if mining was done just on an accumulator over the utxo set, instead \n> of the utxo set itself?\n> \n> If miners and nodes only see an UTXO accumulator, how do HTLCs survive? The \n> HTLC success spend path needs the preimage to be revealed and readable. How \n> does this fit in an accumulator-only mining model, and what forces \n> publication so the payer can claim its incoming HTLC?\n\nMore generally, if mining is just an accumulator, how do we preserve censorship\nresistence? It's unlikely that the underlying math of the accumulator allows\nanyone to mine a new block with exactly as much data as is required to verify\nthe accumulator. \n\nRecently I met someone who told me that his company needed a full archival node\nof the Solana (IIRC) blockchain. That is, *all* Solana transactions going back\nin time, sufficient to verify everything. They had a very large b",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] CTV activation meeting on IRC - Thursday 18 December 17:00 UTC",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-Zqo-gRCeMDd2VtmXL7Ox31OT3pFmsfXQ5mq6SzeuFnMzg@mail.gmail.com",
          "title": "[bitcoindev] CTV activation meeting on IRC - Thursday 18 December 17:00 UTC",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Wed, 10 Dec 2025 03:38:14 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 775 bytes --]\n\nHi everyone,\n\nWe will organize a meeting next week to discuss the activation parameters\nfor BIP 119. You can review the related pull requests, different activation\nmethods, past meeting logs etc. and participate in the discussion.\n\nIRC Channel: #ctv-csfs-activation on libera.chat\nAgenda: Discuss activation parameters and build activation client for BIP\n119\n\n/dev/fd0\nfloppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-Zqo-gRCeMDd2VtmXL7Ox31OT3pFmsfXQ5mq6SzeuFnMzg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1197 bytes --]",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 0,
            "text_length": 966,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Request for early peer review of two BIP drafts (BUDS and segOP)",
      "message_count": 1,
      "participants": [
        "Callum"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X-WjPYaiTj5NQnAFp+df+4qWCT8oG_c9DsS-TZ47SjZow@mail.gmail.com",
          "title": "[bitcoindev] Request for early peer review of two BIP drafts (BUDS and segOP)",
          "author": "Callum <cal.defenwycke@gmail@com>",
          "date": "Mon, 8 Dec 2025 21:52:26 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1167 bytes --]\n\nHello all,\n\nI would appreciate early peer review on two BIP drafts I have published:\n\n   1.\n\n   BUDS (Bitcoin Unified Data Standard) — an informational BIP defining a\n   neutral, non-consensus taxonomy for describing transaction data.\n\n   Draft and reference materials:\n   https://github.com/defenwycke/bip-buds\n   2.\n\n   segOP (Segregated OP_RETURN) — a consensus proposal describing a\n   structured TLV data section and corresponding commitment output.\n\n   Draft and reference materials:\n   https://github.com/defenwycke/bip-segop\n\nBoth drafts are small and self-contained. Feedback on clarity, correctness,\nstructure, or missing considerations would be very welcome.\n\nThank you for your time.\n\nKind regards,\n\nDefenwycke\n\n08.12.2025\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAOj3_X-WjPYaiTj5NQnAFp%2Bdf%2B4qWCT8oG_c9DsS-TZ47SjZow%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 2528 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1323,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] A safe way to remove objectionable content from the blockchain (now on GitHub)",
      "message_count": 1,
      "participants": [
        "Lazy Fair"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABHzxrjfvyBRD7sG9rngvDhr9cfzLEQibn4bup_J8pz7UHQpqA@mail.gmail.com",
          "title": "[bitcoindev] A safe way to remove objectionable content from the blockchain (now on GitHub)",
          "author": "Lazy Fair <laissez.faire.btc@gmail@com>",
          "date": "Sat, 6 Dec 2025 17:41:10 +1100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4166 bytes --]\n\nI've started putting together some ideas around how to remove objectionable\ncontent from the blockchain. The very early work-in-progress description is\non GitHub: https://github.com/laissez-faire-btc/safe-remove\n\nI won't include all the details here, because there's necessarily a lot to\ncover, but the basic design goals I've aimed to address are something like\nthis:\n\n* optional - each node gets to decide what to remove, if anything\n* safe - provably no harm is done to those not choosing to use it, and any\ncost or risk to those using it is well understood, minimal, and mitigated\n* full node functionality - a node that does remove content can still do\neverything it could have done otherwise, without relying on anyone else\n* retrospective - content that exists on the blockchain today\n(pre-implementation) can be removed later (post-implementation)\n* trustless, verifiable, permissionless - control messages enabling data to\nbe removed are simple verifiable statements of fact that can be written by\nanybody\n* lightweight - minimal changes and impact to policy, consensus,\nimplementation, usage, the economy\n* granularity, associativity, commutability, idempotence - the least\npossible data is removed, and ordering is inconsequential\n* transferable - nodes that choose to remove objectionable content can\nshare those blocks (with content removed) with others who hold the same\nobjection, so that the receiver may never even momentarily hold the\nobjectionable content\n\nBeing design goals, these are probably not all achievable. I'll need your\nhelp to work through all the details.\n\nI have some more notes I just haven't written up yet, so I'm keen for your\ninput please, on what direction I should take, questions I should answer,\naspects I should consider or detail further, etc.\n\nIn the absence of any feedback, I'll be proceeding with either documenting\nthe threat model, or a bit of a literature review - starting with the\nfollowi",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2092,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] OP_CIV - Post-Quantum Signature Aggregation",
      "message_count": 1,
      "participants": [
        "\"'conduition' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/02e3cb64-50e8-4814-bf53-72db87deafc8n@googlegroups.com",
          "title": "Re: [bitcoindev] OP_CIV - Post-Quantum Signature Aggregation",
          "author": "\"'conduition' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 28 Nov 2025 10:52:27 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 17217 bytes --]\n\nHey Tadge,\n\nYou're right that OP_CIV would discourage address reuse, but it'd also make \nlife difficult for wallet developers who want to adopt it. Some wallet devs \n*today* don't even bother with multi-address support, so imagine if to do \nso effeciently, they needed to statefully track prior UTXOs and generate \naddresses based on a changing UTXO set over time.\n\nAlso I want to mention, there's a big privacy difference between these CISA \ntechniques, and CISA via address reuse. \n\nIf I receive two payments to the same address, i immediately reveal that \nthose UTXOs are owned by the same entity: me.\n\nIf I receive two payments to *distinct* addresses which are linked via your \nOP_CIV (or via my idea by committing to pubkeys) then I can choose when and \nwhether to reveal the fact that those UTXOs are commonly owned. Most user \nwallets have more than just two UTXOs, so in a setting where I have \npossibly dozens of UTXOs, this offers me more flexibility with respect to \nmy on-chain privacy, allowing me to choose when and how to reveal common \nUTXO ownership. This is kind of already the status quo, because chainalysis \nuses common-input ownership heuristics even if they are flawed/incorrect, \njust for the sake of having a \"working\" tool they can sell.\n\nRegarding the extra cost, we can quantify that! Let's say we have a taptree \nof height `h` with `2^h` leaves. We use one leaf for a unique pubkey, and \nthe other `2^h - 1` tap leaves store commitments to other pubkeys or to \npre-existing UTXOs. To spend a TX with `n` inputs using this CISA paradigm, \nwe need one signature, plus `n - 1` taproot control blocks and tapscripts. \nEach control block has size `h * 32`, plus ~32 bytes to reference the other \npubkey or UTXO in the locking tapscript. So in total, the witness size \nscales as: `(n - 1)((h + 1) * 32)`. In other words, for every additional \ninput covered by the CISA scheme, we must pay for roughly `(h + 1) * 32",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2061,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] SLH-DSA (SPHINCS) Performance Optimization Techniques",
      "message_count": 1,
      "participants": [
        "Tim Ruffing"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/6ad6c7418b6b845d6e2dd0ccdb2b508de0c3c10c.camel@real-or-random.org",
          "title": "Re: [bitcoindev] SLH-DSA (SPHINCS) Performance Optimization Techniques",
          "author": "Tim Ruffing <me@real-or-random@org>",
          "date": "Fri, 28 Nov 2025 16:39:12 +0100",
          "body": "Let me just say that leave the note here that this is awesome work!\n\nI didn't expect that so much can be gained using SIMD, and that it\nbeats SHA-NI by such a large margin (even taking into account the\ncaveats you've mentioned).\n\nTim\n\nOn Sun, 2025-11-23 at 18:46 -0800, 'conduition' via Bitcoin Development\nMailing List wrote:\n> Hi devs,\n> \n> I've spent the last several months implementing and benchmarking\n> optimization techniques for the post-quantum hash-based signature\n> scheme SLH-DSA (formerly SPHINCS+), which is being considered as a\n> candidate for a quantum-resistant soft-fork upgrade to Bitcoin, re:\n> BIP360.\n> \n> Survey article: https://conduition.io/code/fast-slh-dsa/\n> \n> char1.png\n> \n> As a material result of my findings, I believe I now possess what may\n> be the fastest publicly available implementation of SLH-DSA (at least\n> on my hardware), and possibly also one of the fastest GPU\n> implementations, though I've had difficulty finding comparable\n> alternatives on that front. Its speed is owed to the Vulkan graphics\n> programming API, often used by video game devs to squeeze performance\n> out of gaming PCs and mobile phones.\n> \n> The code: \n> - https://github.com/conduition/slhvk\n> - https://github.com/conduition/slh-experiments\n> \n> Using my CPU, this code can sign a message with SLH-DSA-SHA2-128s in\n> just 11 milliseconds, and can generate keys in only 2 milliseconds\n> (1ms if batched). Verification throughput approaches that of ECDSA,\n> at around 15000 nanoseconds per verification if properly batched. If\n> you have a GPU with drivers, everything runs even faster.\n> \n> For perspective, the fastest open source SLH-DSA library I could\n> find, PQClean, requires 94 milliseconds for SLH-DSA-SHA2-128s signing\n> and 12ms for keygen on my CPU. PQClean can only achieve this speed on\n> x86 CPUs, whereas Vulkan works on ARM devices, including Apple\n> silicon.\n> \n> There are caveats. This technique is memory-hungry, requiring several\n> megabytes of RAM for signin",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Q-Lock: Quantum-Resistant Spending via ECDSA + Hash-Based Secrets",
      "message_count": 1,
      "participants": [
        "Amarildo"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/1c6c4afc-0fe4-4b72-b70f-3f6ba4c19315n@googlegroups.com",
          "title": "[bitcoindev] Q-Lock: Quantum-Resistant Spending via ECDSA + Hash-Based Secrets",
          "author": "Amarildo <amarildocaka01@gmail@com>",
          "date": "Fri, 28 Nov 2025 07:00:04 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 14499 bytes --]\n\nHi everyone,\n\nI'd like to propose an alternative approach to quantum resistance \nfor Bitcoin that I believe is simpler than BIP-360 P2QRH.\n\n**Q-Lock: Quantum-Resistant Spending Protocol**\n\nSUMMARY:\n- Keeps ECDSA unchanged (no new signature algorithms!)\n- Adds hash-based secret layer on top\n- Uses only SHA256 + Merkle trees (proven crypto)\n- ~3 KB transactions (comparable to FALCON)\n- Two-phase commit-reveal scheme\n- Soft fork compatible\n- BIP-32 HD wallets work normally\n\nKEY INSIGHT:\nInstead of replacing ECDSA with new post-quantum algorithms \n(FALCON, SPHINCS+, Dilithium), Q-Lock adds a quantum-safe \nsecret layer. Attacker must break BOTH ECDSA AND know the \nhash preimages - quantum computers can't reverse SHA256.\n\nCOMPARISON TO BIP-360:\n- BIP-360: New lattice-based crypto, 1.3-50 KB sigs, breaks BIP-32\n- Q-Lock: Proven SHA256 crypto, ~3 KB sigs, BIP-32 works\n\nHOW IT WORKS:\n1. Setup: Generate 64 random secrets, commit via Merkle root\n2. Commit phase: Lock outputs WITHOUT exposing pubkey\n3. Reveal phase: Expose pubkey + secrets at block-hash-determined positions\n4. Quantum attacker sees pubkey too late - outputs already locked!\n\n```\nQ-Lock is a quantum-resistant spending protocol for Bitcoin \nthat adds a hash-based secret layer on top of existing ECDSA \nsignatures. It uses a two-phase commit-reveal scheme where \nspending positions are determined by the block hash, making \nit secure against quantum attackers who can break ECDSA.\n\nQ-Lock does NOT replace ECDSA. It adds quantum protection \nwhile preserving Bitcoin's existing cryptographic foundation.\n\nTransaction size: ~3 KB\nRequires: Soft fork (1-2 new opcodes)\n```\n\n-----\n\n## MOTIVATION\n\n```\nTHE QUANTUM THREAT:\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nShor's algorithm can break ECDSA by extracting private keys \nfrom public keys. When a Bitcoin transaction is broadcast, \nthe public key is exposed in the mempool. A quantum attacker \ncould:\n\n1. See public ke",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2079,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Benchmarking Bitcoin Script Evaluation for the Varops Budget (GSR)",
      "message_count": 1,
      "participants": [
        "\"'Julian' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/5906e2bb-c215-44b0-bb61-0bb91d55717dn@googlegroups.com",
          "title": "Re: [bitcoindev] Benchmarking Bitcoin Script Evaluation for the Varops Budget (GSR)",
          "author": "\"'Julian' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 28 Nov 2025 05:09:25 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 6894 bytes --]\n\nHi Russell,\n\nthanks for taking a look at the code.\n\nIn interpreter.cpp the static function EvalChecksigTapscript(...) is \nresponsible for subtracting from execdata.m_validation_weight_left, for the \noriginal SigVersion::TAPSCRIPT this is still the case, but Tapscript v2 is \nimplemented as a new SigVersion::TAPSCRIPT_V2 and therefore it will not \ntake the original sigops constraint into account (there is an if condition \nright above checking for the SigVersion).\n\nThe new varops budget replaces this sigops constraint and is contained in \nthe new EvalScript(...) overload. Currently it will only subtract from the \nbudget if the checksig succeeds, but I think this should be moved up a \nstatement, such that it will always subtract the varops cost, making the \ncost calculation more static.\n\nThe changes have not been reviewed in depth and I am looking for someone \ninterested in helping me with that.\n\n\n\nOn Monday, 10 November 2025 at 15:48:27 UTC+1 Russell O'Connor wrote:\n\nMy understanding is that in order to avoid block assembly becoming an \nNP-hard packing problem, there must be only one dimension of constraint \nsolving.  However, AFAICT, in your tarscript V2 code you have both the new \nvarops constraint and the original sigops constraint.\n\nFWIW, in Simplicity we reuse the same budget mechanism introduced in \ntapscript (V1) with our cost calculations (though our costs are computed \nstatically instead of dynamically at runtime for better or for worse).\n\nOn Fri, Nov 7, 2025 at 11:06 AM 'Julian' via Bitcoin Development Mailing \nList <bitco...@googlegroups•com> wrote:\n\nHello everyone interested in Great Script Restoration and the Varops Budget,\n\nThe main concerns that led to the disabling of many opcodes in v0.3.1 were \ndenial-of-service attacks through excessive computational time and memory \nusage in Bitcoin script execution. To mitigate these risks, we propose to \ngeneralize the sigops budget in a new Tapscript le",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2084,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: AI-assisted drafts and disclosure",
      "message_count": 1,
      "participants": [
        "Oghenovo Usiwoma"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOCjZ9RmtKWALV033EENs=wzt43GUG9k4mOeJkAzvyp2e2xj9w@mail.gmail.com",
          "title": "[bitcoindev] Re: AI-assisted drafts and disclosure",
          "author": "Oghenovo Usiwoma <eunovo9@gmail@com>",
          "date": "Thu, 20 Nov 2025 18:48:02 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2166 bytes --]\n\n> Clear disclosure of AI assistance as a process note, not a stigma.\n\nI agree with you, but I think disclosure of AI assistance will be treated\nas \"stigma\", even if that was not its intention. This is my issue with the\n\"AI-label\". If I use AI for research, do I have to add \"AI label\" to my\nBIP? at what point do I have to add the label?\n\n- Novo\n\nOn Thu, Nov 20, 2025 at 1:16 PM nt yl <wrapperband@googlemail•com> wrote:\n\n> Hi Oghenovo Usiwoma and Bitcoin Mechanic,\n>\n> You wrote:\n>\n> In my humble opinion, I believe that humans will continue to use the\n> easiest method available to them to achieve their goals. If we agree that\n> humans will do this, then there will be a lot of AI-assisted content. If I\n> did write an AI-assisted BIP draft, why would I add this \"AI-label\" to my\n> BIP when I know that it will cause reviewers to ignore it?\n>\n> As a disabled person who uses AI tools, my view is that AI will soon be\n> part of most serious workflows, much like reading the manuals and prior\n> discussions is today. Used well, it can summarise long threads, prioritise\n> issues, deduplicate proposals, and help check code for obvious bugs.\n> Refusing to use any such tools can be a step backward in productivity.\n>\n> The key is how we use them. I would support:\n>\n>    -\n>\n>    Clear disclosure of AI assistance as a process note, not a stigma.\n>    -\n>\n>    Strong norms that final authorship, technical accuracy, and\n>    accountability rest with the human proposer.\n>    -\n>\n>    Encouraging A.I. for review support, not for replacing understanding.\n>\n> This balances transparency with practical benefits and keeps the bar on\n> rigour where it belongs.\n>\n> Best,\n> Wrapper\n>\n> https://www.zerogpt.com/   0% A.I.\n>\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubsc",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2051,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Announcing Penlock v1: Paper-Based Secret Splitting for BIP39 Seed Phrases",
      "message_count": 1,
      "participants": [
        "\"'Rama Gan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/GbNAPQX2Q4TzZvS6aWLPf3iy7z1yTXVrgnPpXazBjdcWH-zROBEBieE02r6GX128LM7mml6oTzAmlboV97EWpG1ujLcVZ6fx6uihUMXxCEo=@proton.me",
          "title": "[bitcoindev] Announcing Penlock v1: Paper-Based Secret Splitting for BIP39 Seed Phrases",
          "author": "\"'Rama Gan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 20 Nov 2025 09:04:24 +0000",
          "body": "Hello everyone,\n\nI am thrilled to announce the public release of Penlock!\n\nThe goal is achieved! If you have a printer, scissors, a craft knife,\nand a pin, you can mechanically secret-split a 12-word seed phrase\nin under two hours. This includes the entire process—learning,\nprinting, assembling, executing, and storing the shares.\n\nPenlock is a printable paper calculator that guides you through\nsplitting a seed phrase into a 2-of-3 backup. It is open-source,\nuses straightforward and robust cryptography, and includes various\nfail-safes that protect against errors. A beta was announced on\nthis list last year, and the public release is now available at:\n<https://v1.penlock.io/en/>\n\nThis release breaks backward-compatibility with the beta, allowing for\nenhancements that make Penlock significantly easier to operate. Here\nare the main improvements in v1:\n\n- Faster Secret-Splitting: Penlock now focuses exclusively on producing\n2-of-3 backups using its own paper-optimized splitting algorithm. The\nprevious iteration supported K-of-M splitting with Shamir Secret\nSharing, but at the cost of more complexity and a clunkier 2-of-3\nprocess. Since 2-of-3 covers nearly all use cases, optimizing for it\nseemed like the right approach.\n\n- Backup Strategy Template: Penlock now suggests a generic, adaptable\nbackup strategy that helps set up offsite recovery and trust-minimized\ninheritance. In short, each share is tied to a different type of\nstorage: Digital, Social, and (optionally) Legal. This ensures an\nattacker would have to run two different types of attacks, and makes\nit hard for a party holding one share to obtain a second one. You\ncan find more details at <https://v1.penlock.io/en/split#strategy>.\n\n- On-Paper Error Correction: Penlock v1 introduces what I believe to\nbe the first on-paper error correction algorithm. Each BIP39 word is\nextended with two pre-computed parity symbols, guaranteeing per-word\nunambiguous correction of 1 error and detection of 2. In practice,\nit's also poss",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Improve Bitcoin’s resilience to large-scale power grid failures and Carrington-type solar storms",
      "message_count": 1,
      "participants": [
        "\"Edil Guimarães de Medeiros\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CANJiN3LnCFJxJpGxScLTqT2JF4iQNsX3hipiNiBK_OLMkkXb1g@mail.gmail.com",
          "title": "Re: [bitcoindev] Improve Bitcoin’s resilience to large-scale power grid failures and Carrington-type solar storms",
          "author": "\"Edil Guimarães de Medeiros\" <jose.edil@gmail@com>",
          "date": "Wed, 19 Nov 2025 14:04:36 -0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4863 bytes --]\n\nI don't see any specific measure that would require specific support from\nBitcoin Core, maybe you can point to more specific requirements.\nThe canonical approach is to maintain specific projects that solve specific\nproblems using one of the node interfaces (e.g. RPC).\nBut of course, anyone is free to contribute patches that might help handle\nthis kind of situation.\n\nAs you said, reorgs are expected to be gracefully handled already by the\nnode implementations.\nMost software that is tested in testnet probably also was exposed to harsh\nconditions like deep reorgs and long periods without any block being mined.\nHaving said that, the potential problem you describe is not specific to\nBitcoin and having alternative critical communication mechanisms is\ndesirable.\nBut they probably fall under the economically not viable kind of\ninfrastructure that humans have relied on governments to implement and\nmaintain, which is far from an ideal approach.\n\nAnd by the way, this is the mailing list.\n\nRegards.\n\nEm dom., 16 de nov. de 2025 às 20:00, Alexandre <alexandre.lg99@gmail•com>\nescreveu:\n\n> Hi,\n> I’m submitting this feature request to explore how Bitcoin could better\n> withstand extreme, long-lasting infrastructure failures caused by major\n> solar events. Before explaining the request itself, I want to provide a\n> brief overview of what these events are, because their scale matters.\n>\n> A large solar storm occurs when the Sun emits an intense burst of charged\n> particles and electromagnetic energy. When this material reaches Earth, it\n> can disturb the magnetic field and induce strong electric currents in long\n> conductors such as power lines. In extreme cases, this can damage\n> transformers, overload electrical grids, interrupt satellite operations,\n> and disrupt long-distance communication systems. The most famous historical\n> example is the Carrington Event of 1859, the largest geomagnetic storm ever\n> recorded. It trigge",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2114,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Standardization of On-Chain Identity Publication",
      "message_count": 1,
      "participants": [
        "\"'Edyth Kylak Johnson' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2acc9c28-6413-4147-8d11-e1ae0a677b75n@googlegroups.com",
          "title": "[bitcoindev] [BIP Proposal] Standardization of On-Chain Identity Publication",
          "author": "\"'Edyth Kylak Johnson' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 19 Nov 2025 03:54:25 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 943 bytes --]\n\nDear bitcoin-dev,\nI am submitting a draft Bitcoin Improvement Proposal titled *“Standardization \nof On-Chain Identity Publication”* for discussion. The draft specifies \ncanonical CBOR payloads, Poseidon-based `nullifier_hash` domain separation \n(`v0iden` / `v0corp`), and an optional Ed25519 signature wrapper. The \nproposal text and implementation notes are available in this \nPR: https://github.com/bitcoin/bips/pull/2038 . I welcome review and \nfeedback on interoperability, canonicalization (deterministic CBOR), and \nsecurity considerations.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/2acc9c28-6413-4147-8d11-e1ae0a677b75n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 1196 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1121,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] New bitcoin backbone code release + Tx relay v2 update",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/299d4f39-b8cd-4736-b6bb-71def4d85f74n@googlegroups.com",
          "title": "[bitcoindev] New bitcoin backbone code release + Tx relay v2 update",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Tue, 18 Nov 2025 16:01:33 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3679 bytes --]\n\nHello devs,\n\nShared new code for bitcoin backbone available on the website\n(bitcoinbackbone.org). Biggest changes from latest release has\nbeen mostly working on BIP324 re-implementation, cleaning bugs\nimplementing a simple tx-relay stack, a little mempoool buffer\nand some groundworks on address management. Tx syncing works with\nvanilla bitcoin core v0.30 software.\n\nI did a layout of the process architecture on the website, but the\nmempool is fully living in its own mempool process, fully separate\nfrom the block pipeline. In case of mempool DoS for whatever reasons,\nthe full-node keeps processing blocks. This also opens the door to\nhave *multiple* mempools with incompatible policies among themselves,\nand just select the highest fees paying graph of consensus-valid\ntransactions, after sanitizing out conflicts.\n\nAs I was writing in my latest email about bitcoin backbone, of course\nthere are some trade-offs with the mempool not living in the same memory\nspace than the validation engine, though I think you have practical\nimprovements on this area.\n\nThe simple tx-relay stack also implements a basic implementation of the\nproposed overhaul of the tx-relay v2 [0]. Currently, the tx flow is\nINV(txid) -> ; <- GETDATA(inv(txid)) ; TX(tx) -> . With the proposed \ntx-relay\nv2 overhaul, if an INV for the txid has not previously received for the\ntransaction, i.e the transaction processing has not been requested, the\ntransaction is strictly rejected, without further processing. This more\nstricter tx processing can be activated with a setting option in bitcoin\nbackbone.\n\nLong-term, I think some form of tx-relay link-level mitigation is a strong\nnecessity to diminish the surface attack of time-sensitive contracting\nprotocol in face of tx-relay throughput overflow, where a malicious peer\nis buying out your full-node tx bandwidth to tamper with the propagation\nof a time-sensitive tx (e.g a lightning's HTLC-preimage) [1].\n\nThe d",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 1,
            "text_length": 2068,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    }
  ],
  "summary": {
    "total_threads": 50,
    "total_messages": 50,
    "unique_participants": 36
  }
}