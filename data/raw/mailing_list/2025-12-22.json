{
  "source": "mailing_list",
  "list": "bitcoin-dev",
  "fetched_at": "2026-01-16T00:39:19.155031+00:00",
  "date": "2025-12-22",
  "threads": [
    {
      "title": "Re: [bitcoindev] [BIP Proposal] Add sp() output descriptor format for BIP352",
      "message_count": 1,
      "participants": [
        "Sebastian Falbesoner"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/59b1879d-b43d-41ac-9b3e-3e65cf31d4e5n@googlegroups.com",
          "title": "Re: [bitcoindev] [BIP Proposal] Add sp() output descriptor format for BIP352",
          "author": "Sebastian Falbesoner <sebastian.falbesoner@gmail@com>",
          "date": "Mon, 22 Dec 2025 12:47:10 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 20224 bytes --]\n\nHi Craig,\n\na few comments about the cost of label scanning, as this topic comes up\nrepeatedly:\n\n> The problem with this approach is that scanning for each additional label\n> adds incrementally and non-trivially to the computational burden.\n\nI think this statement is a misconception or at best only half of the truth,\nlikely based on the assumption that all existing and future SP wallets would\nimplement scanning using the same method.\n\n> For each label, there is an EC point addition and comparison against all\n> taproot outputs for an eligible transaction.\n\nIterating through labels and calculating taproot outputs to match for is \nonly\none way to implement scanning. Another one, as laid out in BIP-352 [1], is \nto\ndo it backwards: for each taproot output, subtract the output candidate and\ncheck if the result is in the label cache. One advantage of this approach is\nthat its scanning cost is independent of the number of labels to scan for, \nas\nthe lookup time in the cache is constant and efficient if a proper data\nstructure is used.\n\nTo prove that point, I've extended the scanning benchmark of the libsecp SP\nmodule PR #1765 [2] with an _actual_ label cache using a third-party hash\ntable implementation [3]:\nhttps://github.com/theStack/secp256k1/commit/f9f41adcedaca98aa4f3f65e2782e25b2124bf85\n\nThe scanning time is measured with three different label cache sizes: no\nentries (i.e. empty lookup function stub, no hash-map involved), one entry\n(\"tiny\"), and one million entries (\"huge\"). Running the benchmark for \nscanning\na transaction with 10 taproot outputs leads to the following output:\n\n$ ./build/bin/bench sp_scan_with_labels\nBenchmark                               ,    Min(us)    ,    Avg(us)    ,   \n Max(us)\n\nsp_scan_with_label_cache_empty_L=0      ,    61.3       ,    61.4       ,   \n 61.4\nsp_scan_with_label_cache_tiny_L=1       ,    61.6       ,    61.6       ,   \n 61.7\nsp_scan_with_label_cache_huge_L=1000000 ,",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Draft BIP: DustSweep – policy-only UTXO dust compaction",
      "message_count": 1,
      "participants": [
        "Defenwycke"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X8cJLJChvv3-QSGA8j5MVwgYxn1BAUeugTTgiqUWzEK_Q@mail.gmail.com",
          "title": "Re: [bitcoindev] Draft BIP: DustSweep – policy-only UTXO dust compaction",
          "author": "Defenwycke <cal.defenwycke@gmail@com>",
          "date": "Mon, 22 Dec 2025 19:33:01 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 16817 bytes --]\n\nHello Murch.\n\n\nThanks for taking the time to follow up and for spelling out the incentive\nconcerns so clearly.\n\n\nYou’re right - the recent reduction of the default minimum relay feerate to\n0.1 sat/vB materially changes the economic backdrop I was assuming. Under\nthose conditions, most consolidation is already cheap enough that a\nprotocol- or policy-level mechanism no longer makes sense, and the\nremaining friction is better addressed at the wallet/UX layer rather than\nthrough miner or relay rules.\n\n\nI agree with your point that Bitcoin policy should not rely on miners\nselling blockspace below market value, and that any mechanism that only\nencourages behavior without enforceable constraints is unlikely to be\njustified.\n\n\nI’m going to step back from this direction and reconsider the problem in a\ndifferent scope. I appreciate the careful read and the candid feedback. it\nwas helpful in clarifying where the real boundary lies.\n\n\nKind regards\n\n\nDefenwycke\n\n\n\nOn Mon, 22 Dec 2025 at 19:06, Murch <murch@murch•one> wrote:\n\n> Hi Defenwycke,\n>\n> You replied to every line of my email, except the most relevant one.\n>\n> Murch wrote:\n>  > All that said, at the new minimum feerate of 0.1 s/vB, a 148 vB P2PKH\n> input costs 15 sats, a 68 vB P2WPKH input costs 7 sats, and a 57.5 vB\n> P2TR input costs 6 sats.\n>\n> Your proposal prescribes an entire new class of transactions that are\n> managed by separate rules in a separate data structure. You propose to\n> charge 5 sats per input for those transactions, and prescribe that\n> miners should include such transactions even when they lose money by\n> doing so: at elevated feerates. Especially at high feerates, it is\n> irrational for miners to follow your proposal of selling blockspace\n> below value.\n>\n> This idea is made completely obsolete by the recent lowering of the new\n> minimum feerate. The most common inputs (P2WPKH) only cost <7 sats at\n> the new minimum feerate, and the ones th",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 3,
            "text_length": 2073,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Draft BIP: DustSweep – policy-only UTXO dust compaction",
      "message_count": 1,
      "participants": [
        "Defenwycke"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X8GtJtAgcvvPZW2Ovxt31CzGtn9tssqTSZ4BeQ_bL6pxg@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: Draft BIP: DustSweep – policy-only UTXO dust compaction",
          "author": "Defenwycke <cal.defenwycke@gmail@com>",
          "date": "Fri, 12 Dec 2025 20:17:28 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5466 bytes --]\n\nHello Jonathan,\n\nThanks for the thoughtful feedback — that makes sense.\n\nI started with a very narrow definition mostly to make the invariant\nobvious and easy to reason about. Every DustSweep tx should monotonically\nreduce the UTXO set and never meaningfully compete with the fee market. As\nlong as that holds, I’m not particularly attached to any one parameter.\n\nI agree that requiring 100% dust inputs and exactly one output is probably\noverly strict in practice. A majority dust requirement and an output/input\nratio cap seem like reasonable ways to preserve the incentive (net UTXO\nreduction) while making it more usable for real wallets.\n\nMy main goal here is to give operators something that’s safe to run and\npredictable in behaviour — cheap, bounded, and only active when blockspace\nwould otherwise go unused. I’m happy to adjust thresholds or relax\nconstraints as long as those properties remain intact.\n\nAppreciate you taking the time to look at it.\n\nKind regards,\n\nDefenwycke\n\nOn Fri, Dec 12, 2025 at 6:16 PM Jonathan Voss <k98kurz@gmail•com> wrote:\n\n> Interesting proposal. Something like that would be helpful, but perhaps it\n> would be more useful if it was not quite so narrowly defined. For example,\n> instead of requiring all inputs be dust-class UTXO, it could require a\n> minimum of 80% dust-class inputs; instead of exactly one output, it could\n> be max_outputs = floor(n_inputs / 5) to keep a maximum output/input ratio\n> of 1/5. This could allow for better aggregation of dust outputs into\n> economically meaningful, monetary outputs than the narrower definition\n> while maintaining the incentives for meaningfully reducing UTXO set size.\n>\n> I would run this policy on my node. Hashers should ultimately be okay with\n> this policy since someone among them also has to run full nodes, and it\n> would provide an additional (albeit very small) fee source when block space\n> demand is low.\n>\n> On Thursday, December 11, 20",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 3,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] CTV activation meeting #1 Notes",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-Zr9JnLcohdUQRufM42OwROcOh76fA1xjtqUkY5=otqfwg@mail.gmail.com",
          "title": "[bitcoindev] CTV activation meeting #1 Notes",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Sat, 20 Dec 2025 06:58:42 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 920 bytes --]\n\nHi everyone,\n\nWe organized an IRC [meeting][0] in #ctv-csfs-activation channel on 18\nDecember 2025 to discuss the activation parameters for BIP 119. Everyone\nagreed to use BIP 9 with conservative parameters.\n\nActivation parameters and notes: https://ctv-activation.github.io/\n\nPlease let me know if you do not agree with parameters and prefer different\ndates.\n\n[0]: https://groups.google.com/g/bitcoindev/c/JZR5cUgpfUs/m/VA9ljVQSCwAJ\n[1]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki\n\n/dev/fd0\nfloppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-Zr9JnLcohdUQRufM42OwROcOh76fA1xjtqUkY5%3Dotqfwg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1482 bytes --]",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 1080,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Hash-Based Signatures for Bitcoin's Post-Quantum Future",
      "message_count": 1,
      "participants": [
        "Olaoluwa Osuntokun"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAO3Pvs_cetTGP54zDzJJGRPeN7gXrRYGZZYk4mRYnhJQnwotdA@mail.gmail.com",
          "title": "Re: [bitcoindev] Hash-Based Signatures for Bitcoin's Post-Quantum Future",
          "author": "Olaoluwa Osuntokun <laolu32@gmail@com>",
          "date": "Tue, 9 Dec 2025 16:41:48 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 13469 bytes --]\n\nHi y'all,\n\nconduition wrote:\n> I'm personally hoping that we'll find a way to derive child pubkeys using\n> lattices (ML-DSA) and/or isogenies (SQIsign), but I haven't heard of any\n> solid proposals yet.\n\nThis paper [1] proposes a variant of Dilithium (dubbed DilithiumRK, RK for\n'randomized keys' presumably) that enables BIP-32-like functionality. It\nachieves this by getting rid of a public key compression step in the OG\nalgorithm that results in a loss of homomorphic properties. There're\nalgorithmic changes required (eg: a new public network param is needed\nwhich is used for seed/key generation), so it isn't vanilla FIP 204.\n\nAside from the deviation from the standard, the scheme introduces some\nadditional trade offs:\n\n  * Signatures arger as signatures carry a new error hint\n\n  * Signing is 2.7x slower\n\n  * Verification is 1.75x slower\n\nThere's also a published BIP-32-like like scheme for Falcon signatures [2].\nI'm\nless familiar with the details here, but the signature size blows up to\n~24KB compared to ~666 bytes for normal Falcon signatures.\n\n-- Laolu\n\n[1]: https://cic.iacr.org/p/2/3/3\n\n[2]: https://link.springer.com/article/10.1186/s42400-024-00216-w\n\n\nOn Mon, Dec 8, 2025 at 10:49 PM 'conduition' via Bitcoin Development\nMailing List <bitcoindev@googlegroups.com> wrote:\n\n> Great work Jonas and Mikhail, glad to see more eyes and ears surveying\n> these schemes and their potential. Also shameless plug for some of my\n> prior work <https://conduition.io/code/fast-slh-dsa/> on related topics\n> <https://conduition.io/cryptography/quantum-hbs/>.\n>\n> The post-quantum HD wallet derivation problem is one i've been thinking\n> about a lot lately. Due to the lack of algebraic structure in SLH-DSA it's\n> gonna be impossible to fully emulate BIP32 with that scheme alone. I'm\n> personally hoping that we'll find a way to derive child pubkeys using\n> lattices (ML-DSA) and/or isogenies (SQIsign), but I haven't heard of any\n",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2073,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Hash-Based Signatures for Bitcoin's Post-Quantum Future",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgL-VBTgbacpbPStGMqe6u6Y7wB6fWNiGy28zWfkCODp=A@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: Hash-Based Signatures for Bitcoin's Post-Quantum Future",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Fri, 19 Dec 2025 17:14:05 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2019 bytes --]\n\nthis scheme has no mitm attack or replay attack because of the use of\ncovenants to secure each step in the chain\n\nThe best part about starting with something like this is that we can have a\nsafe quantum vault, too useful covenants that are broadly helpful for other\nvaulting schemes, while we develop a proper library that is both performant\nand efficient for quantum signatures.\n\nsecp256k1 has been optimized to the point where timing attacks are\nchallenging, and I wouldn't want to use some sort of quantum library that\nhasn't had that level of optimization.\n\nsimple commit reveal schemes use hashes that are well known to be quantum\nresistant. I consider that a lot safer at first step forward. especially\nbecause we can take that step sooner than later without too much discussion\nover implementation since the underlying covenants have been well studied.\n(txhash and ctv)\n\nwe can't say that about any signature schemes.\n\n\n\nOn Fri, Dec 19, 2025, 3:34 AM Jonas Nick <jonasd.nick@gmail•com> wrote:\n\n> This appears to be a variant of a commit-reveal scheme, a design that has\n> been\n> discussed a few times on this mailing list. Commit-reveal schemes come with\n> their own set of trade-offs.\n>\n> --\n> You received this message because you are subscribed to the Google Groups\n> \"Bitcoin Development Mailing List\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to bitcoindev+unsubscribe@googlegroups•com.\n> To view this discussion visit\n> https://groups.google.com/d/msgid/bitcoindev/b6df02a0-8d69-4882-a13c-411bc90adfa1%40gmail.com\n> .\n>\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAJowKgL-VBTgbacpbPStGMqe6u6Y7wB6fWNiGy",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Major BIP 360 Update",
      "message_count": 1,
      "participants": [
        "Hunter Beast"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/7edb8e8f-064b-4409-9c6d-b4361c1e7df7n@googlegroups.com",
          "title": "[bitcoindev] Major BIP 360 Update",
          "author": "Hunter Beast <hunter@surmount@systems>",
          "date": "Fri, 19 Dec 2025 12:45:43 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 1846 bytes --]\n\n\n\nAfter reviewing community feedback, Ethan Heilman and I have enlisted the \nhelp of a third co-author, Isabel Foxen Duke <https://x.com/isabelfoxenduke>, \nin an editorial role to lead and execute a clean sheet rewrite of BIP 360.\n\nBecause previous revisions introduced meaningful technical changes, we \ndetermined that a full rewrite, rather than incremental edits, was \nwarranted to improve clarity, internal coherence, and to better articulate \nour intentions for managing potential quantum-related risks.\n\nConsistent with its previous version, this proposal does not introduce \npost-quantum signature schemes. Instead, BIP 360 proposes the addition of a \nnew output type with the key path spend removed, which is thus protected \nfrom hypothetical breaks of Elliptic Curve Cryptography (ECC).\n\nWe have renamed this proposed output type \"Pay-to-Tapscript-Hash (P2TSH)\" \nfor clarity, and believe its adoption is an important first step in \nprotecting Bitcoin from potential threats to ECC, via quantum computers or \nany other cryptanalytic advancements.\n\nAdditionally, the proposal now includes test vectors in Python and Rust.\nWith gratitude, we hope you’ll review these changes in the BIP Repo \n<https://github.com/bitcoin/bips/pull/1670> or at BIP360.org \n<http://bip360.org>. We look forward to ongoing community feedback, and new \nideas in our efforts to Make Bitcoin Quantum Resistant.\n\nThank you for your time,\nHunter Beast\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/7edb8e8f-064b-4409-9c6d-b4361c1e7df7n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 10393 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1965,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] op_ctv still has no technical objections",
      "message_count": 1,
      "participants": [
        "\"'moonsettler' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/ZDIGYB4Jcy6DGEkUGxEIBgmD0WhaNQh8X3ovu6bVwnBQ4jCQS84dkG22oLR0XJmgG0emYj9eg1mwU3I0gZtKfpovVCjlXh5FsfO0UmelT-c=@protonmail.com",
          "title": "Re: [bitcoindev] op_ctv still has no technical objections",
          "author": "\"'moonsettler' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 19 Dec 2025 14:58:19 +0000",
          "body": "Hi All,\n\nJust a small remark\n\n> lnhance is more comprehensive. but also it's so much harder to reason about three separate op codes and what the attack surface could be.\n\nIt's 4 opcodes, but ofc it's safe to ignore INTERNALKEY when it comes to unexpected interactions.\nWe have spent basically a whole year on walking in circles with various opcode combos.\n\nWe came up with a set of threshold rules that make sense as an evaluation framework:\n- Fine-grained introspection\n- State-carrying covenants\n- Bigint operations\n- New arithmetic capabilities using lookup tables\n\nThese are key \"ingredients\" to exogenous asset protocols that are script interactible and novel bridge\nconstructions, that might interact badly with mining decentralization.\n\nMany other proposals instantly violate some or all of them, not LNhance.\nTo this day I haven't seen anyone come up with anything remotely scary with CTV+CSFS+PC.\n\nI would like to encourage people to take the time and try to come up with anything \"nasty\".\n\nBR,\nmoonsettler\n\n\nSent with Proton Mail secure email.\n\nOn Thursday, November 27th, 2025 at 10:18 AM, Erik Aronesty <erik@q32•com> wrote:\n\n> It's been many years and there's been a lot of discussion about various covenants\n> I think one of the biggest problems is everyone has to insist on their baby is the best baby.\n>\n> op_ctv is quite literally not the best at anything. That's the whole point. It's non-recursive, can't be used for strange or dangerous things, and can be used to emulate a lot of other opcodes.\n>\n> It's adequate. And I don't think we want anything \"better\" than adequate the first time around. lnhance is more comprehensive. but also it's so much harder to reason about three separate op codes and what the attack surface could be.\n>\n> I don't think it's possible to optimize a series of covenants for all possible scenarios. Easy to make them too powerful and now nodes are doing too much work and we're attracting the kind of network activity that nobody wants.\n>\n> Fortunatel",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Re: op_ctv still has no technical objections",
      "message_count": 1,
      "participants": [
        "\"'conduition' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2914ad6f-7e1a-42b6-9c25-87ac48c63228n@googlegroups.com",
          "title": "[bitcoindev] Re: op_ctv still has no technical objections",
          "author": "\"'conduition' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 27 Nov 2025 18:04:28 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2607 bytes --]\n\nAs someone who has had a merely passive interest in covenants tech, I can \nconfidently say that OP_CTV is probably the only covenants proposal whose \neffects I can confidently say I fully grasp. It's also easy to explain to \nothers. Not saying i'm not in favor of more complex multi-pronged upgrades \nlike LNHANCE, just saying I don't fully understand their opcode interplay \nenough to say yay/nay. Which is maybe an under-represented argument in \nfavor of plain OP_CTV.\n\nregards,\nconduition\n\nOn Thursday, November 27, 2025 at 1:18:03 AM UTC-8 Erik Aronesty wrote:\n\n> It's been many years and there's been a lot of discussion about various \n> covenants \n>\n> I think one of the biggest problems is everyone has to insist on their \n> baby is the best baby. \n>\n> op_ctv is quite literally not the best at anything.  That's the whole \n> point.  It's non-recursive, can't be used for strange or dangerous things, \n> and can be used to emulate a lot of other opcodes. \n>\n> It's adequate.  And I don't think we want anything \"better\" than adequate \n> the first time around. lnhance is more comprehensive.  but also it's so \n> much harder to reason about three separate op codes and what the attack \n> surface could be.\n>\n> I don't think it's possible to optimize a series of covenants for all \n> possible scenarios.  Easy to make them too powerful and now nodes are doing \n> too much work and we're attracting the kind of network activity that nobody \n> wants.  \n>\n> Fortunately the risk of CTV is fairly low.  It's always possible to turn \n> it off (no new tx)... if there's a game theory issue. \n>\n> I don't think there's any particular rush, but we could lose a lot of fees \n> and support for miners if Bitcoin continues to do what it is doing now... \n> scaling almost entirely in custodial systems.  That's also just not the \n> Bitcoin that anyone loves.\n>\n> At this point it feels like it's \"perfect is the enemy of the good\".  \n>\n> We have ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Secondary mailing list for moderated emails",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-ZqQGkEJXxVPSMmXYC1qTafAFShx=2QrMS5mkm-y6M=+nQ@mail.gmail.com",
          "title": "[bitcoindev] Secondary mailing list for moderated emails",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Fri, 19 Dec 2025 17:11:13 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 874 bytes --]\n\nHi everyone,\n\nThe old bitcoin-dev mailing list had a secondary mailing list for moderated\nemails:\nhttps://lists.ozlabs.org/listinfo/bitcoin-dev-moderation\n\nI have created a similar list for bitcoindev@googlegroups.com, with the\nemail address\nbitcoin-dev-moderation@googlegroups•com. If your email is moderated and you\ncannot see it on\nhttps://groups.google.com/g/bitcoindev/, please resend it with the\nmoderation list email address\nin the Cc or Bcc.\n\n /dev/fd0\n floppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-ZqQGkEJXxVPSMmXYC1qTafAFShx%3D2QrMS5mkm-y6M%3D%2BnQ%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1450 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1046,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Peer Feature Negotiation",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aUUXLgEUCgGb122o@erisian.com.au",
          "title": "[bitcoindev] [BIP Proposal] Peer Feature Negotiation",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Fri, 19 Dec 2025 19:13:18 +1000",
          "body": "Hello world,\n\nI've been thinking recently about a few ideas that would benefit\nfrom new p2p messages, namely template sharing [0], updating the\nbip324-one-byte-message-types [1], and sharing recent stale blocks [2].\nThat's made me want to make sure that we've got a good way of negotiating\nnew features, and revisiting the ideas from the 2020 thread [3] has me\nstill liking the \"FEATURE\" message idea [4].\n\nAs such, and with Ava's recent exhortation that everyone should be\nwriting BIPs [5] in mind, I've written a BIP:\n\nhttps://github.com/ajtowns/bips/blob/202512-p2p-feature/bip-peer-feature-negotiation.md\n\nSample code, though that part isn't really very interesting:\n\nhttps://github.com/ajtowns/bitcoin/commit/80301f0040fe6048a85b89d0fdf0ffcca836a1d0\n\nThe BIP is perhaps a bit over-engineered at this point for what it does,\nbut I figure better to be over-engineered than under-. And in any event,\nthere was some degree of breakage with the SENDADDRV2's deployment [6,7]\nwhich would be good to avoid repeating. In any event, the BIP text has\na bunch more background, etc.\n\nComments welcome.\n\nCheers,\naj\n\n[0] https://github.com/bitcoin/bitcoin/issues/33691\n\n[1] https://github.com/bitcoin/bips/pull/1378#discussion_r2585766526\n\n[2] https://github.com/bitcoin-data/stale-blocks\n    The idea behind sharing stale blocks (or headers) more proactively,\n    is it better insight into the orphan rate, and whether hashrate\n    is extending the chain vs potentially creating a reorg; and also\n    potentially makes syncing to the new tip after a reorgs more\n    efficient, as you'll have already downloaded the parent of the new tip\n\n[3] https://gnusha.org/pi/bitcoindev/CAFp6fsE=HPFUMFhyuZkroBO_QJ-dUWNJqCPg9=fMJ3Jqnu1hnw@mail.gmail.com/\n\n[4] https://gnusha.org/pi/bitcoindev/20200821023647.7eat4goqqrtaqnna@erisian.com.au/\n\n[5] https://x.com/btcplusplus/status/2000489894515253529\n\n[6] https://github.com/btcsuite/btcd/issues/1661\n\n[7] https://github.com/bitcoin/bitcoin/pull/20564\n\n-- \nYou received th",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2053,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] The Cat, BIP draft discussion.",
      "message_count": 1,
      "participants": [
        "Greg Maxwell"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAAS2fgQLKD1-DomvniTHLTvw52yeaKmOG-K__TnZeYJ+c2hYFA@mail.gmail.com",
          "title": "Re: [bitcoindev] The Cat, BIP draft discussion.",
          "author": "Greg Maxwell <gmaxwell@gmail@com>",
          "date": "Mon, 15 Dec 2025 16:04:27 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 8747 bytes --]\n\nOn Mon, Dec 15, 2025 at 10:35 AM Nona YoBidnes <pepehodler@gmail•com> wrote:\n\n> Here, your argument runs completely opposite of the claim that \"the miner\n> fees are the filter\". You appear to be claiming that dping nothing about\n> spam, making it easier for spammers and being more accommodating to them is\n> the way to go. Unfortunately, that's the approach we have taken for the\n> last 3 years while spam only gets worst.\n>\n\nOn what basis do you claim that spam has 'only gotten worse'--  the\nexisting setup is incredibly effective against spam, essentially blocking\nall forms of pointless data storage that aren't made more valuable by the\nlimitations.  What does go in, goes in at extremely high costs to the\nspammer.\n\nOf what concern is this residual traffic to Bitcoin use?  It doesn't\nincrease node resource use as that's governed by the capacity limits, in\nfact because it's generally much easier to process it speeds up block\nprocessing.  It's substantially a non-issue.\n\nThe proposed gain is some negligible one time reduction in utxo disk space.\n>\n>\n> Between 40 and 50% of the UTXO set is comprised of spam UTXOs with dust\n> amounts. Even more conservative estimates put it at 30%. The Cat would\n> remove those spam NMUs from the UTXO set. I hardly view that as negligible.\n>\n\nIt is negligible-- it's just a one time constant fraction.  It will not\nincrease the set of devices that can run a node in any meaningful sense.\nWhat improvement it provides could also be alternatively achieved through\nlocal only technical changes like changing how the data is stored.\n\nFurthermore, The Cat would send a strong signal to spammers: you are not\n> welcomed on Bitcoin, we are rugging you, and we might do it again. This\n> likely would reduce future spam activity on Bitcoin, further protecting the\n> UTXO set.\n>\n\nAs I've pointed out, it won't stop their NFTs.  They'll simply make a new\nrule in their NFT indexers that says that deleted N",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2048,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: The Cat, BIP draft discussion.",
      "message_count": 1,
      "participants": [
        "Greg Maxwell"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAAS2fgSEX0dcg73qnrj5uP64Xaw=ukj7fhzng_1gT3BntjocNQ@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: The Cat, BIP draft discussion.",
          "author": "Greg Maxwell <gmaxwell@gmail@com>",
          "date": "Fri, 19 Dec 2025 03:31:29 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3224 bytes --]\n\nI received no prior response from you, so I suspect the issue is on your\nend-- since if you sent one I would normally have been directly copied.\n\nIn any case, your message makes no sense. If an output is provably\nunspendable then it is unspendable.  No amount of \"clever steganography\"\ncan change that.   If you're imagining that perhaps they are *presumed* to\nbe unspendable but actually *are* spendable, then sure that would be an\nissue but with any change to consensus relevant code great care must be\ntaken to not introduce errors.  Actually *making* a consensus change would\nonly increase the potential for mistakes.\n\nThese costs are just another reason why this hysteria over a non-issue is\nmisplaced.\n\nBut in any case it is better that (any) implementations that care about\nstamps put in the effort to define their exclusions in ways that are safe\nthan to burden everyone with a consensus change that doesn't care about it.\n\n\nOn Fri, Dec 19, 2025 at 1:49 AM Jonathan Voss <k98kurz@gmail•com> wrote:\n\n> This is my third attempt to respond to this. Idk what is going wrong here.\n>\n> The problem with dropping Bitcoin Stamps UTXOs from the UTXO set without a\n> consensus change is that a clever use of steganography could cause one of\n> those otherwise unspendable outputs to be spendable, thus causing a fork\n> between those nodes that adopted the Stamp pruning method and those that\n> did not once one of those steganographic Stamps is spent. Though this is\n> unlikely, it is still technically possible, and I would not put it past the\n> denizens of the Internet to stir up trouble just for its own sake.\n>\n> On Friday, December 12, 2025 at 6:49:41 PM UTC-5 Greg Maxwell wrote:\n>\n>> On Fri, Dec 12, 2025 at 9:26 PM Jonathan Voss <k98...@gmail•com> wrote:\n>>\n>>> Since the Bitcoin Stamps outputs are already unspendable, it makes\n>>> perfect sense to mark and drop them from the UTXO set.\n>>\n>>\n>> There is no consensus change involved ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2052,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Perhaps the simplest possible quantum-security upgrade",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgLR+vjYrUXuJ-k3FZ9=ZnOj3f3w2qB==M7-yrbQYx_h2A@mail.gmail.com",
          "title": "[bitcoindev] Perhaps the simplest possible quantum-security upgrade",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Wed, 17 Dec 2025 12:57:42 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3408 bytes --]\n\nWas thinking about this and I realized that a quantum-resistance scheme\ndoesn't technically need a new \"signature\" - because those constraints\n(generality) are far harder than needed for Bitcoin's \"proof of utxo\nownership\".\n\nInstead of new signatures, I propose a chain-native authorization primitive\nwhose security is bounded by the same economic assumptions as transaction\nfinality itself. The objective is a quantum migration path that can be\ndeployed immediately, does not require large witnesses, remains cheap to\nvalidate, and does not rely on assumptions stronger than those already\nrequired to trust confirmed spends.\n\nThe construction relies on a minimal new introspection primitive rather\nthan a wholesale redesign of Script. A single opcode exposes a\nchain-derived challenge tied to the spent output, defined as the block hash\nat a selectable offset from the block in which the UTXO was created. The\noffset is fixed by the locking script and can be chosen to reflect the\nvalue at risk. Larger offsets correspond to deeper confirmation depth and\nhigher economic resistance to manipulation (an enforced confirmation wait).\nExisting timelock opcodes already enforce the required delay; the only\nmissing element is access to this chain-defined value.\n\n*This is commit–challenge–response (Σ-protocol–derived) authentication*,\nbut the challenge is provided by *the future chain*.   This is a well known\nscheme.\n\nAuthorization is conjunctive, not alternative. A valid spend must satisfy\nboth a traditional signature check and a delayed, chain-conditioned\nhash-based proof. The traditional signature preserves today’s security\nassumptions and compatibility, while the chain-conditioned proof adds a\nquantum-resistant requirement that cannot be bypassed by a quantum\nadversary. Either condition alone is insufficient. This ensures the scheme\nis strictly at least as secure as current authorization and strictly\nstronger against quantum-cap",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2068,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: Perhaps the simplest possible quantum-security upgrade",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgKcRN6QOKFdvMDdrZVcFGu+hrrCMiB+B9HVdM2RXphQAQ@mail.gmail.com",
          "title": "[bitcoindev] Re: Perhaps the simplest possible quantum-security upgrade",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Thu, 18 Dec 2025 08:11:13 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4185 bytes --]\n\nI wrote the python code for this.  It was a little trickier to get it right:\n\nhttps://gist.github.com/earonesty/ea086aa995be1a860af093f93bd45bf2\n\nSpender publishes an ephemeral anchor tx committing to a future secret\nwithout revealing the secret in one block.\n\nSpender publishes the revealed secret and spend in a future block.\n\nNew opcode needs to verify that the anchor tx was published at least N\nblocks prior to the spend block.\n\nThis creates the necessary information asymmetry without being a true\nsignature, relying on asymmetry-over-time to protect against quantum\nthreats.\n\n\n\nOn Wed, Dec 17, 2025 at 12:57 PM Erik Aronesty <erik@q32•com> wrote:\n\n> Was thinking about this and I realized that a quantum-resistance scheme\n> doesn't technically need a new \"signature\" - because those constraints\n> (generality) are far harder than needed for Bitcoin's \"proof of utxo\n> ownership\".\n>\n> Instead of new signatures, I propose a chain-native authorization\n> primitive whose security is bounded by the same economic assumptions as\n> transaction finality itself. The objective is a quantum migration path that\n> can be deployed immediately, does not require large witnesses, remains\n> cheap to validate, and does not rely on assumptions stronger than those\n> already required to trust confirmed spends.\n>\n> The construction relies on a minimal new introspection primitive rather\n> than a wholesale redesign of Script. A single opcode exposes a\n> chain-derived challenge tied to the spent output, defined as the block hash\n> at a selectable offset from the block in which the UTXO was created. The\n> offset is fixed by the locking script and can be chosen to reflect the\n> value at risk. Larger offsets correspond to deeper confirmation depth and\n> higher economic resistance to manipulation (an enforced confirmation wait).\n> Existing timelock opcodes already enforce the required delay; the only\n> missing element is access to this chain-def",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Does GCC preclude a soft fork to handle timestamp overflow?",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a7m01C4Xm3-WF9Slrg1b2G8OaZiCXKQncrHW4kD5iVrNq8E-yde2W4pF1ZIU6PeiU-jUeyDCsFntfrTw28wW38iIkBeo6OENzlWUsL-hetc=@protonmail.com",
          "title": "Re: [bitcoindev] Does GCC preclude a soft fork to handle timestamp overflow?",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 17 Dec 2025 14:55:40 +0000",
          "body": "Hi Josh,\n\nInteresting observation!\n\nI am of the opinion that the header timestamp overflow is one of those things\nthat are better addressed through a backward-incompatible consensus change. As\npointed out earlier in response to your post, the MTP rule would prevent a chain\nsplit by making sure the legacy chain halts.\n\nFurthermore, even if it was a goal to fix the timestamp overflow through a soft\nfork, the issue will arise so far in the future that it does not justify making\ninferior protocol decisions to fix bugs that exist today (and that could become\nmore problematic within the next decade).\n\nYou came up with a clever hack to address the DoS concern, which somewhat\nreminds me of forward blocks. It makes it possible to still validate cumulative\nwork from a chain of headers, but it relies on actively exploiting Timewarp\nthere. This is unfortunate in itself but also means breaking timestamp-based\ntimelocks which, as people pointed out here and on your Delving thread, entails\nfreezing coins that rely on them.\n\nTherefore my preference is to fix properly Timewarp with BIP 54, and properly\ndeal with the timestamp overflow when (if?) necessary.\n\nBest,\nAntoine Poinsot\n\n\nOn Monday, December 15th, 2025 at 2:30 PM, Josh Doman <joshsdoman@gmail•com> wrote:\n\n> > your idea is to have the header nTime used for difficulty adjustment enforced in the coinbase tx.\n> Correct. As written, BIP54 makes that soft fork impossible, leaving a hard fork as the only option to resolve nTime overflow.\n> \n> > I was about to write this email myself, but then I realized that since BIP 113, timelocks are based on MTP time, and any soft-fork mechanism that messes with MTP time will destroy existing transaction's timelock semantics.\n> \n> Yes, it's unfortunate. There is certainly a tradeoff. On the one hand, there is a risk of coin confiscation, if the soft fork isn't signaled early enough (a few decades in advance is probably sufficient). On the other hand, there are material benefits to avoiding a h",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2077,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Motion to Activate BIP 3",
      "message_count": 1,
      "participants": [
        "Mat Balez"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABd6=MPtx9rN2ZtTz7CbT-zb-3qVUecZZrmb56aFyCSVeLxsEQ@mail.gmail.com",
          "title": "Re: [bitcoindev] Motion to Activate BIP 3",
          "author": "Mat Balez <matbalez@gmail@com>",
          "date": "Thu, 20 Nov 2025 12:14:09 -0800",
          "body": "[-- Attachment #1: Type: text/plain, Size: 14565 bytes --]\n\nMore and more of writing by all humans, including BIP proposers, will\ninevitably involve AI in some more or less significant way. I don't expect\npeople to reliably express the degree to which AI was used to inform the\nthinking behind the BIP, or the writing itself. I'm not aware of any common\nstandard we would use to express those things. Adversarially, we have to\nassume people won't do it if it's not in their interests.\n\nRather, I think the expectation should be that BIP proposers are entirely\nresponsible for submitting high quality BIPs and they take ownership for\nwhat they are submitting (submitting garbage burns your rep, always has and\nalways will). BIP reviewers should simply assume for all BIPs that AI was\nlikely used significantly to create them, and judge BIPs only on the merit\nof the ideas and content.\n\nBecause of the advent of LLMs (and their inevitable continued improvement)\nthis will almost certainly result in an increased number of BIPs being\nadvanced, many of low (slop-filled) quality but also, hopefully, more high\nquality ones as well—proposals that might not otherwise have seen the light\nof day and/or proposals themselves being strengthened with better\narguments, ideas and language.\n\nThe solution to such a rise in volume IMO is that BIP reviewers should also\nequip themselves with LLMs and other AI-powered tools to help\nfilter/triage/assess BIPs to get a handle on the rise in noise level. Yet,\njust like BIP proposers, the onus should be on BIP reviewers to take\nownership for the quality of the decision-making around BIP quality and\nthat it not ever be entirely automated but retain \"human in the loop\"\njudgment—at least for the foreseeable future—just made more efficient and\neffective through the use of AI.\n\nOn Thu, Nov 20, 2025 at 1:47 AM Oghenovo Usiwoma <eunovo9@gmail•com> wrote:\n\n> > I think it makes sense to request that submissions should state if - and\n> to what degree - AI has been use",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2042,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Motion to Activate BIP 3",
      "message_count": 1,
      "participants": [
        "Greg Sanders"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/899eb548-3e3b-4b85-8ae0-1e64d15f1b86n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: Motion to Activate BIP 3",
          "author": "Greg Sanders <gsanders87@gmail@com>",
          "date": "Thu, 13 Nov 2025 10:54:20 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 7475 bytes --]\n\nMakes sense to me, and this e-mail can be a reference point if there's \nfuture discussion.\n\nWith what little review I've done, I think this makes sense to activate!\n\nGreg\n\nOn Wednesday, November 12, 2025 at 7:30:59 PM UTC-5 Murch wrote:\n\n> Hey Greg,\n>\n> Two sections from BIP 3 stand out as relevant here, “BIP Ownership“ and \n> “Deployed Process BIPs”.\n>\n> From “Fundamentals > BIP Ownership”:\n> > “[…] As a BIP progresses through the workflow, it becomes \n> increasingly co-owned by the Bitcoin community.”\n>\n> While Deployed BIPs are considered final and changes should be avoided, \n> the section has a subsection that specifically addresses Process BIPs.\n>\n> From “Workflow > Progression through BIP Statuses > Deployed > Process \n> BIPs”:\n> > “A Process BIP may change status from Complete to Deployed when it \n> achieves rough consensus on the Bitcoin Development Mailing List. A \n> proposal is said to have rough consensus if its advancement has been \n> open to discussion on the mailing list for at least one month, the \n> discussion achieved meaningful engagement, and no person maintains any \n> unaddressed substantiated objections to it. Addressed or obstructive \n> objections may be ignored/overruled by general agreement that they have \n> been sufficiently addressed, but clear reasoning must be given in such \n> circumstances. Deployed Process BIPs may be modified indefinitely as \n> long as a proposed modification has rough consensus per the same criteria.”\n>\n> More specific rules supersede general rules, so this subsection on \n> Process BIPs should hopefully clearly override the general description \n> in “Deployed”. It follows from these two sections that the BIP Authors’ \n> right to decide about changes to their BIP is moderated by the community \n> interests. I would consider especially Process BIPs to be dominantly \n> owned by the community rather than the Authors once they are Deployed. \n> The quoted section s",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2046,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [Discussion] Year 2106 Timestamp Overflow - Proposal for uint64 Migration",
      "message_count": 1,
      "participants": [
        "Henry Romp"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPnXYtPdbFwc1mOsP2eHQBwuJhn2XxLCWC-pt6+N-bu3BRRbiA@mail.gmail.com",
          "title": "Re: [bitcoindev] [Discussion] Year 2106 Timestamp Overflow - Proposal for uint64 Migration",
          "author": "Henry Romp <151henry151@gmail@com>",
          "date": "Mon, 15 Dec 2025 14:09:50 -0500",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3513 bytes --]\n\nAh, I see you're right—once MTP reaches 2^32 - 1, no valid timestamp can\nexceed it, making the next block mathematically impossible.\nI was wrong about the halt. I still maintain my other points about timeline\nand opportunity costs.\n\n\nHenry\n\n\n\n*Henry Romp802-458-7299 <8024587299>*\n*151henry151@gmail•com <151henry151@gmail•com>*\n\n\n\nOn Mon, Dec 15, 2025, 04:59 Garlo Nicon <garlonicon@gmail•com> wrote:\n\n> > The blockchain won't \"halt\" at overflow, it will have validation\n> problems.\n>\n> These \"validation problems\" will be quite serious. For example: it will be\n> possible to produce a chain with a bigger chainwork, and pass it to the old\n> nodes.\n>\n> Which means, that the chain can go forward for the new nodes, while being\n> perceived as a constantly reorged, by the old implementation.\n>\n> And then, the question is: do we want to design a new soft-fork in a way,\n> where it would be seen as constantly-reorged chain by the old nodes?\n>\n> > The overflow doesn't automatically stop the chain.\n>\n> It will, because overflowed timestamps from 1970 will be rejected by all\n> old nodes.\n>\n> > At that point there are no more valid blocks that can be appended to the\n> chain.\n>\n> As long as the chainwork won't overflow, you can always reorg the old\n> blocks. If that reorg will be deterministic, and accepted by hashrate\n> majority, then it will be seen only by old nodes. New nodes can see a\n> stable chain, always going forward, beyond 0xffffffff.\n>\n> Anyway, it will be just one-bit increment per 136 years.\n>\n> niedz., 14 gru 2025 o 15:09 'Russell O'Connor' via Bitcoin Development\n> Mailing List <bitcoindev@googlegroups.com> napisał(a):\n>\n>> On Sat, Dec 13, 2025 at 5:05 AM Henry Romp <151henry151@gmail•com> wrote:\n>>\n>>> The blockchain won't \"halt\" at overflow, it will have validation\n>>> problems. The overflow doesn't automatically stop the chain. Nodes would\n>>> continue with wrapped-around timestamps (though this would cause ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 0,
            "text_length": 2091,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Add PSBT_IN_SP_TWEAK field",
      "message_count": 1,
      "participants": [
        "\"'nymius' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/R53cG3TeXgXDUUS4kH_q226GlaFCjI0DZVT6mdTQzSQdj3RnNqWA-bFT7uGgGQFJG6938kDGvDJVoFQj8ItEMsJ6NyOjCTvpVEarYiyW6-8=@proton.me",
          "title": "[bitcoindev] [BIP Proposal] Add PSBT_IN_SP_TWEAK field",
          "author": "\"'nymius' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Mon, 15 Dec 2025 08:00:01 +0000",
          "body": "[-- Attachment #1.1.1: Type: text/plain, Size: 5112 bytes --]\n\nHi all,\nI'm working on the implementation of silent payments in BDK.\n\nBDK's transaction creation process is structured around PSBTs. Because of this, a stable implementation of silent payments in the project depends of the specifications of BIP 352 for this format. BIP 375 and BIP 374 are core component for this.\n\nHowever, there is a need for the inclusion of silent payments tweaks in PSBTs to spend silent payment outputs, which was considered before [1][2] but never specified.\n\nI would like to propose the following as a base for a new BIP proposal addressing this gap:\n\n### Abstract\n\nThis document proposes additional fields for BIP 370 PSBTv2 that allow for BIP 352 silent payment tweaks to be included in a PSBT of version 2. These will be fields for scripts that are relevant to the spending of silent payment outputs, but may be also useful to other protocols using taproot tweaks not following BIP 340 spec.\n\n### Motivation\n\nBIPs 352 specify silent payments protocol, which provides a new way to create P2TR outputs and spend them. The existing PSBT fields are unable to support silent payments without changes, due to the new method by which outputs are created. BIP 375 and complementary BIP 374 specify how to create outputs locked with silent payment keys using PSBTs. But they don't specify how to unlock these outputs in a transaction. Therefore new fields must be defined to allow PSBTs to carry the information necessary for tweaking taproot keys without following the BIP 340 tagging scheme.\n\n### Specification\n\nThe new per-input types are defined as follows:\n\n| Name              | \\<keytype\\>               | \\<keydata\\> | <keydata\\><br>Description | \\<valuedata\\>    | \\<valuedata\\><br>Description                                                                                 | \\<Versions Requiring Inlusion\\> | \\<Versions Requiring Exclusion\\> | \\<Versions Allowing Inclusion\\> |\n| ----------------- | --------",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2055,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Splitting more block, addr and tx classes of network traffic",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALZpt+Hx9vFwNQd6qGSFMWXU=A6j82m6ZjJg3JaHK26WW0UQZw@mail.gmail.com",
          "title": "[bitcoindev] Splitting more block, addr and tx classes of network traffic",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Thu, 4 Dec 2025 22:33:43 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3714 bytes --]\n\nHi list,\n\nSurfacing an old idea concerning the network-level and the current meddling\nof block,\ntx and addr messages traffic generally all over one network link.\nHistorically, for\nexample, if you consider bitcoin core by default connections are going to\nbe FULL_RELAY.\nOver the last years, there has been few improvements to separate network\nlinks by types\ne.g with the introduction of dedicated outbound BLOCK-RELAY connections\n[1], without the\nsegregation at the network-level between the class of traffic really being\npursued, or at\nleast more flexibility in network mechanisms to signal to a node's peers\nwhat categories\nof messages will be processed on a given link.\n\nPreviously it has been shown that leveraging tx-relay's orphan mechanism\ncan allow to map\na peer's network-topology [2] (sadly, one trick among others). Being able\nto infer a peer's\n\"likely\" network topology from tx traffic, one can guess the peers used to\ncarry block-relay\ntraffic. From the PoV of an economical node, dissimulating the block-relay\ntraffic is a very\nvaluable to minimize the risks of escalation attacks based on\nnetwork-topology (e.g for\nlightning nodes [3]).\n\nSegregating more network traffic by class of messages sounds to suppose 1)\nbeing able to signal\namong the {ADDR, ADDRV2} service bits if block, addr or tx relay is\nsupported on a link to be\nopened for a pair of a (net_addr, port) or alternatively 2) if network link\nare open blindly\nwith peers, being to signal in the VERSION message or with a dedicated\nmessage what class of\nmessage is supported. There is already a signaling mechanism in the VERSION\nmessage to\ndisable tx-relay (i.e `fRelay`), however there is no signaling to disable\nblock-relay over a link.\nAlternatively, it has been proposed in the past to add a new early message\namong all the other\nhandshake messages between the VERSION / VERACK flow, but it has never been\nimplemented [4].\n\nFor bitcoin backbone, started to nativ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2074,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: Splitting more block, addr and tx classes of network traffic",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/7cceae55-0885-4a66-9e1f-55e1537e2e17n@googlegroups.com",
          "title": "[bitcoindev] Re: Splitting more block, addr and tx classes of network traffic",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Sun, 14 Dec 2025 18:10:14 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 8730 bytes --]\n\n \n\nHi Defenwycke,\n\nI'm already working on a native multi-process architecture where the traffic\nclasses are isolated on different runtimes, and the \"old\" block store is \nshared.\nAll the points, you made about explicit signaling and the drawbacks are \nvalid,\nand one of the latest time the idea to add a signaling bit for full-rbf \npeers\ncame up, privacy concerns were raised.\n\nThe drawback for the multi-process, multi-socket design approach is to \nmultiply\nthe number of inbound sockets consumed by a peer, though in the case of a \n\"cold\nblock\" archive process it's the inbound peer initiating the connection.\n\nBandwidth-consumption wise, getting messages like BIP 0338 this is still an\noutbound bandwidth win for your full-node peers adopting it, and more \ngenerally\nfor any ingress filtering at the network-level.\n\nBest,\nAntoine\nOTS hash: e1b51b6a80bc77a1cd9e65b1fb74e9b5f52b93473d9e1f1390015eae70674b4c\nLe mercredi 10 décembre 2025 à 18:12:32 UTC, defenwycke a écrit :\n\n> Hello Antoine,\n>\n> This is an interesting problem, and introducing finer-grained traffic \n> classes certainly makes sense. The three areas that stand out to me are \n> peer declaration, topology inference and system bottlenecks.\n>\n> Peer declaration: \n>\n> Explicit signalling of specialised roles (Example - I only relay \n> hot-blocks) to peers increases the fingerprint/profile. We already see \n> topology inference attacks via relay behaviour; adding public role \n> declarations may expand that surface. Nodes can already drop or \n> deprioritise whatever they wish locally, so explicit signalling may not be \n> necessary.\n>\n> Topology inference:\n>\n> Since topology inference can be drawn from tx-relay timing and relay \n> behaviour, an internal class-based model also allows the node to randomise \n> acceptance, forwarding, and scheduling behaviour per class. Even small \n> amounts of deliberate jitter or probabilistic message handling make it far \n> harder for",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2078,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Feedback on a simple 2-path vault design (2-of-2 + CLTV recovery) and use of pruned nodes for UTXO retrieval",
      "message_count": 1,
      "participants": [
        "victor perez"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAHyc38=a=7fCgPg10e=jkpiUA8qiJf+DAaoOaNcP1JajjsZTtw@mail.gmail.com",
          "title": "Re: [bitcoindev] Feedback on a simple 2-path vault design (2-of-2 + CLTV recovery) and use of pruned nodes for UTXO retrieval",
          "author": "victor perez <svcrobotics@gmail@com>",
          "date": "Sun, 14 Dec 2025 11:40:27 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 12246 bytes --]\n\nHi Antoine,\n\nThank you very much for your detailed reply—it's extremely helpful.\n\nFollowing your advice, I'm going to simplify my work and first focus on a\nsingle spending path: a clean 2-of-2 (A + B) multisig, signed with two\nLedgers. My goal is to get this flow stable end-to-end (descriptor\ncreation, UTXO handling, PSBT flow, hardware signing, broadcast) before\nadding the recovery path with a timelock.\n\nJust to clarify the scope: my application is not meant to be a second\nLiana. It's an educational and experimental Ruby on Rails environment that\nI use to better understand Bitcoin in practice.\n\nThe app combines several independent modules:\n\n  - A vault module, where I experiment with descriptors, Miniscript/Taproot\nconstructions, PSBTs, and hardware signing.\n  - A BRC-20 and on-chain analytics module, which helps me explore data\nintelligence by extracting and analysing blockchain data.\n  - A donation module in sats connected to my BTCPay Server.\n  - Various dashboards for visualizing Bitcoin data.\n\nI should mention that I am currently not using regtest. All my experiments\nare done directly on mainnet with real BTC, because it helps me stay fully\naware of real-world constraints and forces me to design things carefully.\nThat said, based on your recommendations, I will start integrating regtest\ninto my workflow so I can iterate faster and test edge-cases more safely.\n\nYour pointers toward Bitcoin Core's wallet API, BDK, Miniscript, and\nhardware-wallet policies give me a very clear roadmap for progressing in a\nstructured way.\n\nThanks again for your time and guidance—it truly helps.\n\nBest regards,\nVictor\n\n\nLe sam. 13 déc. 2025, 18:03, Antoine Poinsot <darosior@protonmail•com> a\nécrit :\n\n> Hi Victor,\n>\n> > If you have any recommendations on what pitfalls to avoid or reading\n> material on robust recovery designs, I’d be glad to hear them.\n>\n> Since you mentioned that your purpose was educational, i would recommen",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2126,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Reducing RAM requirements with dynamic dust",
      "message_count": 1,
      "participants": [
        "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/Q4RLVZW6OK88aVcalvUK7KJJIKOXckKhB7a5zTN7LTxA-jzal3587k4yUiIMjcIBoqLI0eK4uQLZtjJGsbj1R8zsfaMDM-RGSw2V9KI6AAw=@proton.me",
          "title": "[bitcoindev] Reducing RAM requirements with dynamic dust",
          "author": "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sat, 06 Dec 2025 16:08:45 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 10005 bytes --]\n\nGiven the increasing RAM requirements, due to the increasing UTXO set, I suggest seeing the UTXO set size as a controlled variable. A feedback mechanism sets a dynamic dust level, below from which UTXOs are removed/discarded and thus freeing RAM.\n\nBelow is an overview essay better expressed by grok, which can also be seen in here:\nhttps://hackmd.io/P-2lzGb8TiC86IOE3OGiYA?view\n\n# Enhancing Bitcoin's Scalability: A PID-Inspired Approach to Managing UTXO Set Growth\n\n## Abstract\n\nBitcoin’s UTXO set is currently an unbounded accumulator that risks long-term centralization as node RAM requirements grow without limit. Existing fee incentives have proven insufficient against sustained low-value output creation (e.g., inscriptions, tokenized assets, dust-heavy protocols). This article proposes a soft-fork mechanism that treats UTXO set size as a controlled variable: a slowly rising target size is defined, and a PID-style feedback controller, updated every difficulty epoch, dynamically raises a minimum-value floor beneath which old UTXOs become unspendable. The result is bounded, predictable growth of the UTXO set with ample warning periods, no hard caps on monetary use, and strong resistance to bloat attacks—all while remaining fully compatible with a soft-fork deployment.\n\n## Introduction\n\nBitcoin, the pioneering decentralized digital currency, operates as a complex dynamic system governed by consensus rules that ensure security, immutability, and permissionless participation. At its core, Bitcoin maintains a distributed ledger known as the blockchain, which records all transactions in a sequence of blocks. Each transaction involves inputs and outputs: inputs reference previously unspent outputs from prior transactions, while outputs create new spendable units called Unspent Transaction Outputs (UTXOs). The UTXO set represents the aggregate state of all currently spendable coins in the network, serving as a critica",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2057,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Reducing RAM requirements with dynamic dust",
      "message_count": 1,
      "participants": [
        "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/ASHweqfTSVKBPOY2P4UCyK7k7C28OWcQx2SfP9Ovqv2xifZo6SJYpwYLQTjvXTuf7lCa6fqeP92n47L6EokhlA7gHguLLgzHBQMY87rQDQk=@proton.me",
          "title": "Re: [bitcoindev] Re: Reducing RAM requirements with dynamic dust",
          "author": "\"'uuowwpevskfcordh' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 12 Dec 2025 22:22:51 +0000",
          "body": "Thanks both Eric and Erik for the replies. I can't answer whether RAM requirements due to UTXO would indeed be a problem or not. I think a worse-case performance could be considered assuming a \"no-RAM\" environment.\n\nThis being said, I wanted to share some insights still related to the dynamic dust mechanism (the essay).\n\n1. This proposal could be named \"dynamic dust\" plus \"dust sweeping\". Dynamic dust refers to the dust level being defined by the controller at every epoch, and dust sweeping refers to deprecation of utxos below that dust threshold.\n\n2. The grace period for the sweep, individual for each transaction, allows for a new perspective. This is, again, better portrayed by Grok:\n\n## Annex: Addressing Concerns of Confiscation in UTXO Deprecation\n\nWhile the proposed PID-inspired mechanism for UTXO set management offers a pathway to enhanced scalability, it has elicited valid criticisms, particularly regarding its confiscatory nature. Deprecating low-value UTXOs could be perceived as an involuntary seizure of assets, undermining Bitcoin's principles of ownership and immutability. This concern merits careful consideration, as any protocol change must preserve user trust and avoid arbitrary interventions.\n\nThe proposal maintains a degree of neutrality by evaluating UTXOs solely based on their satoshi (SAT) value, without interpreting their content or purpose. This objective criterion minimizes subjective judgments, applying uniformly across all outputs regardless of their origin or use case.\n\nA key mitigating factor lies in the incorporation of a grace period—typically spanning 6 to 12 months—during which owners of affected UTXOs can consolidate or spend them without direct penalty. This window transforms the deprecation process from outright confiscation into a dynamic incentive structure, favoring resource allocation in a constrained system. In Bitcoin's ecosystem, users already incur ongoing costs for participation, such as transaction fees, which can render lo",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2065,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] A safe way to remove objectionable content from the blockchain",
      "message_count": 1,
      "participants": [
        "Peter Todd"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aTl8Y7p4qtYAsHbP@petertodd.org",
          "title": "Re: [bitcoindev] A safe way to remove objectionable content from the blockchain",
          "author": "Peter Todd <pete@petertodd@org>",
          "date": "Wed, 10 Dec 2025 13:57:55 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2902 bytes --]\n\nOn Tue, Dec 09, 2025 at 11:32:48AM -0800, Boris Nagaev wrote:\n> Hi waxwing/AdamISZ,\n> \n> On incentives: agreed that \"good\" only matters if it's an equilibrium. The \n> aim is to shape early design choices so the incentive-compatible \n> equilibrium includes DA and forced publication, rather than slipping into a \n> DA-weak equilibrium where only a few parties hold full data.\n\nExactly.\n\nFurthermore I want to be clear that in this context, the existence of strong ZK\nmath is an *exploit* on the Bitcoin protocol, in much the same way that a\nmathematical advancement that could be used to break SHA256 preimage security\nis also an exploit on the Bitcoin protocol.\n\nIt may be the case that the power of ZK techniques is sufficiently strong that\nBitcoin needs to be redesigned to mitigate them; there is even a small chance\nthat this is not possible and Lightning/HTLCs eventually become insecure due to\nit. No different than how there is a small chance that quantum computing\nrelevant to cryptography turns out to be real and numerous protocols become\ninsecure due to it.\n\n> > what if mining was done just on an accumulator over the utxo set, instead \n> of the utxo set itself?\n> \n> If miners and nodes only see an UTXO accumulator, how do HTLCs survive? The \n> HTLC success spend path needs the preimage to be revealed and readable. How \n> does this fit in an accumulator-only mining model, and what forces \n> publication so the payer can claim its incoming HTLC?\n\nMore generally, if mining is just an accumulator, how do we preserve censorship\nresistence? It's unlikely that the underlying math of the accumulator allows\nanyone to mine a new block with exactly as much data as is required to verify\nthe accumulator. \n\nRecently I met someone who told me that his company needed a full archival node\nof the Solana (IIRC) blockchain. That is, *all* Solana transactions going back\nin time, sufficient to verify everything. They had a very large b",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] CTV activation meeting on IRC - Thursday 18 December 17:00 UTC",
      "message_count": 1,
      "participants": [
        "\"/dev /fd0\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALiT-Zqo-gRCeMDd2VtmXL7Ox31OT3pFmsfXQ5mq6SzeuFnMzg@mail.gmail.com",
          "title": "[bitcoindev] CTV activation meeting on IRC - Thursday 18 December 17:00 UTC",
          "author": "\"/dev /fd0\" <alicexbtong@gmail@com>",
          "date": "Wed, 10 Dec 2025 03:38:14 +0530",
          "body": "[-- Attachment #1: Type: text/plain, Size: 775 bytes --]\n\nHi everyone,\n\nWe will organize a meeting next week to discuss the activation parameters\nfor BIP 119. You can review the related pull requests, different activation\nmethods, past meeting logs etc. and participate in the discussion.\n\nIRC Channel: #ctv-csfs-activation on libera.chat\nAgenda: Discuss activation parameters and build activation client for BIP\n119\n\n/dev/fd0\nfloppy disk guy\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CALiT-Zqo-gRCeMDd2VtmXL7Ox31OT3pFmsfXQ5mq6SzeuFnMzg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 1197 bytes --]",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 0,
            "text_length": 966,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Request for early peer review of two BIP drafts (BUDS and segOP)",
      "message_count": 1,
      "participants": [
        "Callum"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOj3_X-WjPYaiTj5NQnAFp+df+4qWCT8oG_c9DsS-TZ47SjZow@mail.gmail.com",
          "title": "[bitcoindev] Request for early peer review of two BIP drafts (BUDS and segOP)",
          "author": "Callum <cal.defenwycke@gmail@com>",
          "date": "Mon, 8 Dec 2025 21:52:26 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1167 bytes --]\n\nHello all,\n\nI would appreciate early peer review on two BIP drafts I have published:\n\n   1.\n\n   BUDS (Bitcoin Unified Data Standard) — an informational BIP defining a\n   neutral, non-consensus taxonomy for describing transaction data.\n\n   Draft and reference materials:\n   https://github.com/defenwycke/bip-buds\n   2.\n\n   segOP (Segregated OP_RETURN) — a consensus proposal describing a\n   structured TLV data section and corresponding commitment output.\n\n   Draft and reference materials:\n   https://github.com/defenwycke/bip-segop\n\nBoth drafts are small and self-contained. Feedback on clarity, correctness,\nstructure, or missing considerations would be very welcome.\n\nThank you for your time.\n\nKind regards,\n\nDefenwycke\n\n08.12.2025\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAOj3_X-WjPYaiTj5NQnAFp%2Bdf%2B4qWCT8oG_c9DsS-TZ47SjZow%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 2528 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1323,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] A safe way to remove objectionable content from the blockchain (now on GitHub)",
      "message_count": 1,
      "participants": [
        "Lazy Fair"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABHzxrjfvyBRD7sG9rngvDhr9cfzLEQibn4bup_J8pz7UHQpqA@mail.gmail.com",
          "title": "[bitcoindev] A safe way to remove objectionable content from the blockchain (now on GitHub)",
          "author": "Lazy Fair <laissez.faire.btc@gmail@com>",
          "date": "Sat, 6 Dec 2025 17:41:10 +1100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4166 bytes --]\n\nI've started putting together some ideas around how to remove objectionable\ncontent from the blockchain. The very early work-in-progress description is\non GitHub: https://github.com/laissez-faire-btc/safe-remove\n\nI won't include all the details here, because there's necessarily a lot to\ncover, but the basic design goals I've aimed to address are something like\nthis:\n\n* optional - each node gets to decide what to remove, if anything\n* safe - provably no harm is done to those not choosing to use it, and any\ncost or risk to those using it is well understood, minimal, and mitigated\n* full node functionality - a node that does remove content can still do\neverything it could have done otherwise, without relying on anyone else\n* retrospective - content that exists on the blockchain today\n(pre-implementation) can be removed later (post-implementation)\n* trustless, verifiable, permissionless - control messages enabling data to\nbe removed are simple verifiable statements of fact that can be written by\nanybody\n* lightweight - minimal changes and impact to policy, consensus,\nimplementation, usage, the economy\n* granularity, associativity, commutability, idempotence - the least\npossible data is removed, and ordering is inconsequential\n* transferable - nodes that choose to remove objectionable content can\nshare those blocks (with content removed) with others who hold the same\nobjection, so that the receiver may never even momentarily hold the\nobjectionable content\n\nBeing design goals, these are probably not all achievable. I'll need your\nhelp to work through all the details.\n\nI have some more notes I just haven't written up yet, so I'm keen for your\ninput please, on what direction I should take, questions I should answer,\naspects I should consider or detail further, etc.\n\nIn the absence of any feedback, I'll be proceeding with either documenting\nthe threat model, or a bit of a literature review - starting with the\nfollowi",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2092,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] OP_CIV - Post-Quantum Signature Aggregation",
      "message_count": 1,
      "participants": [
        "\"'conduition' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/02e3cb64-50e8-4814-bf53-72db87deafc8n@googlegroups.com",
          "title": "Re: [bitcoindev] OP_CIV - Post-Quantum Signature Aggregation",
          "author": "\"'conduition' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 28 Nov 2025 10:52:27 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 17217 bytes --]\n\nHey Tadge,\n\nYou're right that OP_CIV would discourage address reuse, but it'd also make \nlife difficult for wallet developers who want to adopt it. Some wallet devs \n*today* don't even bother with multi-address support, so imagine if to do \nso effeciently, they needed to statefully track prior UTXOs and generate \naddresses based on a changing UTXO set over time.\n\nAlso I want to mention, there's a big privacy difference between these CISA \ntechniques, and CISA via address reuse. \n\nIf I receive two payments to the same address, i immediately reveal that \nthose UTXOs are owned by the same entity: me.\n\nIf I receive two payments to *distinct* addresses which are linked via your \nOP_CIV (or via my idea by committing to pubkeys) then I can choose when and \nwhether to reveal the fact that those UTXOs are commonly owned. Most user \nwallets have more than just two UTXOs, so in a setting where I have \npossibly dozens of UTXOs, this offers me more flexibility with respect to \nmy on-chain privacy, allowing me to choose when and how to reveal common \nUTXO ownership. This is kind of already the status quo, because chainalysis \nuses common-input ownership heuristics even if they are flawed/incorrect, \njust for the sake of having a \"working\" tool they can sell.\n\nRegarding the extra cost, we can quantify that! Let's say we have a taptree \nof height `h` with `2^h` leaves. We use one leaf for a unique pubkey, and \nthe other `2^h - 1` tap leaves store commitments to other pubkeys or to \npre-existing UTXOs. To spend a TX with `n` inputs using this CISA paradigm, \nwe need one signature, plus `n - 1` taproot control blocks and tapscripts. \nEach control block has size `h * 32`, plus ~32 bytes to reference the other \npubkey or UTXO in the locking tapscript. So in total, the witness size \nscales as: `(n - 1)((h + 1) * 32)`. In other words, for every additional \ninput covered by the CISA scheme, we must pay for roughly `(h + 1) * 32",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2061,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] SLH-DSA (SPHINCS) Performance Optimization Techniques",
      "message_count": 1,
      "participants": [
        "Tim Ruffing"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/6ad6c7418b6b845d6e2dd0ccdb2b508de0c3c10c.camel@real-or-random.org",
          "title": "Re: [bitcoindev] SLH-DSA (SPHINCS) Performance Optimization Techniques",
          "author": "Tim Ruffing <me@real-or-random@org>",
          "date": "Fri, 28 Nov 2025 16:39:12 +0100",
          "body": "Let me just say that leave the note here that this is awesome work!\n\nI didn't expect that so much can be gained using SIMD, and that it\nbeats SHA-NI by such a large margin (even taking into account the\ncaveats you've mentioned).\n\nTim\n\nOn Sun, 2025-11-23 at 18:46 -0800, 'conduition' via Bitcoin Development\nMailing List wrote:\n> Hi devs,\n> \n> I've spent the last several months implementing and benchmarking\n> optimization techniques for the post-quantum hash-based signature\n> scheme SLH-DSA (formerly SPHINCS+), which is being considered as a\n> candidate for a quantum-resistant soft-fork upgrade to Bitcoin, re:\n> BIP360.\n> \n> Survey article: https://conduition.io/code/fast-slh-dsa/\n> \n> char1.png\n> \n> As a material result of my findings, I believe I now possess what may\n> be the fastest publicly available implementation of SLH-DSA (at least\n> on my hardware), and possibly also one of the fastest GPU\n> implementations, though I've had difficulty finding comparable\n> alternatives on that front. Its speed is owed to the Vulkan graphics\n> programming API, often used by video game devs to squeeze performance\n> out of gaming PCs and mobile phones.\n> \n> The code: \n> - https://github.com/conduition/slhvk\n> - https://github.com/conduition/slh-experiments\n> \n> Using my CPU, this code can sign a message with SLH-DSA-SHA2-128s in\n> just 11 milliseconds, and can generate keys in only 2 milliseconds\n> (1ms if batched). Verification throughput approaches that of ECDSA,\n> at around 15000 nanoseconds per verification if properly batched. If\n> you have a GPU with drivers, everything runs even faster.\n> \n> For perspective, the fastest open source SLH-DSA library I could\n> find, PQClean, requires 94 milliseconds for SLH-DSA-SHA2-128s signing\n> and 12ms for keygen on my CPU. PQClean can only achieve this speed on\n> x86 CPUs, whereas Vulkan works on ARM devices, including Apple\n> silicon.\n> \n> There are caveats. This technique is memory-hungry, requiring several\n> megabytes of RAM for signin",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Q-Lock: Quantum-Resistant Spending via ECDSA + Hash-Based Secrets",
      "message_count": 1,
      "participants": [
        "Amarildo"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/1c6c4afc-0fe4-4b72-b70f-3f6ba4c19315n@googlegroups.com",
          "title": "[bitcoindev] Q-Lock: Quantum-Resistant Spending via ECDSA + Hash-Based Secrets",
          "author": "Amarildo <amarildocaka01@gmail@com>",
          "date": "Fri, 28 Nov 2025 07:00:04 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 14499 bytes --]\n\nHi everyone,\n\nI'd like to propose an alternative approach to quantum resistance \nfor Bitcoin that I believe is simpler than BIP-360 P2QRH.\n\n**Q-Lock: Quantum-Resistant Spending Protocol**\n\nSUMMARY:\n- Keeps ECDSA unchanged (no new signature algorithms!)\n- Adds hash-based secret layer on top\n- Uses only SHA256 + Merkle trees (proven crypto)\n- ~3 KB transactions (comparable to FALCON)\n- Two-phase commit-reveal scheme\n- Soft fork compatible\n- BIP-32 HD wallets work normally\n\nKEY INSIGHT:\nInstead of replacing ECDSA with new post-quantum algorithms \n(FALCON, SPHINCS+, Dilithium), Q-Lock adds a quantum-safe \nsecret layer. Attacker must break BOTH ECDSA AND know the \nhash preimages - quantum computers can't reverse SHA256.\n\nCOMPARISON TO BIP-360:\n- BIP-360: New lattice-based crypto, 1.3-50 KB sigs, breaks BIP-32\n- Q-Lock: Proven SHA256 crypto, ~3 KB sigs, BIP-32 works\n\nHOW IT WORKS:\n1. Setup: Generate 64 random secrets, commit via Merkle root\n2. Commit phase: Lock outputs WITHOUT exposing pubkey\n3. Reveal phase: Expose pubkey + secrets at block-hash-determined positions\n4. Quantum attacker sees pubkey too late - outputs already locked!\n\n```\nQ-Lock is a quantum-resistant spending protocol for Bitcoin \nthat adds a hash-based secret layer on top of existing ECDSA \nsignatures. It uses a two-phase commit-reveal scheme where \nspending positions are determined by the block hash, making \nit secure against quantum attackers who can break ECDSA.\n\nQ-Lock does NOT replace ECDSA. It adds quantum protection \nwhile preserving Bitcoin's existing cryptographic foundation.\n\nTransaction size: ~3 KB\nRequires: Soft fork (1-2 new opcodes)\n```\n\n-----\n\n## MOTIVATION\n\n```\nTHE QUANTUM THREAT:\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nShor's algorithm can break ECDSA by extracting private keys \nfrom public keys. When a Bitcoin transaction is broadcast, \nthe public key is exposed in the mempool. A quantum attacker \ncould:\n\n1. See public ke",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2079,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Benchmarking Bitcoin Script Evaluation for the Varops Budget (GSR)",
      "message_count": 1,
      "participants": [
        "\"'Julian' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/5906e2bb-c215-44b0-bb61-0bb91d55717dn@googlegroups.com",
          "title": "Re: [bitcoindev] Benchmarking Bitcoin Script Evaluation for the Varops Budget (GSR)",
          "author": "\"'Julian' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 28 Nov 2025 05:09:25 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 6894 bytes --]\n\nHi Russell,\n\nthanks for taking a look at the code.\n\nIn interpreter.cpp the static function EvalChecksigTapscript(...) is \nresponsible for subtracting from execdata.m_validation_weight_left, for the \noriginal SigVersion::TAPSCRIPT this is still the case, but Tapscript v2 is \nimplemented as a new SigVersion::TAPSCRIPT_V2 and therefore it will not \ntake the original sigops constraint into account (there is an if condition \nright above checking for the SigVersion).\n\nThe new varops budget replaces this sigops constraint and is contained in \nthe new EvalScript(...) overload. Currently it will only subtract from the \nbudget if the checksig succeeds, but I think this should be moved up a \nstatement, such that it will always subtract the varops cost, making the \ncost calculation more static.\n\nThe changes have not been reviewed in depth and I am looking for someone \ninterested in helping me with that.\n\n\n\nOn Monday, 10 November 2025 at 15:48:27 UTC+1 Russell O'Connor wrote:\n\nMy understanding is that in order to avoid block assembly becoming an \nNP-hard packing problem, there must be only one dimension of constraint \nsolving.  However, AFAICT, in your tarscript V2 code you have both the new \nvarops constraint and the original sigops constraint.\n\nFWIW, in Simplicity we reuse the same budget mechanism introduced in \ntapscript (V1) with our cost calculations (though our costs are computed \nstatically instead of dynamically at runtime for better or for worse).\n\nOn Fri, Nov 7, 2025 at 11:06 AM 'Julian' via Bitcoin Development Mailing \nList <bitco...@googlegroups•com> wrote:\n\nHello everyone interested in Great Script Restoration and the Varops Budget,\n\nThe main concerns that led to the disabling of many opcodes in v0.3.1 were \ndenial-of-service attacks through excessive computational time and memory \nusage in Bitcoin script execution. To mitigate these risks, we propose to \ngeneralize the sigops budget in a new Tapscript le",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2084,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: AI-assisted drafts and disclosure",
      "message_count": 1,
      "participants": [
        "Oghenovo Usiwoma"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAOCjZ9RmtKWALV033EENs=wzt43GUG9k4mOeJkAzvyp2e2xj9w@mail.gmail.com",
          "title": "[bitcoindev] Re: AI-assisted drafts and disclosure",
          "author": "Oghenovo Usiwoma <eunovo9@gmail@com>",
          "date": "Thu, 20 Nov 2025 18:48:02 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2166 bytes --]\n\n> Clear disclosure of AI assistance as a process note, not a stigma.\n\nI agree with you, but I think disclosure of AI assistance will be treated\nas \"stigma\", even if that was not its intention. This is my issue with the\n\"AI-label\". If I use AI for research, do I have to add \"AI label\" to my\nBIP? at what point do I have to add the label?\n\n- Novo\n\nOn Thu, Nov 20, 2025 at 1:16 PM nt yl <wrapperband@googlemail•com> wrote:\n\n> Hi Oghenovo Usiwoma and Bitcoin Mechanic,\n>\n> You wrote:\n>\n> In my humble opinion, I believe that humans will continue to use the\n> easiest method available to them to achieve their goals. If we agree that\n> humans will do this, then there will be a lot of AI-assisted content. If I\n> did write an AI-assisted BIP draft, why would I add this \"AI-label\" to my\n> BIP when I know that it will cause reviewers to ignore it?\n>\n> As a disabled person who uses AI tools, my view is that AI will soon be\n> part of most serious workflows, much like reading the manuals and prior\n> discussions is today. Used well, it can summarise long threads, prioritise\n> issues, deduplicate proposals, and help check code for obvious bugs.\n> Refusing to use any such tools can be a step backward in productivity.\n>\n> The key is how we use them. I would support:\n>\n>    -\n>\n>    Clear disclosure of AI assistance as a process note, not a stigma.\n>    -\n>\n>    Strong norms that final authorship, technical accuracy, and\n>    accountability rest with the human proposer.\n>    -\n>\n>    Encouraging A.I. for review support, not for replacing understanding.\n>\n> This balances transparency with practical benefits and keeps the bar on\n> rigour where it belongs.\n>\n> Best,\n> Wrapper\n>\n> https://www.zerogpt.com/   0% A.I.\n>\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubsc",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2051,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Announcing Penlock v1: Paper-Based Secret Splitting for BIP39 Seed Phrases",
      "message_count": 1,
      "participants": [
        "\"'Rama Gan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/GbNAPQX2Q4TzZvS6aWLPf3iy7z1yTXVrgnPpXazBjdcWH-zROBEBieE02r6GX128LM7mml6oTzAmlboV97EWpG1ujLcVZ6fx6uihUMXxCEo=@proton.me",
          "title": "[bitcoindev] Announcing Penlock v1: Paper-Based Secret Splitting for BIP39 Seed Phrases",
          "author": "\"'Rama Gan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 20 Nov 2025 09:04:24 +0000",
          "body": "Hello everyone,\n\nI am thrilled to announce the public release of Penlock!\n\nThe goal is achieved! If you have a printer, scissors, a craft knife,\nand a pin, you can mechanically secret-split a 12-word seed phrase\nin under two hours. This includes the entire process—learning,\nprinting, assembling, executing, and storing the shares.\n\nPenlock is a printable paper calculator that guides you through\nsplitting a seed phrase into a 2-of-3 backup. It is open-source,\nuses straightforward and robust cryptography, and includes various\nfail-safes that protect against errors. A beta was announced on\nthis list last year, and the public release is now available at:\n<https://v1.penlock.io/en/>\n\nThis release breaks backward-compatibility with the beta, allowing for\nenhancements that make Penlock significantly easier to operate. Here\nare the main improvements in v1:\n\n- Faster Secret-Splitting: Penlock now focuses exclusively on producing\n2-of-3 backups using its own paper-optimized splitting algorithm. The\nprevious iteration supported K-of-M splitting with Shamir Secret\nSharing, but at the cost of more complexity and a clunkier 2-of-3\nprocess. Since 2-of-3 covers nearly all use cases, optimizing for it\nseemed like the right approach.\n\n- Backup Strategy Template: Penlock now suggests a generic, adaptable\nbackup strategy that helps set up offsite recovery and trust-minimized\ninheritance. In short, each share is tied to a different type of\nstorage: Digital, Social, and (optionally) Legal. This ensures an\nattacker would have to run two different types of attacks, and makes\nit hard for a party holding one share to obtain a second one. You\ncan find more details at <https://v1.penlock.io/en/split#strategy>.\n\n- On-Paper Error Correction: Penlock v1 introduces what I believe to\nbe the first on-paper error correction algorithm. Each BIP39 word is\nextended with two pre-computed parity symbols, guaranteeing per-word\nunambiguous correction of 1 error and detection of 2. In practice,\nit's also poss",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Improve Bitcoin’s resilience to large-scale power grid failures and Carrington-type solar storms",
      "message_count": 1,
      "participants": [
        "\"Edil Guimarães de Medeiros\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CANJiN3LnCFJxJpGxScLTqT2JF4iQNsX3hipiNiBK_OLMkkXb1g@mail.gmail.com",
          "title": "Re: [bitcoindev] Improve Bitcoin’s resilience to large-scale power grid failures and Carrington-type solar storms",
          "author": "\"Edil Guimarães de Medeiros\" <jose.edil@gmail@com>",
          "date": "Wed, 19 Nov 2025 14:04:36 -0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4863 bytes --]\n\nI don't see any specific measure that would require specific support from\nBitcoin Core, maybe you can point to more specific requirements.\nThe canonical approach is to maintain specific projects that solve specific\nproblems using one of the node interfaces (e.g. RPC).\nBut of course, anyone is free to contribute patches that might help handle\nthis kind of situation.\n\nAs you said, reorgs are expected to be gracefully handled already by the\nnode implementations.\nMost software that is tested in testnet probably also was exposed to harsh\nconditions like deep reorgs and long periods without any block being mined.\nHaving said that, the potential problem you describe is not specific to\nBitcoin and having alternative critical communication mechanisms is\ndesirable.\nBut they probably fall under the economically not viable kind of\ninfrastructure that humans have relied on governments to implement and\nmaintain, which is far from an ideal approach.\n\nAnd by the way, this is the mailing list.\n\nRegards.\n\nEm dom., 16 de nov. de 2025 às 20:00, Alexandre <alexandre.lg99@gmail•com>\nescreveu:\n\n> Hi,\n> I’m submitting this feature request to explore how Bitcoin could better\n> withstand extreme, long-lasting infrastructure failures caused by major\n> solar events. Before explaining the request itself, I want to provide a\n> brief overview of what these events are, because their scale matters.\n>\n> A large solar storm occurs when the Sun emits an intense burst of charged\n> particles and electromagnetic energy. When this material reaches Earth, it\n> can disturb the magnetic field and induce strong electric currents in long\n> conductors such as power lines. In extreme cases, this can damage\n> transformers, overload electrical grids, interrupt satellite operations,\n> and disrupt long-distance communication systems. The most famous historical\n> example is the Carrington Event of 1859, the largest geomagnetic storm ever\n> recorded. It trigge",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2114,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Standardization of On-Chain Identity Publication",
      "message_count": 1,
      "participants": [
        "\"'Edyth Kylak Johnson' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2acc9c28-6413-4147-8d11-e1ae0a677b75n@googlegroups.com",
          "title": "[bitcoindev] [BIP Proposal] Standardization of On-Chain Identity Publication",
          "author": "\"'Edyth Kylak Johnson' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 19 Nov 2025 03:54:25 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 943 bytes --]\n\nDear bitcoin-dev,\nI am submitting a draft Bitcoin Improvement Proposal titled *“Standardization \nof On-Chain Identity Publication”* for discussion. The draft specifies \ncanonical CBOR payloads, Poseidon-based `nullifier_hash` domain separation \n(`v0iden` / `v0corp`), and an optional Ed25519 signature wrapper. The \nproposal text and implementation notes are available in this \nPR: https://github.com/bitcoin/bips/pull/2038 . I welcome review and \nfeedback on interoperability, canonicalization (deterministic CBOR), and \nsecurity considerations.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/2acc9c28-6413-4147-8d11-e1ae0a677b75n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 1196 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 1121,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] New bitcoin backbone code release + Tx relay v2 update",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/299d4f39-b8cd-4736-b6bb-71def4d85f74n@googlegroups.com",
          "title": "[bitcoindev] New bitcoin backbone code release + Tx relay v2 update",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Tue, 18 Nov 2025 16:01:33 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 3679 bytes --]\n\nHello devs,\n\nShared new code for bitcoin backbone available on the website\n(bitcoinbackbone.org). Biggest changes from latest release has\nbeen mostly working on BIP324 re-implementation, cleaning bugs\nimplementing a simple tx-relay stack, a little mempoool buffer\nand some groundworks on address management. Tx syncing works with\nvanilla bitcoin core v0.30 software.\n\nI did a layout of the process architecture on the website, but the\nmempool is fully living in its own mempool process, fully separate\nfrom the block pipeline. In case of mempool DoS for whatever reasons,\nthe full-node keeps processing blocks. This also opens the door to\nhave *multiple* mempools with incompatible policies among themselves,\nand just select the highest fees paying graph of consensus-valid\ntransactions, after sanitizing out conflicts.\n\nAs I was writing in my latest email about bitcoin backbone, of course\nthere are some trade-offs with the mempool not living in the same memory\nspace than the validation engine, though I think you have practical\nimprovements on this area.\n\nThe simple tx-relay stack also implements a basic implementation of the\nproposed overhaul of the tx-relay v2 [0]. Currently, the tx flow is\nINV(txid) -> ; <- GETDATA(inv(txid)) ; TX(tx) -> . With the proposed \ntx-relay\nv2 overhaul, if an INV for the txid has not previously received for the\ntransaction, i.e the transaction processing has not been requested, the\ntransaction is strictly rejected, without further processing. This more\nstricter tx processing can be activated with a setting option in bitcoin\nbackbone.\n\nLong-term, I think some form of tx-relay link-level mitigation is a strong\nnecessity to diminish the surface attack of time-sensitive contracting\nprotocol in face of tx-relay throughput overflow, where a malicious peer\nis buying out your full-node tx bandwidth to tamper with the propagation\nof a time-sensitive tx (e.g a lightning's HTLC-preimage) [1].\n\nThe d",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 1,
            "text_length": 2068,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "[bitcoindev] OP_CHECKUTXOSETHASH idea",
      "message_count": 1,
      "participants": [
        "Erik Aronesty"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAJowKgLE4kb7qT1NxXrmEssr8+fQGd-=7=m-BAsjePoti8TRRg@mail.gmail.com",
          "title": "[bitcoindev] OP_CHECKUTXOSETHASH idea",
          "author": "Erik Aronesty <erik@q32@com>",
          "date": "Mon, 29 Sep 2025 17:09:15 -0700",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1671 bytes --]\n\nA soft fork could introduce a new opcode, `OP_CHECKUTXOSETHASH`, allowing\nminers to optionally commit a deterministic hash of the current UTXO set\ninto a block. If present, all nodes must verify its correctness or reject\nthe block; if absent, the block is still valid. Old nodes treat the opcode\nas unspendable, so backward compatibility is preserved.\n\nBecause computing the full UTXO root is costly, this makes each checkpoint\nintentionally expensive to produce, ensuring that miners will only include\nthem when compensated with sufficient fees. Additionally, it could be\nlimited to one per block.\n\nThe result is a voluntary, self-limiting, incentive-aligned, fee-driven\nsystem where checkpoints are cheaply consensus-enforced when included but\nnever mandatory.\n\nMost nodes could operate on a rolling history validated by occasional,\nhigh-value commitments, while archival nodes remain free to preserve the\nfull chain. This reduces the burden of initial sync and resource use\nwithout sacrificing Bitcoin’s security model, since any invalid checkpoint\nwould invalidate its block.\n\nIn practice, the chain becomes more efficient for everyday use while the\nhistorical record remains intact for those willing to bear the expense of\nmaintaining it.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAJowKgLE4kb7qT1NxXrmEssr8%2BfQGd-%3D7%3Dm-BAsjePoti8TRRg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 2187 bytes --]",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 1794,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] Re: OP_CHECKUTXOSETHASH idea",
      "message_count": 1,
      "participants": [
        "Eric Voskuil"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/76c1b5a1-5b78-4576-981f-4df69aefc9a6n@googlegroups.com",
          "title": "[bitcoindev] Re: OP_CHECKUTXOSETHASH idea",
          "author": "Eric Voskuil <eric@voskuil@org>",
          "date": "Sun, 16 Nov 2025 11:11:16 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2923 bytes --]\n\nHi Erik,\n\n>  Most nodes could operate on a rolling history validated by occasional, \nhigh-value commitments, while archival nodes remain free to preserve the \nfull chain.\n\nThis is an old big-blocker idea, and still a terrible one. It effectively \nreduces what we now call validation to majority hash power control. IOW \nfunctionally equivalent to SPV. A few actual full nodes (maybe) validating \ndoes not have the implied effect. For a node's validation to matter, the \nnode has to be accepting coin in trade. SPV entirely relies on the \npresumption that a very large portion of economic activity is actually \nvalidated. Very large means enough that majority hash power has a true \ndisincentive to intentionally mine invalid blocks, despite the reward for \ndoing so (e.g. unlimited inflation). What you are calling \"archival nodes\" \ndon't actually \"preserve the full chain\" for everyone else, because their \neffect is limited to their own transactions. Otherwise we are talking about \nfraud proofs, which is a conversation that doesn't end well.\n\n>  Because computing the full UTXO root is costly...\n\nIt is not, it's getting cheaper every year.\n\ne\n\nOn Monday, September 29, 2025 at 8:11:51 PM UTC-4 Erik Aronesty wrote:\n\nA soft fork could introduce a new opcode, `OP_CHECKUTXOSETHASH`, allowing \nminers to optionally commit a deterministic hash of the current UTXO set \ninto a block. If present, all nodes must verify its correctness or reject \nthe block; if absent, the block is still valid. Old nodes treat the opcode \nas unspendable, so backward compatibility is preserved. \n\nBecause computing the full UTXO root is costly, this makes each checkpoint \nintentionally expensive to produce, ensuring that miners will only include \nthem when compensated with sufficient fees. Additionally, it could be \nlimited to one per block.\n\nThe result is a voluntary, self-limiting, incentive-aligned, fee-driven \nsystem where checkpoints are cheaply ",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2042,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] [BIP Proposal] Reduced Data Temporary Softfork",
      "message_count": 1,
      "participants": [
        "Lucas Barbosa"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPbyeOFpVf9kWPzRZA9CZ--vpFZkKdroHf5nuMFV=_hse44i_g@mail.gmail.com",
          "title": "Re: [bitcoindev] [BIP Proposal] Reduced Data Temporary Softfork",
          "author": "Lucas Barbosa <lucasbarbosafurtado0@gmail@com>",
          "date": "Mon, 10 Nov 2025 16:46:24 -0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2759 bytes --]\n\n>Okay, if you or anyone can show me an example of a \"boring and\nunconcerning thing\" that involves pre-signed transactions that use\ndeep/OP_IF-containing Taptrees and timelocks, which predates the original\nsoftfork proposal, I will be happy to update the BIP. Saying \"someone might\nbe doing this\" is simply frivolous obstructionism which, again, could be\nused to stop any attempt to change the consensus rules.\n\nHello Dathon\nThe responsibility to demonstrate this is yours, it is you who is hastily\nproposing an emergency change. the more information you can bring, the\neasier it will be for you to get what you want\n\n\nEm qua., 29 de out. de 2025, 23:57, Erik Aronesty <erik@q32•com> escreveu:\n\n>\n>> Case law in the USA regarding illegal content has always rested squarely\n>> on those who:\n>\n>\n>  1 - provide broad public access, in this case a company like OpenSEA\n> (which has had to block content)\n>  2 - the original author\n>\n> if punishing \"relays\" was a thing, then every CISCO router, SMTP relay and\n> DISCORD server that provided access would be in court all day long\n>\n> instead, it's the users of the illegal data and the publishers that\n> actually wind up in trouble - not the internet providers\n>\n> the bitcoin ledger is neither a browser or web server, nor is it an image\n> uploader.  there is zero ability to view images built into the system\n>\n> and even if it was\n>\n> the purpose of this software is to be a distributed and effectively\n> uncensorable ledger.\n>\n> hopefully it doesn't change because someone launched a meme campaign with\n> vague threats of legal action\n>\n> if a transaction has /no reasonable expectation of being mined/ (too\n> expensive to validate, too large, too low fees), there's also no reason to\n> relay it\n>\n> this is probably the best way to set policy\n>\n> --\n> You received this message because you are subscribed to the Google Groups\n> \"Bitcoin Development Mailing List\" group.\n> To unsubscribe from",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2064,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] BIP54 implementation and test vectors",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/V0qeILOW1CuH3NS2O8IUdQBK8i3o8LwzLNGf7xh1UO0S_Gzui1CpdP5NhdT3EtrW6NgqxJ538egeag6bVZoBX8C8E46ZYTCyPg1qBxkwCXs=@protonmail.com",
          "title": "[bitcoindev] BIP54 implementation and test vectors",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Tue, 21 Oct 2025 15:46:04 +0000",
          "body": "Hi everyone,\n\nI'd like to give an update on my Consensus Cleanup work, now BIP54.\n\nI opened an implementation against Bitcoin Inquisition v29.1 at [0]. It contains extensive testing\nof each of the four proposed mitigations, and was used as a basis to generate test vectors for\nBIP54. I opened a PR against the BIPs repository to add them to BIP54 [1].\n\nThe test vectors for the transaction-level sigops limit contain a wide variety of usage combinations\nas well as ways of running into the limit. They also include some historical violations as well as\npathological transactions demonstrating the implementation details of the sigop accounting logic\n(which was itself borrowed from that of BIP16, which all Bitcoin implementations presumably already\nhave).\n\nThe test vectors for the new witness-stripped transaction size restriction similarly exercise the\nbounds of the check under various conditions (e.g. transactions with/without a witness). All\nhistorical violations were also added to the test vectors, thanks to Chris Stewart for digging those\nup.\n\nBecause the new timestamp restrictions are tailor-made to the mainnet difficulty adjustment\nparameters, the test vectors for those contain a number of chains of mainnet headers (from genesis).\nEach test case contains a full header chain and whether it is valid according to BIP54. These chains\nwere generated using a custom miner available in [2] and added to the implementation as a JSON data\nfile.\n\nThe test vectors for the coinbase restriction similarly include a chain of mainnet blocks, because\nthe timelock check is context-dependent. These were generated using a similar miner also available\nat [2].\n\nI'm seeking feedback on these test vectors from everybody but in particular developers of\nalternative Bitcoin clients, as compatibility with other Bitcoin implementations than Bitcoin Core\nwas a design goal.\n\nBest,\nAntoine Poinsot\n\n[0]: https://github.com/bitcoin-inquisition/bitcoin/pull/99\n[1]: https://github.com/bitcoin/bips/pull/201",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2051,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: BIP54 implementation and test vectors",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/5fe13896-913c-4b16-8507-69809b369612n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: BIP54 implementation and test vectors",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Sun, 9 Nov 2025 17:40:58 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 11336 bytes --]\n\nHi Poinsot,\n\nThanks for the precision. Yes my wonder is more if you put yourself in the \nshoes of an attacker,\nand you have to calculate your cost for an attack, what is the most \ninteresting between playing on\nthe number of prevout lookups and maximizing the quadratic hashing. I do \nbelieve the proposed 2500\nsigops limit is slashing the quadratic hashing worst-case concern, while at \nthe same time not providing\nan advantage to the attacker on the prevout lookup cost. Say differently, I \nbelieve we should ensure that\nany introduced DoS limit in the goal to reduce worst-case for a DoS vector \nA do not downgrade the worst-case\nfor another DoS vector B. \n\nPreviously, as the way the novel limit was proposed in abstracto, I had a \nconcern with given that\nif you take for example bitcoin core multiple input checks where made \n(first all scripts flags and\nthen for consensus mandatory script flags) [0], a DoS attacker could have \ndeliberately make the\nscript failed on a policy flag and then make it hard fails on the novel \n2500 limit, _at a cheaper\nprice_ (less CHECKMULTISIG bytes to pack in the tx). I don't think it's a \nconcern anymore as after\n[1] and others, there is no double validation anymore and \n`CheckSigOpsBIP54` has been implemented\nwith the other policy check limits.\n\nOf course the number of CHECKMULTISIG bytes to pack is only a concern for \nan attacker in the situation\nwhere satoshis have to be provided to pass the `min_relay_feerate` policy \nrule, but it's a realistic\nlimit one has to reason when you're considering the cost of network-wide \nDoS. Somehow, you're maximizing\nthe higher DoS cost per byte per satoshi you might have to commit in a \nsingle tx.\n\nDisagree with you on the prevout lookup cost exploitation, as I think there \nis at least variant to\nattempt to slash the cost for an attacker for some categories of DoS. But \nyes seen the calculations\nfor various DoS blocks, and that can be discussed",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 2,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] LNHANCE a soft-fork package",
      "message_count": 1,
      "participants": [
        "Brandon Black"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aQzcGITQE3ckHB7K@console",
          "title": "Re: [bitcoindev] LNHANCE a soft-fork package",
          "author": "Brandon Black <freedom@reardencode@com>",
          "date": "Thu, 6 Nov 2025 09:34:16 -0800",
          "body": "As the original proposer of LNHANCE, let it be known that I still think\nit's a great direction for bitcoin script improvements. This set of\nopcodes is carefully crafted to offer significant utility with minimal\nfootguns or even sharp corners.\n\nI am also a fan of the competing TEMPLATEHASH+CSFS+IKEY proposal which\nremoves the blunted corner of modifying legacy script while adding the\nblunted corner of committing to the annex. It also removes the hacky\nsibling commitment via scriptSig, loses the ability to use simple vaults\nwith legacy ECDSA-only signing infrastructure, and saves just under 8vB\nin a typical lightning symmetry uncontested force close scenario.\n\nBoth are excellent directions to move bitcoin script and I hope to see\none of the two enforced on the network in the (not too distant) future.\n\nBest,\n\n--Brandon\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/aQzcGITQE3ckHB7K%40console.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 1220,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [Pre-BIP Discussion] Bitcoin Node Repository Consensus-Policy Separation",
      "message_count": 1,
      "participants": [
        "Juan Aleman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/73a08ea3-b9be-424b-a1cb-beac3206723cn@googlegroups.com",
          "title": "Re: [bitcoindev] [Pre-BIP Discussion] Bitcoin Node Repository Consensus-Policy Separation",
          "author": "Juan Aleman <bitcoindev@juanaleman@com>",
          "date": "Fri, 31 Oct 2025 11:51:18 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 7260 bytes --]\n\nHello Matt, thanks for your response.\n\nI searched about libbitcoinkernel and it does look like some effort is \nbeing put into the creation of this library.\n\nBut again, my focus is SPECIFICALLY on the powerful influence of the \nbitcoin/bitcoin repo itself. If you don't this merits a BIP, what would be \nthe appropriate avenue to address and potentially do something about \nreorganizing the repo itself?\n\nOn Friday, October 31, 2025 at 2:41:30 PM UTC-4 Matt Corallo wrote:\n\n> You should probably dig into the libbitcoinkernel project (and the immense \n> amount of work that has gone into it, as well as the immense amount of work \n> that it requires). Also this is not anything that would merit a BIP.\n>\n> On Oct 31, 2025, at 14:20, Juan Aleman <bitco...@juanaleman•com> wrote:\n>\n> ﻿Hello bitcoin developers,\n>\n>\n>\n> My name is Juan Alemán, and this is my first post to the mailing list. But \n> I've been involved with Bitcoin since 2017. First only as a hard money \n> investor, but later also as a developer, specially fascinated by this \n> permanent medium. I hope this proposal can be appreciated by all \n> perspectives as a pragmatic (maybe unorthodox, but timely) solution to move \n> forward in agreement.\n>\n> The changes in v30 defaults got my attention (similar to many of you), as \n> they are completely opposite to what has historically been \"standard\" \n> practice. A highly controversial change that surfaces the influence over \n> default policy in the network, escalating to the point of a fork proposal \n> <https://github.com/bitcoin/bips/pull/2017>.\n>\n> First, it must be reminded that a fork should be unnecessary if defaults \n> are simply reverted <https://github.com/bitcoin/bitcoin/pull/33682>, \n> while still allowing all policy possibilities.\n>\n> After my second PR <https://github.com/bitcoin/bitcoin/pull/33690> \n> attempt was (also) closed (and I was blocked from the repo), I realized \n> that the main issue here is s",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2090,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] On (in)ability to embed data into Schnorr",
      "message_count": 1,
      "participants": [
        "waxwing/ AdamISZ"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/31d18bd9-62e0-4035-b04f-f70ff4253257n@googlegroups.com",
          "title": "Re: [bitcoindev] On (in)ability to embed data into Schnorr",
          "author": "waxwing/ AdamISZ <ekaggata@gmail@com>",
          "date": "Sun, 2 Nov 2025 05:30:44 -0800 (PST)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 4249 bytes --]\n\n> I already told you, when I said \"known plaintext attack\". If you want to \nput random data into private keys or signatures, then things are hard to \nbreak. However, if it is something useful for the reader, then usually, \nthat kind of data are non-random. For example: some users store \ntransactions inside OP_RETURNs, and they use ASCII hex representation. If \nthey would use binary encoding, then they would save 50% space. But people \nsimply don't care.\n\n> And the similar case is possible here: if you want to store random data, \nthen it is hard to use this method. However, if you want to store ASCII \ntext, where many words can be found in a dictionary, or where the format of \nthe data is known upfront, or can be easily guessed, then the security of \nthe keys, is comparable to the brainwallets.\n\n> Which means, that you can just put your data into the private key of the \nuser, and a \"signature nonce\" (which is nothing else, but yet another \nprivate key, placed on secp256k1). And then, if you know, that your data, \nis for example \"ASCII string\", then it means, that each and every key, that \nyou produce, simply leaks at least 32 bits per 256-bit key, if not more.\n\nAh, right; I had originally written a response to this idea but then \ndiscarded it on the basis that it's kinda \"obvious\" that we shouldn't think \nabout that, and focused on the more in-the-weeds concept of a lattice \nattack instead.\n\nBut it isn't obvious.\n\nSo let's think of the spectrum here. First, the most trivial nonce to \nbreak: one consisting of a single bit (OK technically you can't encode k=0, \nheh, but, whatever, put it in the second bit of the string). Obviously that \nis extractable, getting 32 bytes plus one bit. That one extra bit above the \n33% is achievable because of \"grinding\" except here grinding is the most \ntrivial version possible: trying 2 alternatives. This still fits my \noriginal claim, which is \"33% plus whatever you can get f",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] segOP potential BIP discussion",
      "message_count": 1,
      "participants": [
        "defenwycke"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/c38d00f7-a42b-4f7b-899e-11e823a43d7dn@googlegroups.com",
          "title": "[bitcoindev] segOP potential BIP discussion",
          "author": "defenwycke <cal.defenwycke@gmail@com>",
          "date": "Wed, 29 Oct 2025 16:40:50 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 13060 bytes --]\n\nHi all,\n\nI attempted to propose a BIP earlier today. I was notified of my incorrect \nactions versus core procedures.\n\nSee attached or below - my proposal for discussion.\n\nRegards\n\nDefenwycke.\n\n---\n\nA proposed discussion of segOP\nAuthor: Defenwycke / defenwycke@icloud•com\n29.10.2025\n\nsegOP (Segregated OP_RETURN)\n\n    A proposed extension to Bitcoin transactions. It introduces a \ndedicated, structured, full-fee data lane for on-chain data, without \ndisrupting existing transaction rules. Think of it like this - segOP is to \narbitrary data what SegWit was to signatures — a clean, isolated, \nforward-compatible path that preserves old-node harmony while restoring fee \nfairness.\n\nAbstract:\n\n    segOP defines a new segregated data section for Bitcoin transactions, \ncryptographically committed via OP_SUCCESS184. It standardizes on-chain \nmetadata storage by enforcing full fees, structured TLV encoding, and a 100 \nKB cap, while remaining backward-compatible with legacy nodes.\n\nIt is not:\n\n    - A replacement for OP_RETURN\n    - An off-chain mechanism\n    - A hard fork\n\nIt is:\n\n    - A soft-fork-safe, future-proof, SegWit-style data section\n    - Full-fee (4 weight units per byte)\n    - Structured (TLV + Merkle-root verified)\n    - Limited to 100 KB per transaction\n\nWhat issues could segOP rectify?:\n\n    1. Ordinals abuse witness discount. segOP will apply full fee rate for \nlarge data.\n    2. No structured metadata lane. segOP introduces TLV-encoded + \nMerkle-verified section.\n    3. Witness discount abused for megabytes. segOP Enforces 100 KB cap.\n    4. OP_RETURN unstructured & limited. segOP = structured + verifiable.\n    5. Spam cheap storage. segOP deters spam with fees.\n\n    In short - segOP restores fairness — data pays its real weight cost, \npreserving block space for financial use.\n\nWhere segOP lives:\n\n    Transaction Layout (Post-segOP)\n    Transaction\n    ├── nVersion\n    ├── vin (inputs)\n    ├── vout (o",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2044,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Re: segOP potential BIP discussion",
      "message_count": 1,
      "participants": [
        "\"'moonsettler' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/3S1IMGSH6z-3Ho81Ugp9o-ltTwpIC-4ow6bn6aEAtK4XrkG5HTkvTw0BeZFpPILfabdp7rz_LDHEBWX_XZk0a7nKR4sJRUp_3B7pAMaJ86I=@protonmail.com",
          "title": "Re: [bitcoindev] Re: segOP potential BIP discussion",
          "author": "\"'moonsettler' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sat, 01 Nov 2025 12:00:26 +0000",
          "body": "Hi Defenwycke,\n\nI think this is not a horrible idea, there might be future demand for a pruneable proof of publication space.\n\nBut, your proposal does not provide an incentive for anyone to adopt it. If it was cheaper than witness space,\nI think it would be a serious consideration especially for rollups.\nThe idea that the bytes incur full cost (4WU) makes it on arrival economically speaking.\n\nAlso it's a bit unclear how consensus and nodes in sync would interact with the \"recent window\".\n\nIt's a reasonable approach to mandate the presence of such an extension block near the chain-tip, but\nnodes by default should not download or verify it during IBD. This would only add a constant burden to nodes,\nwhile allowing bitcoin to scale on higher layers more that require such proof of publication mechanism for\ntheir security.\n\nThinking that this would be used by graffiti type payloads that especially are seeking the permanence, persistence\nand replication of bitcoin transactional data, or that metaprotocols that want to use the block space as an archival\nlayer for their own token ledgers is I'm afraid completely misguided or even delusional.\n\nBR,\nmoonsettler\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/3S1IMGSH6z-3Ho81Ugp9o-ltTwpIC-4ow6bn6aEAtK4XrkG5HTkvTw0BeZFpPILfabdp7rz_LDHEBWX_XZk0a7nKR4sJRUp_3B7pAMaJ86I%3D%40protonmail.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1668,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [BIP Proposal] Soft Fork Compromise on op_return to Resolve Current Bitcoin Controversies",
      "message_count": 1,
      "participants": [
        "Melvin Carvalho"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAKaEYhKdhJ1vP5BBYNAMF7557M9dSoQx8_uqjdAzRM3DgA6ajg@mail.gmail.com",
          "title": "Re: [bitcoindev] [BIP Proposal] Soft Fork Compromise on op_return to Resolve Current Bitcoin Controversies",
          "author": "Melvin Carvalho <melvincarvalho@gmail@com>",
          "date": "Fri, 31 Oct 2025 07:31:03 +0100",
          "body": "[-- Attachment #1: Type: text/plain, Size: 13893 bytes --]\n\nčt 30. 10. 2025 v 20:35 odesílatel Martin Habovštiak <\nmartin.habovstiak@gmail•com> napsal:\n\n> \"Honest\" only refers to miners not trying to reverse the transactions by\n> making an alternative chain. It has nothing to do with your subjective\n> evaluation of the transactions worth trying to censor the \"bad ones\".\n>\n\nHi Martin,\n\nSmall clarification per the white paper: \"honest\" isn’t only about\nreversing transactions. Section 8 of the white paper also discusses honest\nnodes and which transactions are accepted into blocks.\n\nSatoshi further clarified standardness:\n\"The design supports a broad range of transaction types that are possible,\nbut not all are standard. Standard transactions are the ones that are\ndesigned to be used for the common case.\"\n-- June 2010\n\nPer Section 11, the white paper's security model shows honest miners (e.g.\nfollowing standard operation) outpacing alternatives. In practice, miners\nfollowing a standardness agreement or soft fork for OP_RETURN would, on\naffected blocks, earn around $100,000 more, than under a mixed policy,\nmaking prioritizing standard transactions the economically optimal strategy.\n\nThis is because there are a finite number of blocks before each halving, so\nthe opportunity cost of non-standard payloads is half the subsidy, which is\nmore than enough economic upside to offset fees. A standardness agreement\nsoft fork is therefore economically compelling for miners: it aligns with\nlong-standing practice and provides long-term incentives.\n\nBest,\nMelvin\n\n\n>\n> Bitcoin was specifically designed to prevent censorship of transactions\n> that follow the consensus rules. Trying to go against it makes you a fool\n> at best or an attacker at worst.\n>\n> Dňa št 30. 10. 2025, 18:37 Melvin Carvalho <melvincarvalho@gmail•com>\n> napísal(a):\n>\n>>\n>>\n>> čt 30. 10. 2025 v 3:16 odesílatel Greg Maxwell <gmaxwell@gmail•com>\n>> napsal:\n>>\n>>> I searched for the source of your quotation and am unable",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 2,
            "text_length": 2107,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "[bitcoindev] [BIP Proposal] Limit ScriptPubkey Size >= 520 Bytes Consensus.",
      "message_count": 1,
      "participants": [
        "PortlandHODL"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/6f6b570f-7f9d-40c0-a771-378eb2c0c701n@googlegroups.com",
          "title": "[bitcoindev] [BIP Proposal] Limit ScriptPubkey Size >= 520 Bytes Consensus.",
          "author": "PortlandHODL <admin@qrsnap@io>",
          "date": "Thu, 2 Oct 2025 13:42:06 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 1881 bytes --]\n\nProposing: Softfork to after (n) block height; the creation of outpoints \nwith greater than 520 bytes in the ScriptPubkey would be consensus invalid. \n\nThis is my gathering of information per BIP 0002\n\nAfter doing some research into the number of outpoints that would have \nviolated the proposed rule there are exactly 169 outpoints. With only 8 \nbeing non OP_RETURN. I think after 15 years and not having discovered use \nfor 'large' ScriptPubkeys; the reward for not invalidating them at the \nconsensus level is lower than the risk of their abuse. \n\n   - \n*Reasons for *\n      - Makes DoS blocks likely impossible to create that would have any \n      sufficient negative impact on the network.\n      - Leaves enough room for hooks long term\n      - Would substantially reduce the divergence between consensus  and \n      relay policy\n      - Incredibly little use onchain as evidenced above.\n      - Could possibly reduce codebase complexity. Legacy Script is largely \n      considered a mess though this isn't a complete disablement it should reduce \n      the total surface that is problematic.\n      - Would make it harder to use the ScriptPubkey as a 'large' \n      datacarrier.\n      - Possible UTXO set size bloat reduction.\n      \n      - *Reasons Against *\n      - Bitcoin could need it in the future? Quantum?\n      - Users could just create more outpoints.\n   \nThoughts?\n\nsource of onchain data  \n<https://github.com/portlandhodl/portlandhodl/blob/main/greater_520_pubkeys.csv>\n\nPortlandHODL\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/6f6b570f-7f9d-40c0-a771-378eb2c0c701n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 2232 bytes --",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2076,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    }
  ],
  "summary": {
    "total_threads": 50,
    "total_messages": 50,
    "unique_participants": 36
  }
}