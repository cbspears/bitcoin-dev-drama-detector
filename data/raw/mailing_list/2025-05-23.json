{
  "source": "mailing_list",
  "list": "bitcoin-dev",
  "fetched_at": "2026-01-15T23:10:04.666675+00:00",
  "date": "2025-05-23",
  "threads": [
    {
      "title": "Re: [bitcoindev] BIP39 Extension for Manual Seed Phrase Creation",
      "message_count": 1,
      "participants": [
        "\"'Russell O'Connor' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAMZUoK=A8T5N4ekR7r6+cfaxMCYL=a5_v0kqdPNVDzgcUY9xrg@mail.gmail.com",
          "title": "Re: [bitcoindev] BIP39 Extension for Manual Seed Phrase Creation",
          "author": "\"'Russell O'Connor' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 23 May 2025 16:45:22 -0400",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5058 bytes --]\n\nFWIW, BIP-93 (codex32) was designed for both human and computer generated\nrandomness.  Codex32 also supports human and computer generated secret\nsharing.\n\nSee also <https://secretcodex32.com/>.\n\nOn Fri, May 23, 2025 at 11:35 AM Eric <nerdyrugbyguy@gmail•com> wrote:\n\n> Quoting BIP39: \"This guide is meant to be a way to transport\n> computer-generated randomness with a human-readable transcription.\"\n>\n> BIP39 was meant to capture computer generated randomness.  Manually\n> calculating the sha256 hash is not practical.\n>\n> Using a separate tool to compute the checksum or last word is cumbersome\n> and requires users to have a more advanced understanding of cryptography.\n>\n>\n> On May 23, 2025 8:29:27 AM MDT, Kyle Honeycutt <coinables@gmail•com>\n> wrote:\n>\n>> Respectfully, a \"black box\" is not trusted to generate mnemonic\n>> passphrases, the standard is well-defined and generally followed across\n>> wallets.\n>>\n>>\n>> https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki#Generating_the_mnemonic\n>>\n>> Users can create their own mnemonics in a trustless way following the\n>> BIP39 standard published in 2013.\n>>\n>> Using any entropy source a user can perform a SHA256 hash on the entropy\n>> to get a 256 bit string, then convert that to binary. Perform another\n>> SHA256 hash on the binary, take the first 8 bits and solve for checksum and\n>> then solve the rest of mnemonic words.\n>>\n>> On Fri, May 23, 2025, 6:15 AM Eric Kvam <nerdyrugbyguy@gmail•com> wrote:\n>>\n>>> *Motivation*\n>>> Make it easy for users to manually create their seed phrase so that they\n>>> don't have to trust a \"black box\" and allow for encoding derivation path in\n>>> seed phrase to simplify recovery\n>>>\n>>> *How*\n>>> Use every eighth word from the wordlist to generate 16 word phrases with\n>>> 128 bits of entropy (no checksum).  The most significant eight bits of each\n>>> word are used as entropy.  The least significant three bits of each word\n>>> s",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2065,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] jpeg resistance of various post-quantum signature schemes",
      "message_count": 1,
      "participants": [
        "\"'Bas Westerbaan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAMjbhoU=PCUwbhWFbqCbOdZc+ybmREJmmt1K1TuHrCTncKH6VA@mail.gmail.com",
          "title": "[bitcoindev] jpeg resistance of various post-quantum signature schemes",
          "author": "\"'Bas Westerbaan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 21 May 2025 12:32:33 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 5422 bytes --]\n\nHi all,\n\nMy colleague Ethan asked me the fun question which post-quantum signature\nschemes have the following security property, which he called jpeg\nresistance.\n\nAttacker wins if for a (partially specified) signature and full message,\nthey can find a completed signature and public key, such that the completed\nsignature verifies under the public key.\n\nA naive hash-based signature is not jpeg resistant. Schoolbook Winternitz\none-time signatures, forest-of-trees few-time signatures, and Merkle trees\nall validate signatures (/authentication paths) by recomputing the public\nkey (/Merkle tree root) from the signature and the message, and checking\nwhether the recomputed public key matches the actual public key. That means\nwe can pick anything for the signature, and just set the public key to the\nrecomputed public key.\n\nThe situation is more subtle for actual standardized hash-based signatures.\nRFC 8391 XMSS doesn’t sign the message itself, but first hashes in (among\nothers) the public key. Basically the best we can do for XMSS (except for\nsetting the signature randomizer) is to guess the public key. Thus it’s\npretty much jpeg resistant.\n\nThe situation is different again for RFC 8391 XMSSMT. XMSSMT is basically a\ncertificate chain of XMSS signatures. An XMSSMT public key is an XMSS\npublic key. An XMSSMT signature is a chain of XMSS signatures: the XMSSMT\npublic key signs another XMSS public key; which signs another public XMSS\npublic key; …; which signs the message. Again the top XMSSMT public key is\nhashed into the message signed, but that only binds the first XMSS\nsignature. We can’t mess with the first signature, but the other signatures\nwe can choose freely, as those roots are not bound. Thus XMSSMT with two\nsubtrees is only half jpeg resistant and it gets worse with more subtrees.\n\nSimilarly SLH-DSA (FIPS 205, née SPHINCS+) is a certificate chain of (a\nvariant of) XMSS signing another XMSS public key, which si",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: jpeg resistance of various post-quantum signature schemes",
      "message_count": 1,
      "participants": [
        "\"'Bas Westerbaan' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/e812604c-94a5-4f5f-87e8-71d178963d62n@googlegroups.com",
          "title": "[bitcoindev] Re: jpeg resistance of various post-quantum signature schemes",
          "author": "\"'Bas Westerbaan' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Thu, 22 May 2025 05:57:33 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 8985 bytes --]\n\n\n\nOn Wednesday, May 21, 2025 at 10:58:00 PM UTC+2 Hunter Beast wrote:\n\nThank you for this! It's definitely informing how we approach development \nof BIP-360. SLH-DSA is concering, in that 7/8 arbitrary data would make it \nabout on par with the de facto witness discount. I don't want to sacrifice \nSLH-DSA because it's favored due to hash-based signatures having more \nconfidence due to not introducing as many novel security assumptions as are \nintroduced with lattice cryptography.\n\n\nAt present, lattices are the only viable approach to post-quantum key \nagreement in TLS. If come Q-day they're broken, then it's not just Bitcoin \nthat's in big trouble. If you do want the certainty of hashes, you might \nwant to consider XMSS: that's JPEG resistant. With parameters n=16, h=20, \nd=1, w=16 it has 32 byte public key and 880 byte signature can sign a \nmillion messages, and only requires 3,000 hashes for verification [1] \n(which can actually be reduced threefold.) The big downside is that if you \nuse the same OTS leaf twice, probably anyone can forge another signature on \nthat leaf. In this case you might make this mistake harder by keeping track \nof the last leaf that was used for each public key. If you see a public key \nsign using the same leaf a second time, you simply ignore the second \nsignature. This helps against an oopsie that's at least a few hours apart, \nbut not if you're using the same leaf twice in short succession.\n \n\nAnother concern regarding SLH-DSA might be its performance, it's an order \nof magnitude more costly to run than FALCON, which itself is an order of \nmagnitude more costly to run than secp256k1 Schnorr...\n\n\nI assume you're talking about signature size? Falcon-512 requires fewer \ncycles to verify than secp256k1. SLH-DSA's verification is a bit slower. \nThere is some flexibility: SLH-DSA today assumes that a signer will make \n2^64 signatures. If you drop that to say one million, then you can ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2075,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Relax OP_RETURN standardness restrictions",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aCH8AdZeBAc0UVfT@erisian.com.au",
          "title": "Re: [bitcoindev] Relax OP_RETURN standardness restrictions",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Mon, 12 May 2025 23:47:45 +1000",
          "body": "On Thu, Apr 17, 2025 at 06:52:34PM +0000, 'Antoine Poinsot' via Bitcoin Development Mailing List wrote:\n> Bitcoin Core will by default only relay and mine transactions with at most a single OP_RETURN output, with a scriptPubKey no larger than 83 bytes. This standardness rule falls into the third category: it aims to mildly deter data storage while still allowing a less harmful alternative than using non-provably-unspendable outputs.\n> \n> Developers are now designing constructions that work around these limitations. An example is Clementine, the recently-announced Citrea bridge, which uses unspendable Taproot outputs to store data in its \"WatchtowerChallenge\" transaction due to the standardness restrictions on the size of OP_RETURNs[^0].\n\nThe reason for limiting OP_RETURNs to 80 bytes of data is to encourage\ndevelopers to store hashes on the chain, rather than the actual\ndata. Why store 1GB when you can commit to it with a 32B hash, and save\n99.9999968% in fees? In all this debate I haven't seen an analysis of\nother alternatives Citrea/Clementine might use, rather than storing 144\nbytes of data on chain.\n\nAs I understand it, the context in which they're using the data is the\nfollowing protocol:\n\n * we have three known groups: Operators, Watchtowers and Signers\n * we also have: Users and Challengers (who can be anyone)\n * we assume that there is at least 1 honest Operator, 1 honest Watchtower,\n   1 honest Signer, and 1 honest Challenger, and >50% honest hashrate\n\nWhen things go wrong, and one of the Operators tries to cheat, one way\nthey can do so is by publishing a claim that they posted a transaction\nin a Bitcoin block that's not actually in the Bitcoin block chain. At\nthat point, an honest Watchtower observers the claim, and produces a\nGroth16 proof that he has a more-work chain that does not contain the\nblock claimed by the Operator.\n\n * but what if the Operator was honest and the Watchtower was trying to cheat?\n\n * in that case, the claimed Groth16 proof can be e",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] Re: Relax OP_RETURN standardness restrictions",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/qps_M7VTLROH7U1v1n_5snfjf-H-Gl-BX-V9qc1JSzzyqfsRoPrbaCzQAQFa1pU4w0cfXZHVnUta6Z7UryG1hUhtpcGXw1ZHiHOfl3HR2jo=@protonmail.com",
          "title": "[bitcoindev] Re: Relax OP_RETURN standardness restrictions",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Wed, 14 May 2025 15:54:55 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2948 bytes --]\n\nHi,\n\nThis proposal was heavily mediatized, and severe mischaracterizations of the change being proposed led to genuine concerns among the community. A better communication from my part could have avoided unnecessary worries among bitcoiners and a lot of wasted time to everybody.\n\nIn an attempt to right this wrong, i have collected objections community members have raised across the board (on Github, the Bitcoin development mailing list, X, podcasts, at conferences, ..) to address them in a single post.\n\nI just posted to Delving Bitcoin addressing all concerns and objections i could get my hands on: https://delvingbitcoin.org/t/addressing-community-concerns-and-objections-regarding-my-recent-proposal-to-relax-bitcoin-cores-standardness-limits-on-op-return-outputs/1697. These are actual objections and concerns raised by community members, taken literally with little or no reformulation to address the precise statement.\n\nAntoine Poinsot\nOn Thursday, April 17th, 2025 at 2:52 PM, Antoine Poinsot <darosior@protonmail•com> wrote:\n\n> Hi,\n>\n> Standardness rules exist for 3 mains reasons: mitigate DoS vectors, provide upgrade hooks, or as a nudge to deter some usages.\n>\n> Bitcoin Core will by default only relay and mine transactions with at most a single OP_RETURN output, with a scriptPubKey no larger than 83 bytes. This standardness rule falls into the third category: it aims to mildly deter data storage while still allowing a less harmful alternative than using non-provably-unspendable outputs.\n>\n> Developers are now designing constructions that work around these limitations. An example is Clementine, the recently-announced Citrea bridge, which uses unspendable Taproot outputs to store data in its \"WatchtowerChallenge\" transaction due to the standardness restrictions on the size of OP_RETURNs[^0]. Meanwhile, we have witnessed in recent years that the nudge is ineffective to deter storing data onchain.\n>\n> Since the ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2059,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position",
      "message_count": 1,
      "participants": [
        "Bob Burnett"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/BY5PR03MB51712A578A9098824DED13FE969EA@BY5PR03MB5171.namprd03.prod.outlook.com",
          "title": "Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position",
          "author": "Bob Burnett <bob.burnett@barefootmining@com>",
          "date": "Wed, 21 May 2025 18:12:52 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 4268 bytes --]\n\nAnd yes, I understand how demand for such services makes sense, and I do not fault you for pursuing them. But they are a threat, and I think the Bitcoin ecosystem should think hard about how to avoid their emergence\n\nI appreciate your response/interaction/opinion.  I do believe you come to your position from your belief on what is in the best interests of Bitcoin, and I respect that.  I realize that you don’t know me, and I can only say that my position is also established with the same intentions.  With that said, I don’t think these types of services are a threat at all.  I think they are essential to a healthy mining network where miners can have some control over a portion of their future revenue streams, especially in the greatly reduced subsidy era we are about to enter.  And, I think the lack of a futures/forward market for blockspace is a major inhibitor to adoption and usage.  Its hard to build a business where access to block space is a necessity without any visibility to the future.  I believe this can be done in a manner that provides openness and transparency, and it would also give us for the first time visibility to future demand and pricing and I think that will be valuable to the enter ecosystem.   Again, thanks for the reply.\n\nFrom: Pieter Wuille <bitcoin-dev@wuille•net>\nDate: Wednesday, May 21, 2025 at 1:52 PM\nTo: Bob Burnett <bob.burnett@barefootmining•com>\nCc: Sjors Provoost <sjors@sprovoost•nl>, Bitcoin Development Mailing List <bitcoindev@googlegroups.com>\nSubject: Re: [bitcoindev] Removing OP_Return restrictions: Devil's Advocate Position\nYou don't often get email from bitcoin-dev@wuille•net. Learn why this is important<https://aka.ms/LearnAboutSenderIdentification>\nHi Bob,\n\nOn Wednesday, May 21st, 2025 at 1:24 PM, Bob Burnett <bob.burnett@barefootmining•com> wrote:\n\nNone of my comments insinuate that deals would not be public or that all users and all miners would not have access to ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2076,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Removing OP_Return restrictions: Devil's Advocate Position",
      "message_count": 1,
      "participants": [
        "Bob Burnett"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/BY5PR03MB5171FCC38022BF80272729FD969EA@BY5PR03MB5171.namprd03.prod.outlook.com",
          "title": "Re: [bitcoindev] Re: Removing OP_Return restrictions: Devil's Advocate Position",
          "author": "Bob Burnett <bob.burnett@barefootmining@com>",
          "date": "Wed, 21 May 2025 02:10:13 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 13990 bytes --]\n\nFor those who don’t know me, I run a mining company called Barefoot Mining– not the biggest mining company but not the smallest either.  Whether I would be considered major or not can be judged by others.\n\nThat said, I suggest being very careful about projecting the current behavior of major miners as the norm or representative of the future.  We are extremely early in the development of the mining industry and there is a high likelihood that over the next few years that there will a dramatic change in the list of major miners – and there very well may be changes in the philosophies and priorities of these miners as well.\n\nI spent most of career in the personal computer industry going back to ’86 (most notably as the CTO of Gateway) and I learned many things from my experience.  One important thing was that the pace with which companies could rise to or fall from prominence was jaw-dropping.  Assuming that “major miners” was meant to mean a group that largely is comprised of pubcos, none of the major players in the mining industry have been doing it for long - with most going public very recently (’22 and ’23).   They but pups as companies and we’ve already seen a huge flameout or two.  The next three to five years will likely result in a few more flameouts and some large new entrants that may approach mining from a completely different perspective.  A second learning I will share from my PC development days was that predicting usages and user behavior is next to impossible.  The safest and most accommodating path is to give as much user optionality/configurability as possible.  My high-level recommendation is to work on paths that give users more choice not less.  This is applies to OP_RETURN but, even more importantly, I think it is the best design direction in general.\n\nTo offer what may be a new lens in which to view miners, I’ll share a bit of my philosophy and vision for my company.  I view Barefoot a",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Weak blocks give an advantage to large miners",
      "message_count": 1,
      "participants": [
        "\"James O'Beirne\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPfvXf+2wkB6MyN6Bogr8c6G3uZq255Ec90qC4y5WxuEGoCPrg@mail.gmail.com",
          "title": "Re: [bitcoindev] Weak blocks give an advantage to large miners",
          "author": "\"James O'Beirne\" <james.obeirne@gmail@com>",
          "date": "Wed, 7 May 2025 20:42:51 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3161 bytes --]\n\nThis analysis excludes two important points:\n\n1. If a small miner has a mempool that is marginally closer to a large\nminer's, they will connect blocks found by that miner more quickly, making\ntheir own mining operation more efficient.\n\n2. A small miner benefits from becoming aware of (potentially large,\nnon-standard, or directly submitted) transactions because they may want to\nmake use of it in their own block templates for more revenue.\n\nBandwidth is rarely a limiting factor for template creators (as there are\nmany more expensive pieces of hardware required to have a competitive\nmining operation), and so a miner may very reasonably decide that it's\nworth trading some bandwidth (in the form of received weak blocks) for the\nprospect of juicing their fee revenue and minimizing tip connection time.\n\n\nOn Mon, May 5, 2025 at 11:36 PM Peter Todd <pete@petertodd•org> wrote:\n\n> On Mon, May 05, 2025 at 07:18:57PM +1000, Anthony Towns wrote:\n> > I meant to mention this last email, but had forgotten where to find\n> > the link. Personally, I think Greg's \"relay extra transactions via weak\n> > blocks\" idea [0] from a year ago is an approach that should be considered\n> > here. The TLDR is that if there are miners out there with different\n> > relay policies than your node that are accepting transactions you'll\n> > reject (eg, lower fee, new tx versions, more complicated dependencies,\n> > ...) then once they find a relatively high PoW share, have the network\n> > relay that as a weak compact block, with full round-trips to gather\n> > any transactions that weren't in your mempool and add those txs to your\n> > extra pool to help with block reconstruction in the near future.\n> >\n> > [0] https://delvingbitcoin.org/t/second-look-at-weak-blocks/805/1\n>\n> Weak blocks give an advantage to large miners. Small miners, who rarely\n> find blocks, are also going to rarely find weak blocks, making the\n> feature mostly useless for them in t",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2063,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Unbreaking testnet4",
      "message_count": 1,
      "participants": [
        "pithosian"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/20250428114858.46B477C1126@smtp.postman.i2p",
          "title": "Re: [bitcoindev] Unbreaking testnet4",
          "author": "pithosian <pithosian@i2pmail@org>",
          "date": "Mon, 28 Apr 2025 11:48:58 +0000 (UTC)",
          "body": "On Sun, 27 Apr 2025 22:54:54 +0000 (UTC)\nJameson Lopp <jameson.lopp@gmail•com> wrote:\n> I'd suggest simply disabling the halving logic and making it a\n> perpetual 50 TBTC issuance. At that rate, it would still take ~8\n> years or so to surpass the 21M limit and I'd think that testnets\n> should be reset more frequently than that.\n\nOn Mon, 28 Apr 2025 11:06:55 +0000 (UTC)\nJameson Lopp <jameson.lopp@gmail•com> wrote:\n> Encoding an \"end of life date\" into testnets is actually an\n> interesting idea worth discussing. As far as I'm aware it's never\n> been done before on any network.\nWhat about having the halving act as a reset? Eg: don't reduce the\nmining reward AND disallow spends of UTXOs from before the last halving.\n\n> On Mon, Apr 28, 2025 at 2:11 AM Saint Wenhao <saintwenhao@gmail•com>\n> wrote:\n> \n> > > Demurrage might be asking a bit much in terms of deviation.\n> >\n> > If that's the case, then why signing all blocks in signet is not\n> > \"too much\"?\n> >\n> \n> Because signet isn't testnet? It gives up permissionless block\n> creation in return for predictability.\n> \n> \n> > Or why unlimited supply is not \"too much\"?\n> >\n> \n> It might be, but it might not be, given that the point of testnet is\n> for coins to be free for developers to acquire and use without fear of\n> financial loss. Thus scarcity isn't really an inviolable property of\n> testnet.\n> \n> \n> > All of these changes were put in the same basket of \"Require\n> > unanimous consent\", so why one kind of change is better or worse\n> > than the others? All of them deviates from the mainnet, and we\n> > probably wouldn't want anything like that on the original chain\n> > anyway.\n> >\n> > > I'd think that testnets should be reset more frequently than that.\n> >\n> > Then why don't we put any kind of reset logic into testnet5\n> > consensus rules? Because when nothing like that is present, then\n> > testnets can potentially run forever. Testnet3 is becoming an\n> > altcoin, and new testnets will also be, if no significant changes\n> >",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2037,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Unbreaking testnet4",
      "message_count": 1,
      "participants": [
        "pithosian"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/20250512201916.3818A7C1190@smtp.postman.i2p",
          "title": "Re: [bitcoindev] Re: Unbreaking testnet4",
          "author": "pithosian <pithosian@i2pmail@org>",
          "date": "Mon, 12 May 2025 20:19:16 +0000 (UTC)",
          "body": "> Not only that. It may also invalidate timelocked signatures, which\n> would be made around \"halving\".\n\nGood point. I was thinking about just hacking at the UTXO set as it\nconceptually seemed to make the change very localized, but timelocks\nprobably(?) rule the whole approach out.\n\nThe freely-spendable amount would be:\n\namount/2^(targetHeight/halvingBlocks-utxoHeight/halvingBlocks)\n\nOr the bitshift equivalent, where targetHeight is the current height,\nor in the case of timelocks, the locked height, but longer\ntimestamp-based timelocks can't be reasoned about very well with any\n'degrading coin' behaviour, and even your presigned, height locked\ntransaction might not get be confirmed before the next epoch if the\ntimelock approaches it.\n\nDoesn't modifying spendability have the same problem? When presigning\nyour timelocked transaction, you need to be aware of the amount you can\nactually spend come expiry of the timelock up-front, however the coin\ndegrades.\n\nIt also breaks lightning channels, I think.\n\nOn Mon, 12 May 2025 18:18:09 +0000 (UTC)\nSaint Wenhao <saintwenhao@gmail•com> wrote:\n\n> > Updating the entire UTXO set all at once would be pretty expensive,\n> \n> Not only that. It may also invalidate timelocked signatures, which\n> would be made around \"halving\". So, if you would sign something, when\n> block height will be set to 209,990, and timelock it into 20 blocks,\n> then at block height 210,010, it would be invalid, because of\n> incorrect amount.\n> \n> Which means, that stored UTXO amounts should be probably left\n> untouched, but rather spendability of the coins should be affected.\n> So: if someone received 50 tBTC, then that person should be able to\n> freely move 25 tBTC anywhere, but 25 tBTC can be enforced to go\n> directly into transaction fees (and so on, and so forth, so later it\n> would be splitted into 12.5 spendable tBTC, and 37.5 tBTC fees).\n> \n> And then, that kind of fees can be claimed directly by miners, or can\n> be simply burned, by just not claiming it, ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2041,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Public disclosure of one vulnerability affecting Bitcoin Core <29.0",
      "message_count": 1,
      "participants": [
        "\"'Antoine Poinsot' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/UCY0pWHlfFg8YzQRMNBHyUIg15CJLI8gM4E-7eHvYmUhkE5mP9Bz71xcHbnyyie8V9ZOnbi6yyKy4rG9h4O8RVx6_tAWD5BV6W71SHHyJiY=@protonmail.com",
          "title": "Re: [bitcoindev] Public disclosure of one vulnerability affecting Bitcoin Core <29.0",
          "author": "\"'Antoine Poinsot' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Fri, 16 May 2025 14:41:22 +0000",
          "body": "> You can find the advisory on the Bitcoin Core project website at https://bitcoincore.org/en/2025/03/31/disclose-cve-2024-52919.\n\nThe link was since updated to https://bitcoincore.org/en/2025/04/28/disclose-cve-2024-52919\n\n\nOn Monday, April 28th, 2025 at 3:00 PM, 'Antoine Poinsot' via Bitcoin Development Mailing List <bitcoindev@googlegroups.com> wrote:\n\n> \n> \n> Hi everyone,\n> \n> In accordance with our security disclosure policy, i am sharing today a low-severity security advisory affecting Bitcoin Core versions before 29.0 (released 2 weeks ago).\n> \n> You can find the advisory on the Bitcoin Core project website at https://bitcoincore.org/en/2025/03/31/disclose-cve-2024-52919.\n> \n> For more details about the Bitcoin Core security disclosure policy, see https://bitcoincore.org/en/security-advisories.\n> \n> Antoine Poinsot\n> \n> --\n> You received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\n> To view this discussion visit https://groups.google.com/d/msgid/bitcoindev/EYvwAFPNEfsQ8cVwiK-8v6ovJU43Vy-ylARiDQ_1XBXAgg_ZqWIpB6m51fAIRtI-rfTmMGvGLrOe5Utl5y9uaHySELpya2ojC7yGsXnP90s%3D%40protonmail.com.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/UCY0pWHlfFg8YzQRMNBHyUIg15CJLI8gM4E-7eHvYmUhkE5mP9Bz71xcHbnyyie8V9ZOnbi6yyKy4rG9h4O8RVx6_tAWD5BV6W71SHHyJiY%3D%40protonmail.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1825,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] [Proposal] 64-bit arithmetic in Script",
      "message_count": 1,
      "participants": [
        "Christian Decker"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CALxbBHWP=zOfT0+YM=4MgR6SEuT9CCFHQEuH_mkgtDKiRxpfog@mail.gmail.com",
          "title": "Re: [bitcoindev] [Proposal] 64-bit arithmetic in Script",
          "author": "Christian Decker <decker.christian@gmail@com>",
          "date": "Wed, 14 May 2025 10:27:54 +0200",
          "body": "Hi Chris,\n\nI was contacted by other ML members pointing out that the GSR may not\nhave announced on the ML. I was not aware, and would not have brought\nit up as a competing effort in such a case.\nApologies for the noise, and I hope that an update on the idea and\ncurrent status of the GSR will be published eventually :-)\n\nRegards,\nChristian\n\nOn Wed, May 14, 2025 at 10:24 AM Chris Stewart\n<stewart.chris1234@gmail•com> wrote:\n>\n> Hi Christian,\n>\n> Thank you for the interest in this proposal!\n>\n> I’d like to invite you, Rusty, or any other contributors to provide an update to the list on the status of GSR. The most recent public writing I’m aware of is Rusty’s blog post, which is now around 18 months old. Are there any newer materials — such as additional posts, WIP BIPs, or code — that we could review or experiment with? Even rough drafts would be helpful for prototyping and discussion.\n>\n> I’m not opposed to the broader goals of GSR, but I do think it’s a bit ambitious. That’s partly why I’ve focused my efforts on isolating what I believe is the most requested feature: 64-bit precision to enable amount locks.\n>\n> >arbitrary sized integers\n>\n> It would be helpful to see some concrete examples of opcodes that would require arbitrary precision, but wouldn’t be achievable with 64-bit arithmetic. Looking at the Elements project, there are a couple of examples — ECMULSCALARVERIFY and TWEAKVERIFY — which operate on 256-bit stack arguments. Notably, these opcodes don’t support composition with existing arithmetic opcodes like OP_ADD or OP_SUB; they simply verify cryptographic conditions. I would argue they do not actually require supporting more precision in Script as the stack arguments aren't parsed into CScriptNum.\n>\n> It could be useful to have a list of these potential opcodes that could be enabled in a single place to give other protocol developers an idea of what is enabled by arbitrary precision.\n>\n> >maybe you could join that effort for your use-cases too?\n>\n> Where c",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2056,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "RE: [bitcoindev] The Tragic Tale of BIP30",
      "message_count": 1,
      "participants": [],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/035301dbbba6$701dd490$50597db0$@voskuil.org",
          "title": "RE: [bitcoindev] The Tragic Tale of BIP30",
          "author": "<eric@voskuil@org>",
          "date": "Fri, 2 May 2025 17:09:05 -0400",
          "body": "Hi Ruben,\n\n> >The obvious solution to this problem is to not create the problem in the first\n> place.\n> \n> Yes, that is a fair point. Not removing the checkpoints is one way of ensuring\n> the consensus bug cannot be triggered.\n\nIt's more than that. We are contemplating a \"consensus bug\" that would cause a chain split because the BIP30 exceptions are no longer being covered by any checkpoint. The heights at which this would cause a split are well below all but 3 of the 14 checkpoints. For that to occur 11 formerly checkpointed blocks would first have to be popped, given the existence of a stronger chain capable of triggering the above bug. This implies 11 more chain splits, depending at which point nodes adopted the checkpoint soft fork(s), just to reach this bug, and up to 14 possible in total. It makes no sense to fix this bug without first fixing chain splits that would be triggered *over 200,000 blocks less deep* than this BIP30 bug. And the only way to fix those is to not remove the checkpoints - which renders this bug inert.\n\n> I'm agnostic about whether having\n> checkpoints is also a reason to forgo consensus checks such as BIP30 (or my\n> proposed alternative of checking the coinbase TXID for uniqueness and\n> ensuring no future collision).\n\nThere is certainly a reason, the checkpoints are consensus rules.\n\n> Even though checkpoints essentially force your node to halt if something were invalid up until that point, \n\nRight, if any other rule conflicted with them then the chain would stall forever at that point. That is not the applied meaning of these rules. The checkpoints declare that the blocks are required and therefore inherently valid. The reason we are having this conversation is the contemplated removal of the checkpoints, which also implies that other validation within covered blocks is not consensus.\n\n> I still think there is value in being able to verify that the rules were followed.\n\nLike them or not, checkpoints are the rules that are required to be",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2042,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
      "message_count": 1,
      "participants": [
        "Sergej Kotliar"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CABZBVTBupMcBbOUtLbMaEmAiWGsMwisNW+k+bTUJGsUad2=ZZg@mail.gmail.com",
          "title": "Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
          "author": "Sergej Kotliar <sergej@bitrefill@com>",
          "date": "Thu, 20 Oct 2022 14:37:53 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 12590 bytes --]\n\nOn Thu, 20 Oct 2022 at 09:22, Anthony Towns <aj@erisian•com.au> wrote:\n\n> On Wed, Oct 19, 2022 at 04:29:57PM +0200, Sergej Kotliar via bitcoin-dev\n> wrote:\n> > The\n> > biggest risk in accepting bitcoin payments is in fact not zeroconf risk\n> > (it's actually quite easily managed),\n>\n> You mean \"it's quite easily managed, provided the transaction doesn't\n> opt-in to rbf\", right? At least, that's what I understood you saying last\n> time; ie that if the tx signals rbf, then you just don't do zeroconf no\n> matter what other trustworthy signals you might see:\n>\n>   https://twitter.com/ziggamon/status/1435863691816275970\n>\n> (rbf txs seem to have increased from 22% then to 29% now)\n>\n\nYeah. Our share of RBF is a bit lower than that as many RBF transactions\nare something other than consumer purchases, and most consumer purchases\ncan't do RBF\n\n\n> > it's FX risk as the merchant must\n> > commit to a certain BTCUSD rate ahead of time for a purchase. Over time\n> > some transactions lose money to FX and others earn money - that evens out\n> > in the end.\n>\n> > But if there is an _easily accessible in the wallet_ feature to\n> > \"cancel transaction\" that means it will eventually get systematically\n> > abused. A risk of X% loss on many payments that's easy to systematically\n> > abuse is more scary than a rare risk of losing 100% of one occasional\n> > payment. It's already possible to execute this form of abuse with opt-in\n> > RBF,\n>\n> If someone's going to systematically exploit your store via this\n> mechanism, it seems like they'd just find a single wallet with a good\n> UX for opt-in RBF and lowballing fees, and go to town -- not something\n> where opt-in rbf vs fullrbf policies make any difference at all?\n>\n\nSort of. But yes once this starts being abused systemically we will have to\ndo something else w RBF payments, such as crediting the amount in BTC to a\ncustodial account. But this option isn't available to your normal p",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2071,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aBmgk4nqULp2_5GA@erisian.com.au",
          "title": "Re: [bitcoindev] Re: [bitcoin-dev] [Opt-in full-RBF] Zero-conf apps in immediate danger",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Tue, 6 May 2025 15:39:31 +1000",
          "body": "On Fri, May 02, 2025 at 08:06:18PM +1000, Anthony Towns wrote:\n> So the mempoolfullrbf default changed from false to true in 28.0 released\n> in October last year, which is advertised as being run by maybe 30%-40%\n> of the network now, and fullrbf transactions have been reportedly been mined\n> reliably since well before that.\n>\n> Any chance of an update on how that change has affected bitcoin/lightning\n> payment volume for you guys, or customer satisfaction (if payment\n> acceptance is delayed more often), or how much engineering/support time\n> was needed to adapt, or any other impact?\n\nThere was a related thread on X late last year that offers some relevant\ninformation for these questions:\n\n  https://x.com/MattAhlborg/status/1828436316930912364\n\nSome key points from that thread, IMO:\n\n * The \"relative volume\" metric shows a drop in bitcoin/lightning volume\n   from 30%-40% in 2022 to 25%-30% in late 2024\n\n * The \"monthly active users\" metric shows a drop in bitcoin/lightning\n   volume from about 50% to about 40% in a similar timeframe, as well as\n   a large switch from on-chain to lightning\n\n * The \"average payment size\" metric shows distinctly different behaviours\n   between on-chain bitcoin users and lightning users -- individual\n   on-chain payments are about 4x greater in value than individual\n   lightning payments\n\n * Bitrefill stopped accepting zeroconf transactions in Aug/Sep 2023; they\n   didn't indicate if this was due to seeing a rise in (attempted?) fraud,\n   or a purely preventative measure.\n\n * The charts show definite correlations between the decrease in on-chain\n   activity with fee spikes\n\n * The charts don't show obvious correlations between on-chain activity\n   and when bitrefill stopped accepting zeroconf transactions. At best\n   you could argue this shows up as volume not returning to on-chain\n   bitcoin after the fee spikes eased.\n\n * This may also be due to a rise in use of bitrefill accounts -- ie,\n   you send a bunch of money to top up your bit",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Graftleaf: Program Composition and Generic Delegation",
      "message_count": 1,
      "participants": [
        "Josh Doman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/0b5b560b-aa0c-4669-9621-67ccbecba516n@googlegroups.com",
          "title": "[bitcoindev] Graftleaf: Program Composition and Generic Delegation",
          "author": "Josh Doman <joshsdoman@gmail@com>",
          "date": "Mon, 5 May 2025 18:27:44 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 13399 bytes --]\n\n \n\n*TLDR: I'm exploring an idea to enable generalized program composition and \ncoin delegation, which seems to strike a nice balance between simplicity \nand flexibility.*\n\nHi all,\n\nI’ve been thinking recently about the optimal way to introduce delegation \nto Bitcoin. The idea of delegating one’s coins is not a new one. Some \nspeculate <https://bitcoinops.org/en/topics/op_codeseparator/> that OP_\nCODESEPARATOR was an early attempt by Satoshi to do delegation. More \nrecently, proposals like Graftroot \n<https://gnusha.org/pi/bitcoindev/CAAS2fgSnfd++94+40vnSRxQfi9fk8N6+2-DbjVpssHxFvYveFQ@mail.gmail.com/>\n and Entroot <https://gist.github.com/sipa/ca1502f8465d0d5032d9dd2465f32603>\n have been put forward, which would enable delegation (and re-delegation), \nbut only from key path spends and only to a locking script. In contrast, \nCSFS <https://github.com/bitcoin/bips/blob/master/bip-0348.md> would enable \ndelegation from script path spends, but it's limited, as it only \nfacilitates delegation within a pre-committed script.\n\nWhen considering delegation, what type of functionality is desirable? I’d \nargue that generalized delegation has two properties:\n\n   1. Delegation *from any valid spending path*\n   2. Delegation *to arbitrarily complex compositions of programs and \n   script*\n\nThe latter is important so that users can delegate to *addresses*, and not \njust public keys, while retaining the ability to add timelocks and other \nconditions.\n\nIn order to build this, we need two key features: 1) \"Generalized \nComposition,\" and 2) \"Generalized Delegation.\" Generalized composition \ninvolves the conjunction of programs and script, and delegation is merely \nthe addition of a second composition on-the-fly, if the primary one is \nsatisfied.\n\nIs there a simple and safe way to implement generalized composition and \ndelegation within Taproot? I think there is...\n\nI’d like to present a proof-of-concept that I came up with, wh",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2067,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] ColliderVM protocol for computation and L2 bridges",
      "message_count": 1,
      "participants": [
        "\"'Victor Kolobov' via Bitcoin Development Mailing List\""
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAF0T6Xhf=Qb+B-3nBtR1Oiyk3gOO=o-8jdT0cJ6fRH=2azQvAg@mail.gmail.com",
          "title": "[bitcoindev] ColliderVM protocol for computation and L2 bridges",
          "author": "\"'Victor Kolobov' via Bitcoin Development Mailing List\" <bitcoindev@googlegroups.com>",
          "date": "Sun, 4 May 2025 15:10:55 +0300",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1330 bytes --]\n\nI would like to update you about an alternative protocol to BitVM that we\nhave been working on, which we call ColliderVM. It uses the same trust\nassumptions as BitVM but without needing fraud proofs. By that it is\neliminating the need for a fraud-proof time window. All in all, some\nadditional work is needed to make this protocol practical.\n\nPerhaps some ideas here could also be of independent interest.\n\n\nHere is the link to the paper:\n\nhttps://eprint.iacr.org/2025/591\n\n(Please note that we erroneously used an incorrect estimate for BLAKE3\nscript size, but this will be fixed in the next version which is coming in\na few days):\n\nWe’ve also made a video explaining this protocol\n\nhttps://starkware.co/blog/avihu-levy-bitcoin-horizons-from-op_cat-to-covenants-hong-kong/\n\nDelving Bitcoin post with more details:\n\nhttps://delvingbitcoin.org/t/collidervm-protocol-for-computation-and-l2-bridges/1662\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAF0T6Xhf%3DQb%2BB-3nBtR1Oiyk3gOO%3Do-8jdT0cJ6fRH%3D2azQvAg%40mail.gmail.com.\n\n[-- Attachment #2: Type: text/html, Size: 6775 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1479,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Introducing Hourglass",
      "message_count": 1,
      "participants": [
        "Hunter Beast"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/db3d0ec4-90b8-44a4-b912-b98ec9083b10n@googlegroups.com",
          "title": "[bitcoindev] Introducing Hourglass",
          "author": "Hunter Beast <hunter@surmount@systems>",
          "date": "Tue, 29 Apr 2025 15:38:26 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 653 bytes --]\n\nThis is a proposal to mitigate against potential mass liquidation of P2PK \nfunds. The specification is pretty simple, but the motivation and \njustification for it is a bit longer.\n\nhttps://github.com/cryptoquick/bips/blob/hourglass/bip-hourglass.mediawiki\n\nFeedback welcome!\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/db3d0ec4-90b8-44a4-b912-b98ec9083b10n%40googlegroups.com.\n\n[-- Attachment #1.2: Type: text/html, Size: 1273 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 807,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Re: Introducing Hourglass",
      "message_count": 1,
      "participants": [
        "Hunter Beast"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/4f35a82a-bedb-4d4d-9de2-2dbc340b18acn@googlegroups.com",
          "title": "[bitcoindev] Re: Introducing Hourglass",
          "author": "Hunter Beast <hunter@surmount@systems>",
          "date": "Sat, 3 May 2025 23:00:11 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2207 bytes --]\n\nTrading volume is a good perspective to view this through, actually. If an \nattacker decides to consolidate immediately, they could do so within just a \ncouple hours and suppress the Bitcoin price for a long time.\n\n> 1.7 million Bitcoin represents possibly about 1 week of global trading \nvolumes. Even assuming it is 1-2 months of trading volumes, the market can \nabsorb.\n\nHourglass spreads that 1 week of trading volume over a minimum of 8 months, \npossibly more.\n\n> Trying to manage the Bitcoin price via spending restrictions is a \nterrible idea.\n\nWhile I generally agree with this sentence, I think P2PK coins are an \nexceptional case.\n\n> In any case, the Bitcoin price routinely drops by upwards of 85%. It is \nnot a security concern. Price volatility is not a security.\n\nPrice volatility absolutely impacts security, and this would be an \nunprecedented event. We also haven't seen an 85% price drop in a long time.\n\nOn Saturday, May 3, 2025 at 5:55:28 AM UTC-6 Francis Pouliot wrote:\n\n>\n> Concept NACK.\n>\n> 1.7 million Bitcoin represents possibly about 1 week of global trading \n> volumes. Even assuming it is 1-2 months of trading volumes, the market can \n> absorb.\n>\n> Trying to manage the Bitcoin price via spending restrictions is a terrible \n> idea.\n>\n> In any case, the Bitcoin price routinely drops by upwards of 85%. It is \n> not a security concern. Price volatility is not a security. \n> On Tuesday, April 29, 2025 at 5:08:16 PM UTC-6 Hunter Beast wrote:\n>\n>> This is a proposal to mitigate against potential mass liquidation of P2PK \n>> funds. The specification is pretty simple, but the motivation and \n>> justification for it is a bit longer.\n>>\n>> https://github.com/cryptoquick/bips/blob/hourglass/bip-hourglass.mediawiki\n>>\n>> Feedback welcome!\n>>\n>\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiv",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 2,
            "text_length": 2039,
            "has_nack": true,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "[bitcoindev] SwiftSync - smarter synchronization with hints",
      "message_count": 1,
      "participants": [
        "Ruben Somsen"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAPv7TjaM0tfbcBTRa0_713Bk6Y9jr+ShOC1KZi2V3V2zooTXyg@mail.gmail.com",
          "title": "[bitcoindev] SwiftSync - smarter synchronization with hints",
          "author": "Ruben Somsen <rsomsen@gmail@com>",
          "date": "Wed, 9 Apr 2025 12:10:21 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 3481 bytes --]\n\nHi everyone,\n\nSwiftSync is a new validation method that allows for near-stateless, fully\nparallelizable validation of the Bitcoin blockchain via hints about which\noutputs remain unspent (<100MB total). All other inputs/outputs are\nefficiently crossed off inside a single hash aggregate that only reaches\nzero if validation was successful and the hints were correct.\n\nThe main observation is that it can be much easier to validate that a given\nUTXO set is correct than to compute it yourself. It allows us to no longer\nrequire a stateful moment-to-moment UTXO set during IBD and allows\neverything to be order independent. I'll briefly summarize the protocol,\nbefore sharing the link to the full write-up.\n\nEach output gets a boolean hint (e.g. committed into Bitcoin Core) about\nwhether or not it will still be in the UTXO set after validation completes.\nIf it does, we write it to disk (append-only - it won't be used until\nSwiftSync finishes). If it does not, we hash the UTXO data and add it to an\naggregate. For each input, we once again hash the UTXO data and remove it\nfrom the aggregate.\n\nAt the end, for every added output there should have been exactly one\nremoved input, bringing the end total of the aggregate to zero. If this is\nindeed the case, we will have validated that the hints, and the resulting\nUTXO set, were correct.\n\nE.g. For spent outputs A, B and inputs C, D we calculate hash(UTXO_A||salt)\n+ hash(UTXO_B||salt) - hash(UTXO_C||salt) - hash(UTXO_D||salt) == 0\n(proving (A==C && B==D) || (A==D && B==C)).\n\nThere is one missing step. The UTXO data is only available when processing\nthe output, but not when processing the input. We resolve this by either\ndownloading the outputs that were spent for each block (equivalent to the\nundo data, maybe 10-15% of a block), or we lean on assumevalid, making it\nsufficient to only hash the outpoints (which are available in both the\noutput and input) rather than the full UTXO da",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2060,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: SwiftSync - smarter synchronization with hints",
      "message_count": 1,
      "participants": [
        "Nagaev Boris"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAFC_Vt6BgUFt5+zbSKzHyN4Sk1nFw5hbXVcv_jdUzA5RJvwFBg@mail.gmail.com",
          "title": "Re: [bitcoindev] Re: SwiftSync - smarter synchronization with hints",
          "author": "Nagaev Boris <bnagaev@gmail@com>",
          "date": "Sat, 3 May 2025 22:06:38 -0300",
          "body": "On Sat, May 3, 2025 at 9:07 AM Greg Maxwell <gmaxwell@gmail•com> wrote:\n>\n> On Saturday, May 3, 2025 at 11:55:28 AM UTC Sanket Kanjalkar wrote:\n>\n> > hash(UTXO_A||salt) + hash(UTXO_B||salt) - hash(UTXO_C||salt) - hash(UTXO_D||salt) == 0 (proving (A==C && B==D) || (A==D && B==C))\n>\n> What if instead of hash we encrypt with AES and modular add/subs? I cannot prove it; but I also don't see a clear way this is broken.\n>\n> 1. Sample random symmetric key `k`\n> 2. Instead of above; AES_k(UTXO_A) + AES_k(UTXO_B) - AES_k(UTXO_C) - AES(UTXO_D) == 0 =>  (proving (A==C && B==D) || (A==D && B==C))?\n>\n>\n> AES in CTR mode is, I'm not sure about other modes? Obviously CTR mode would be unsuitable! (I mean sure modular add/sub and xor are different operations but they are quite close).  I think that in many modes the collision resistance would have to at least be restricted by the birthday bound with the small block size. I think CMC might be needed to avoid that sort of issue.\n\nCan Haraka V2 [1] hash function be used? It is based on AES and\nsupports 256 or 512 bit inputs. UTXO (txid + index) has a fixed size\nand fits into 320 bits. We can use the 512 bit version and just leave\nthe remaining bytes zero.\n\n[1] https://github.com/kste/haraka\n\n-- \nBest regards,\nBoris Nagaev\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/CAFC_Vt6BgUFt5%2BzbSKzHyN4Sk1nFw5hbXVcv_jdUzA5RJvwFBg%40mail.gmail.com.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 1733,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "RE: [bitcoindev] Removing checkpoints in Bitcoin Core v30",
      "message_count": 1,
      "participants": [],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/035701dbbba7$807f23b0$817d6b10$@voskuil.org",
          "title": "RE: [bitcoindev] Removing checkpoints in Bitcoin Core v30",
          "author": "<eric@voskuil@org>",
          "date": "Fri, 2 May 2025 17:16:42 -0400",
          "body": "Hi Sjors,\n\n> In the context of BIP30 [0] Eric Voskuil brought up performance:\n\nI didn't originate the point on performance. I said (in the BIP30 thread):\n\n> One reference states that “assume valid” speeds IBD, but of course it does so by not validating.\n\nWhich was in response to your OP of this thread, which provided that reference, specifically:\n\n\"Assumed Valid Blocks: a feature designed to replace the secondary use of checkpoints for (optionally) speeding up Initial Block Download (IBD) by skipping validation of signatures in old blocks. This was deployed in Bitcoin Core 0.14\" - David A. Harding\n\nThis in turn references the following discussion:\n\n\"Bitcoin 0.5.0 built upon those checkpoints to speed up IBD by skipping verification of signatures in blocks that were earlier in the block chain than the most recent checkpoint.\"\n\nhttps://bitcoincore.org/en/2017/03/08/release-0.14.0/#assumed-valid-blocks\n\n> >  The top checkpoint is consensus for over 11 years and materially reduces\n> the validation cost of 295,000 blocks.\n> \n> I don't think performance should be a consideration when removing\n> checkpoints.\n\nTo be perfectly clear, I am not arguing against this hard fork because it reduces IBD cost. I’m pointing out that one of the arguments *in favor* of removing checkpoints is that \"assume valid\" now serves this \"secondary use\". However, as I pointed out, assume valid is not consensus, it achieves this outcome by trusting, not validating. The existing checkpoints are consensus - they provide this advantage when fully validating.\n\nI'm not suggesting that checkpoints need to be added to improve performance. I'm pointing out that removing them hurts performance. So performance is obviously not a reason to accept such a hard fork.\n\n> Afaik checkpoints were not introduced as a performance feature, but rather as\n> a DoS vulnerability fix.\n\nIt appears from the above discussion that there was more than one reason. However this isn't relevant. What matters is the consequences of ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 0,
            "text_length": 2058,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] BIP Proposal: Define Bitcoin Subunits as Satoshis/Sats",
      "message_count": 1,
      "participants": [
        "Jakub Szwedo"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/3339434d-6a10-4ccf-b1dd-2aa9afee5864n@googlegroups.com",
          "title": "Re: [bitcoindev] BIP Proposal: Define Bitcoin Subunits as Satoshis/Sats",
          "author": "Jakub Szwedo <jakubszwedo@gmail@com>",
          "date": "Fri, 2 May 2025 13:54:26 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 4902 bytes --]\n\nHi,\n\nIf the author of the BIP would like to add some accessibility and voice/UI \nguidance mentioned by Lucas, a great open source resource created by \nBitcoin Design community exists on the topic:\n\nhttps://bitcoin.design/guide/designing-products/units-and-symbols/\n\nI hope it helps.\n\nBest,\nJakub\n\nOn Thursday, 1 May 2025 at 11:24:17 UTC+2 Lucas André wrote:\n\n> Maranatha!\n>\n> I propose a small addition that could improve this, particularly for users \n> relying on assistive technologies (like our boi Hal Finney once did).\n>\n> Specifically, I suggest adding a short section on *accessibility and \n> voice/UI guidance*. Your proposal does a solid job, but it doesn't yet \n> cover how these should be handled in screen readers, voice assistants, or \n> accessible interfaces. Below is a proposed section that could be added \n> under \"specification\" or introduced as a new non-normative section.\n>\n> To ensure clarity and inclusiveness in UIs and assistive technologies, the \n>> following recommendations apply:\n>>  \n>> Pronunciation:\n>> The abbreviation \"sat\" should be pronounced as /sæt/, and \"sats\" (plural) \n>> should be pronounced as /sæts/ (rhyming with \"cats\") by screen readers and \n>> voice assistants. \"Satoshi\" (singular) is pronounced /səˈtoʊʃi/. \"Satoshis\" \n>> (plural) is pronounced /səˈtoʊʃiz/. \n>\n>  \n>\n> Singular vs. Plural:\n>> \"1 sat\" should be read as \"one satoshi\" and \"100 sats\" as \"one hundred \n>> satoshis\" to preserve correct pluralization and meaning. When reading \n>> aloud: \n>\n>  \n>\n> \"1 sat\" → \"one satoshi\" → /wʌn səˈtoʊʃi/\n>> \"100 sats\" → \"one hundred satoshis\" → /wʌn ˈhʌndrəd səˈtoʊʃiz/\n>>  \n>> Readable Formats:\n>> Prefer full terms in accessibility modes (e.g., \"satoshis\" instead of \n>> \"sats\"), and group digits to assist parsing (e.g., \"12,345\" instead of \n>> \"12345\").\n>>  \n>> Contextual Labels:\n>> Interfaces should use clear alt-text or aria-labels such as: *alt=\"Transaction \n>> fee: 14 satoshis per ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/be3813bf-467d-4880-9383-2a0b0223e7e5@gmail.com",
          "title": "[bitcoindev] DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Thu, 17 Apr 2025 16:27:04 +0000",
          "body": "Hi list,\n\nCross-Input Signature Aggregation (CISA) has been a recurring topic here, aiming\nto reduce transaction sizes and verification cost [0]. Tim Ruffing, Yannick\nSeurin and I recently published DahLIAS, the first interactive aggregate\nsignature scheme with constant-size signatures (64 bytes) compatible with\nsecp256k1.\n\nhttps://eprint.iacr.org/2025/692.pdf\n\nRecall that in an aggregate signature scheme, each signer contributes their own\nmessage, which distinguishes it from multi- and threshold signatures, where all\nsigners sign the same message. This makes aggregate signature schemes the\nnatural cryptographic primitive for cross-input signature aggregation because\neach transaction input typically requires signing a different message.\n\nPrevious candidates for constant-size aggregate signatures either:\n- Required cryptographic assumptions quite different from the discrete logarithm\n   problem on secp256k1 currently used in Bitcoin signatures (e.g., groups with\n   efficient pairings).\n- Were \"folklore\" constructions, lacking detailed descriptions and security\n   proofs.\n\nBesides presenting DahLIAS, the paper provides a proof that a class of these\nfolklore constructions are indeed secure if the signer does _not_ use key\ntweaking (e.g., no Taproot commitments or BIP 32 derivation). Moreover, we show\nthat there exists a concrete attack against a folklore aggregate signature\nscheme derived from MuSig2 when key tweaking is used.\n\nIn contrast, DahLIAS is proven to be compatible with key tweaking. Moreover, it\nrequires two rounds of communication for signing, where the first round can be\nrun before the messages to be signed are known. Verification of DahLIAS\nsignatures is asymptotically twice as fast as half-aggregate Schnorr signatures\nand as batch verification of individual Schnorr signatures.\n\nWe believe DahLIAS offers an attractive building block for a potential CISA\nproposal and welcome any feedback or discussion.\n\nJonas Nick, Tim Ruffing, Yannick Seurin\n\n\n[0] See, e.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 2080,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
      "message_count": 1,
      "participants": [
        "waxwing/ AdamISZ"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a9f133ff-1d8e-45a3-8186-79fb52bbd467n@googlegroups.com",
          "title": "Re: [bitcoindev] Re: DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures",
          "author": "waxwing/ AdamISZ <ekaggata@gmail@com>",
          "date": "Wed, 30 Apr 2025 08:54:46 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 4406 bytes --]\n\n\n> That partial signatures do not leak information about the secret key x_k \nis \nimplied by the security theorem for DahLIAS: If information would leak, the \nadversary could use that to win the unforgeability game. However, the \nadversary \ndoesn't win the game unless the adversary solves the DL problem or finds a \ncollision in hash function Hnon.\n\nOK, so that's maybe a theoretical confusion on my part, I'm thinking of the \nHVZK property of the Schnorr ID scheme, which \"kinda\" carries over into the \nFS transformed version with a simulator (maybe? kinda?). Anyway this is a \nsidetrack and not relevant to the paper, so I'll stop on that.\n\n> This is a very interesting point, probably out of scope for the paper. A \nsingle-party signer, given secret keys xi, ..., xn for public keys X1, ..., \nXn \ncan draw r at random, compute R := r*G and then set s := r + c1*x1 + ... + \ncn*xn. So this would only require a single group multiplication.\n\nI feel bad for saying so, but I absolutely do believe it's in scope of the \npaper :) If there is a concrete, meaningful optimisation that's both \npossible and sensible (and as you say, there is such an ultra-simple \noptimisation ... I guess that's entirely correct!), then it should be \nincluded there and not elsewhere. Why? Because it's exactly the kind of \nthing an engineer might want to do, but it's definitely not their place to \nmake a judgement as to whether it's safe or not, given that these protocols \nare such a minefield. I'd say even if there is *no* such optimisation \npossible it's worth saying so.\n\nI guess the counterargument is that it's suitable for a BIP not the paper? \nBut I'd disagree, this isn't purely a bitcoin thing.\n\nOn the third paragraph, yeah, as per earlier email, I realised that that \njust doesn't work.\n\nOn Wednesday, April 30, 2025 at 9:03:34 AM UTC-6 Jonas Nick wrote:\n\n> Thanks for your comments.\n>\n> > That side note reminds me of my first question: would i",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2088,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] [meta] moving conceptual discussion for policy changes",
      "message_count": 1,
      "participants": [
        "Sjors Provoost"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/2294D284-77C1-4885-9585-E591FEE4878A@sprovoost.nl",
          "title": "Re: [bitcoindev] [meta] moving conceptual discussion for policy changes",
          "author": "Sjors Provoost <sjors@sprovoost@nl>",
          "date": "Wed, 30 Apr 2025 17:49:49 +0200",
          "body": "I think it's worth trying, but I don't think it's going to work.\n\nThere's always going to be people who deliberately link directly to a pull request with the goal of wreaking havoc.\n\nIt could just be normal online impulsive behaviour*, similar to road rage. Someone might first comment on the PR, but feels insufficient heard there. This (briefly) makes them angry and they want to share this frustration. The social media algorithm does the rest. By the time you cool down, the damage is done.\n\nBut it can also be done by people who know exactly how this stuff works.\n\n> Op 30 apr 2025, om 16:30 heeft 'Matthew Zipkin' via Bitcoin Development Mailing List <bitcoindev@googlegroups.com> het volgende geschreven:\n> \n> The comment brigade on the OPRETURN pull requests has gotten out of hand and I think we should consider adding a new process step for policy changes.\n\nThat said, people with good intentions should be given every opportunity to voice their concerns in a non-destructive way. It's fair to say that the mailinglist can be a high bar, especially if the social media link takes you to Github. Seeing your comment be moderated without a simple and immediate alternative can lead to extra frustration, it's good if we can prevent that. Since the mailinglist also has a moderation delay, this could add extra fuel to the frustration.\n\n> What I think we need is a second step between the mailing list and the pull request. GitHub \"discussions\" are probably the best format for this, either in bitcoin-core/meta or bitcoin/bitcoin. \n> \n> Taking a hint from Russ' comment in /meta#18, the discussion could be opened with position statements listing all the pro's and con's and most importantly, FAQs and busting myths like \"bigger opreturns make it harder to run a full node\".\n\nIf someone volunteers to write this, that's fine of course. But we should not set this as an expectation. The normal process is to propose on the mailing list and then implement in Bitcoin Core, which this PR followe",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 2072,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Against Allowing Quantum Recovery of Bitcoin",
      "message_count": 1,
      "participants": [
        "Michael Tidwell"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/dbe7018c-149f-4ead-be39-fa368eca06f0n@googlegroups.com",
          "title": "Re: [bitcoindev] Against Allowing Quantum Recovery of Bitcoin",
          "author": "Michael Tidwell <michael@tidwell@io>",
          "date": "Wed, 30 Apr 2025 08:40:41 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 37995 bytes --]\n\nI'm late, but want to share thoughts. I gathered from this thread the way \nmore pertinent and prerequisite idea is to formulate some idea for pqc safe \nschemes, before the idea of burning/freezing/other becomes actionable.\nOriginally I thought Matt's idea of a secure leaf that could be enabled to \nbe the only spend path seemed clever, but after thinking about it more, I \nthink it would be better to cleanly have a new address/ taproot version. \n\n1. We get public data to know how many coins are using the post-quantum \nsecured scheme. Allow better informed decisions on adoptions, planning, and \nunderstanding sentiment on the perceived threat.\n2. would have clean separation for users to know whether or not their \naddress is PQC secured.\n3. for people not worried about it, they wouldn't feel arm-bar'd into \nhaving longer descriptors and an unnecessary leaf.\n4. *unsure here*, but possible that library and wallet developers could \ntreat this with cleaner separation uX, UI and not worry about (legacy-tr) \nvs (pqc-tr) descriptions and script code. (To help users differentiate)\n5. We wouldn't need to worry about some roll out period or flag day where \nthe leafs become necessary or an enabled spend path.\n\nGiven that pqc transactions will likely require additional space and \ncomputational resources, we should be cautious about heavily incentivizing \nuncertain approaches (i.e. it may be advantageous to decide on something \nbefore having certainty about the optimal approach). Significant fee \ndiscounts may be needed once there's high confidence on the \napproach/method. However, enhanced security itself inherently serves as \npart of the explicit incentive, and maybe should be part of the incentive \ncalculation.\n\nOn Monday, April 7, 2025 at 6:34:54 AM UTC-4 Nadav Ivgi wrote:\n\n> One possible alternative to freezing/burning the coins entirely is letting \n> quantum attackers keep some small percent as a reward, but force th",
          "drama_signals": {
            "drama_keywords": 2,
            "positive_keywords": 1,
            "text_length": 2062,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 2
      }
    },
    {
      "title": "Re: [bitcoindev] Standard Unstructured Annex",
      "message_count": 1,
      "participants": [
        "Peter Todd"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/aBBAe265_h9A_lNz@petertodd.org",
          "title": "Re: [bitcoindev] Standard Unstructured Annex",
          "author": "Peter Todd <pete@petertodd@org>",
          "date": "Tue, 29 Apr 2025 02:59:07 +0000",
          "body": "[-- Attachment #1: Type: text/plain, Size: 1380 bytes --]\n\nOn Mon, Apr 28, 2025 at 12:25:08PM -0400, Russell O'Connor wrote:\n> Ah nevermind, I get it now.\n> \n> The contrapositive of this proposed standardness rule is that if one annex\n> is empty, then all annexes must be empty.  Therefore if on participants\n> signs an empty annex, then standardness would imply that all the annexes\n> must be empty.\n\nYou're almost correct.\n\nThere is a consensus distinction between having an annex, and not having\nan annex at all. That means a zero-byte annex is different from not\nhaving an annex at all.\n\nSo with my proposed rule, inputs can either have no annex at all (the\nstandard status quo), or an annex of zero or more bytes.\n\nIf any input has an annex, *all* inputs must have an annex. However, for\nefficiency, they're allowed to have a completely empty, zero-byte,\nannex. So basically an empty annex is just the defined way for an input\nto sign their approval of the use of annexes in that transaction (and\nsubsequent tx pinning risk).\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/aBBAe265_h9A_lNz%40petertodd.org.\n\n[-- Attachment #2: signature.asc --]\n[-- Type: application/pgp-signature, Size: 833 bytes --]",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1578,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Re: Standard Unstructured Annex",
      "message_count": 1,
      "participants": [
        "Antoine Riard"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/8d5251c8-9381-4f35-9d3e-19ba46c8b31cn@googlegroups.com",
          "title": "Re: [bitcoindev] Re: Standard Unstructured Annex",
          "author": "Antoine Riard <antoine.riard@gmail@com>",
          "date": "Wed, 9 Apr 2025 15:55:58 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 5000 bytes --]\n\nHi Peter,\n\n> Applications already using annexes who want to also take advantage of\n> new consensus features will of course have to upgrade their encoding\n> schemes to match. But I think that's fine.\n\nYes, I agree. I believe there is one more thing to falicitate any future\npotential encoding scheme transition for application.\n\nI.e you have the 1-byte : 0x00 | <random_payload_data>, and you could\nhave a an application-only versioning of the <random_payload_data> with\none more 1-byte, to give the evolvability to application to experiment\nwith multiple parsing format.\n\nSo you would have \"1-byte\" 0x00 | \"random_payload_data\" where \n\"random_payload_data\"\nis defined as 1-byte: <version_number> | \"random_payload_data\". That\nversion number shall only have application meaning, no consensus, it's\njust some kind of clear domain separation. AFAICT, the version number\ncould be always retrofitted for a non-0x00 tag-length-value consensus\nmeaning.\n\nIf it can be useful in any way, an old annex branch with a try of TLV:\nhttps://github.com/ariard/bitcoin/commit/84a897feb20c7df813e236d6bf98b69e241a4530\n\nIMHO, this was a very positive thing for taproot to have a lot of\nversioning and upgradeability paths (e.g leaves version, pubkey type, etc).\n\n> There is a possibility of a multi-party, annex-using, protocol where\n> someone does a pinning attack by re-signing their transaction with a\n> bigger annex. But witness-RBF in combination with replace-by-fee-rate\n> will fix this, so I'm not concerned. No such protocols actually exist\n> yet anyway, so we can figure that out later.\n\nCorrect given it's opt-in and that there will be witness-RBF support.\n\nNote, for witness support, where IIUC you have wtxidB allowed to\nreplace wtxidB if wtxidA's feerate > wtxidB and if annex size is\nunbounded, I think it works for multi-party protocols.\n\nFor witness re-composition problems, see:\nhttps://github.com/bitcoin/bitcoin/pull/19645#issuecomment-677",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2049,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] The Future of Bitcoin Testnet",
      "message_count": 1,
      "participants": [
        "Saint Wenhao"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/daecbe84-30e7-4ba8-aa60-596cb7c1658bn@googlegroups.com",
          "title": "Re: [bitcoindev] The Future of Bitcoin Testnet",
          "author": "Saint Wenhao <saintwenhao@gmail@com>",
          "date": "Fri, 25 Apr 2025 10:19:00 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 2883 bytes --]\n\n> Should we plan for a reset of testnet?\n\nSurprisingly, it is a very good question. However, replacing testnet3 with \ntestnet4, by just dropping support for the old network, should not be \ncalled \"reset\", but rather \"abandon\". So, the question is: should we mine a \nnew Genesis Block, at height one, on top of the current Genesis Block from \ntestnet3, and trigger the biggest possible chain reorganization, where the \nwhole chain is reorged in a backward-compatible way?\n\nAlso I wonder, if that method of introducing testnet5, by doing it on top \nof testnet4's Genesis Block is worth considering. Because then, some \nplanned changes, like entirely dropping the difficulty reset, could be \npotentially turned from hard-fork into just a regular soft-fork, supported \nby hashrate majority.\n\nAnd of course, reorging everything is an edge case, that we may want to see \non any testnet first, before anyone will succeed with that on the main \nnetwork, if SHA-256 will ever be broken, and if re-hashing the whole chain \nwill be needed.\n\nponiedziałek, 31 marca 2025 o 22:41:20 UTC+2 Garlo Nicon napisał(a):\n\n> > 4. As a result, TBTC is being actively bought and sold; one could argue \n> that the fundamental principle of testnet coins having no value has been \n> broken.\n>\n> Now, some time passed, so we can look at the history, and get some \n> conclusions. In case of testnet4, the same thing happened. And some people \n> consider testnets as altcoins: \n> https://bitcointalk.org/index.php?topic=5536825.0\n> Which means, that if new testnets will be released in a similar way, then \n> none of them will be worthless.\n>\n> niedziela, 5 maja 2024 o 15:12:08 UTC+2 Peter Todd napisał(a):\n>\n> On Tue, Apr 30, 2024 at 11:46:59AM -0700, Matthew Bagazinski wrote: \n> > \n> > \n> > Unfortunately, the current form of Testnet is doomed to have value, just \n> > like BTC. Its scarcity makes it a valuable asset. And no reset will \n> change \n> > that. It will ",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2047,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "[bitcoindev] Bitcoin Core 29.0 Released",
      "message_count": 1,
      "participants": [
        "Gloria Zhao"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/7897498c-88ec-4c0f-b457-8410944e0ce1n@googlegroups.com",
          "title": "[bitcoindev] Bitcoin Core 29.0 Released",
          "author": "Gloria Zhao <gloriajzhao@gmail@com>",
          "date": "Mon, 14 Apr 2025 18:03:48 -0700 (PDT)",
          "body": "[-- Attachment #1.1: Type: text/plain, Size: 13128 bytes --]\n\nBitcoin Core version 29.0 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-29.0/>\n\nThis release includes new features, various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has \ncompletely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on \nmacOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL \nis\npossible, but it might take some time if the data directory needs to be \nmigrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and tested on operating systems using the\nLinux Kernel 3.17+, macOS 13+, and Windows 10+. Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them. It is not recommended to use Bitcoin Core on\nunsupported systems.\n\nNotable changes\n===============\n\n### P2P and Network Changes\n\n- Support for UPnP was dropped. If you want to open a port automatically,\n  consider using the `-natpmp` option instead, which uses PCP or NAT-PMP\ndepending on router support. (#31130)\n\n- libnatpmp was replaced with a built-in implementation of PCP and NAT-PMP\n  (still enabled using the `-natpmp` option). This supports automatic IPv4 \nport\nforwarding as well as IPv6 pinholing. (#30043)\n\n- When the `-port` configuration option is used, the default onion listening\n  port will now be derived to be that port + 1 instead of being set to a \nfixed\nvalue (8334 on mainnet).  This re-allow",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 2,
            "text_length": 2040,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Post Quantum Signatures and Scaling Bitcoin",
      "message_count": 1,
      "participants": [
        "Ethan Heilman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAEM=y+VK2VwoTc3VbHFbARm9no6qJivrug+LPuGy_m8+PFELOA@mail.gmail.com",
          "title": "Re: [bitcoindev] Post Quantum Signatures and Scaling Bitcoin",
          "author": "Ethan Heilman <eth3rs@gmail@com>",
          "date": "Mon, 14 Apr 2025 15:35:33 -0400",
          "body": "> I'm happy to see thinking and discussion in this area.\n\nGetting this discussion going was exactly my intent. I'm not\npresenting so much a solution as we might want to do this at some\npoint what are problems and can we solve them?\n\n> If it turns out to be the case that PQ schemes need more on-chain size, but have lower per-byte computation cost, a reasonable argument could be made that a higher discount factor for PQ data is acceptable.\n\nI was focused on size because computation is pretty great for most PQ\nsignature schemes. PQ signatures are far cheaper to validate per byte\nand according to BIP-360 Falcon is cheaper than edDSA per signature\nverification.\n\nEdDSA Cycles to verify: 130,000\nFALCON-512 Cycles to verify: 81,036\n\nThis is one of the reasons I am very optimistic that Bitcoin will move\nto post-quantum signatures. If research shows that these signature\nschemes are sufficiently JPEG resistant, and I think it will, then a\ndiscount is very attractive.\n\n> I don't think pre-aggregation (beyond a single-transaction-wide one) is realistic, as it effectively breaks in-mempool transaction replacement, turning every pre-aggregated group of transactions that is being relayed together into an atomic package that must be taken or not as a whole.\n\nIn some circumstances it is possible you could aggregate (P+C1, P+C2)\ninto (P+C1+C2). If you can prove that P is the same in both\ntransactions thus the balance and authentication properties are\nmaintained. However I think what you have described is the shape of\nthe problem we need to solve.\n\nConsider transactions: T1, T1', T2, T3, T4, T5\nwhere T1 and T1' are double spends, i.e., spend the same output to\ndifferent outputs. If half the mempool aggregates TA = (T1, T2, T3)\nand the other half aggregates TB = (T1', T4, T5). TA and TB are\nmutually exclusive and transactions are needlessly dropped on the\nfloor. This is a currently existing griefing vector with coinjoins\ntoday and is an issue with mimblewimble aggregation. I don't think",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2061,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Reiterating centralized coinjoin (Wasabi & Samourai) deanonymization attacks",
      "message_count": 1,
      "participants": [
        "Yuval Kogman"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/CAAQdECB2=FPiTkJ5HT813tcK1522j-J1+2=S=nir6kb33KoQjw@mail.gmail.com",
          "title": "Re: [bitcoindev] Reiterating centralized coinjoin (Wasabi & Samourai) deanonymization attacks",
          "author": "Yuval Kogman <nothingmuch@woobling@org>",
          "date": "Wed, 9 Apr 2025 04:16:35 +0200",
          "body": "On Mon, 7 Apr 2025 at 12:35, Javier Mateos <javierpmateos@gmail•com> wrote:\n> If the coordinator had malicious intentions in the beginning, these have been observed and brought to the table by a community that is always active and vigilant about these crucial issues. I believe this is already part of the healthy culture surrounding Bitcoin.\n\nI don't see a reason to believe the privacy weaknesses I have\ndescribed have been exploited, due to the complexity of the attack. If\nthey are/were exploited as discussed with Sjors above in the thread,\nusers should be able to find evidence of that in their debug logs in\nthe case of wasabi. In regards to samourai, as far as I know no\ncoordinator is operating, and whirlpool functionality has been removed\nfrom the fork that is still maintained.\n\nThat said, there also hasn't been much demand to actually fix these\nissues. They've been publicly documented for years.\n\n> -Overall Transparency: We need clear answers to questions such as: How are the residual funds calculated and allocated? Which wallet(s) are used? Ultimately, this information should be publicly verifiable on the blockchain.\n\nAs far as I know there are currently two compatible client\nimplementations, wasabi wallet and the btcpay coinjoin plugin. The\ntrezor feature was removed following the shutdown of the zksnacks\ncoordinator, as per\nhttps://blog.trezor.io/important-update-transitioning-from-coinjoin-in-trezor-suite-9dfc63d2662f\n\nIt's not verifiable on the blockchain. To the extent that on chain\ndata can be inferred, liquisabi.com provides estimate, but it's just a\nlikely interpretation (in that it's consistent with well known\nbehavior of the client and backend implementations), not proof,\nalthough there's no reason to doubt this information (see earlier in\nthe thread re acknowledgement of the figures' accuracy).\n\nThe source code for these clients is readily available, and has been\nthroughout. Backend code is also available, but it is not possible to\nverify what software",
          "drama_signals": {
            "drama_keywords": 3,
            "positive_keywords": 1,
            "text_length": 2094,
            "has_nack": true,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 3
      }
    },
    {
      "title": "Re: [bitcoindev] New Proposal：String Substring Search in Bitcoin Script - OP_ISSUBSTR",
      "message_count": 1,
      "participants": [
        "Anthony Towns"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/Z_VlNPeDS8Hk3Dyy@erisian.com.au",
          "title": "Re: [bitcoindev] New Proposal：String Substring Search in Bitcoin Script - OP_ISSUBSTR",
          "author": "Anthony Towns <aj@erisian@com.au>",
          "date": "Wed, 9 Apr 2025 04:04:36 +1000",
          "body": "On Tue, Apr 01, 2025 at 12:25:26PM +0000, Pieter Wuille wrote:\n> On Monday, March 31st, 2025 at 4:41 PM, Javier Mateos <javierpmateos@gmail•com> wrote:\n> > The solution of splitting the string and using OP_CAT only works if the exact position of the substring is known. How would a case be handled where the substring could be in any position\n> Whoever produces the signature/witness for spending the coin always knows the position already, so the script can always be modified to instead take that position as an additional input.\n> This is a general principle: the point of scripts is verifying provided information, not computing it. As another example, this means that there is no need for a division or square root opcode if one has a multiplication opcode.\n\nI somewhat disagree with this: there are some concerns that are *easier*\nto express with different opcodes, and I think that's a factor worth\nconsidering.\n\nThis came up with the OP_CAT based proof-of-work faucet [0] -- the\nidea there is that you provide a signature and some nonce data, and\nwhen you combine the two and hash the result, that result begins with\nsome sufficient number of 0 bits (that then gets related back to a\nCHECKSEQUENCEVERIFY delay).\n\nOP_CAT is *sufficient* for testing this, because you just CAT the\nsignature and nonce together and hash them, and can then again CAT the\nthe 0-bits you expect together with some other data and check that all\nof those combined match the hash you calculated earlier.\n\nBut it would be more efficient, and a little easier to code, if you\ncould instead have used SUBSTR/LEFT to pull the initial bytes from\nthe calculated hash and check that those have the expected number of\nleading 0-bits. More efficient, because you don't have to supply all\nthe trailing bytes of the hash in the witness, and easier to code,\nbecause it's a bit more natural to think of manipulating the hash you\ncalculated, rather than having to put user-provided data together and\ncheck that that actually matched ",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2086,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "[bitcoindev] secp256k1lab: a Python library for prototyping",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/d0044f9c-d974-43ca-9891-64bb60a90f1f@gmail.com",
          "title": "[bitcoindev] secp256k1lab: a Python library for prototyping",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Tue, 1 Apr 2025 08:41:37 +0000",
          "body": "Hello list,\n\nWe're pleased to announce the initial release of secp256k1lab, an INSECURE\nimplementation of the secp256k1 elliptic curve and related cryptographic schemes\nwritten in Python, intended for prototyping, experimentation and education.\n\nhttps://github.com/secp256k1lab/secp256k1lab\n\nFeatures:\n\n- Low-level secp256k1 field and group arithmetic.\n- Schnorr signing/verification and key generation according to BIP-340.\n- ECDH key exchange.\n\nWe developed secp256k1lab as part of our work on the ChillDKG work-in-progress\nBIP [0]. It is based on the secp256k1 implementation in the Bitcoin Core test\nframework.\n\nOur goal was to avoid including yet another custom Python implementation of the\nsecp256k1 curve in the ChillDKG reference code. Several existing BIPs (340, 324,\n327, and 352) already contain custom and sometimes subtly diverging\nimplementations of secp256k1. This library aims to provide a single, consistent\ninterface for secp256k1-related cryptographic specifications.\n\nAt the moment, secp256k1lab is included in the ChillDKG repository as a subtree.\nIt remains an open question what would be the best approach for including ChillDKG\n(with the secp256k1lab dependency) into the bips repository [1].\n\nWe welcome your feedback and contributions to this project.\n\nBest regards,\nThe current secp256k1lab maintainers: Sebastian Falbesoner, Jonas Nick, Tim\nRuffing\n\n[0] https://github.com/BlockstreamResearch/bip-frost-dkg\n[1] https://groups.google.com/g/bitcoindev/c/HE3HSnGTpoQ/m/Y2VhaMCrCAAJ\n     (We renamed secp256k1proto to secp256k1lab)\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/d0044f9c-d974-43ca-9891-64bb60a90f1f%40gmail.com.",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 1,
            "text_length": 1985,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "Re: [bitcoindev] Re: secp256k1lab: a Python library for prototyping",
      "message_count": 1,
      "participants": [
        "Jonas Nick"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/a378e1a6-3e0b-4c55-a6fb-58099eb97798@gmail.com",
          "title": "Re: [bitcoindev] Re: secp256k1lab: a Python library for prototyping",
          "author": "Jonas Nick <jonasd.nick@gmail@com>",
          "date": "Mon, 7 Apr 2025 19:16:37 +0000",
          "body": "Hi AdamISZ/waxwing,\n\nI discussed with the maintainers, and we do consider MuSig2 and adaptor\nsignatures to be in-scope. However, we don't currently plan to proactively add\nthese features ourselves.\n\nThe reason the library currently contains an implementation of BIP 340 and not\nonly raw elliptic curve operations is that we use BIP 340 in the ChillDKG\nreference code. So if there is demand to specify a scheme that is based on\nMuSig2 or adaptor signatures, then a similar reasoning would apply. MuSig2 would\nbe particularly easy to add because it already has a python reference\nimplementation and test vectors.\n\n-- \nYou received this message because you are subscribed to the Google Groups \"Bitcoin Development Mailing List\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to bitcoindev+unsubscribe@googlegroups•com.\nTo view this discussion visit https://groups.google.com/d/msgid/bitcoindev/a378e1a6-3e0b-4c55-a6fb-58099eb97798%40gmail.com.",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 0,
            "text_length": 1048,
            "has_nack": false,
            "has_ack": false
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    },
    {
      "title": "Re: [bitcoindev] Does anyone still need testnet3?",
      "message_count": 1,
      "participants": [
        "Sjors Provoost"
      ],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/4B21A2CA-2224-4BD1-AA5D-C5B2F8859E4B@sprovoost.nl",
          "title": "Re: [bitcoindev] Does anyone still need testnet3?",
          "author": "Sjors Provoost <sjors@sprovoost@nl>",
          "date": "Tue, 1 Apr 2025 11:06:05 +0200",
          "body": "[-- Attachment #1: Type: text/plain, Size: 2330 bytes --]\n\nHi Sanket,\n\nI've heard before from some lightning folks that migrating to testnet4 presents a chicken-egg problem.\n\nIf we were to start rotating test networks a frequency of e.g. once every three years, this would become a recurring problem.\n\nLightning seems to be a special case because it relies heavily on interoperability, and so any move has to be coordinated between multiple parties each with their own priorities.\n\nAt the same time Lightning software often needs the latest and greatest Bitcoin Core version e.g. for its new policy features. So sticking to v29 back-ports isn't a long term viable option.\n\n\nI think it's worth considering for the lightning industry to organize a custom signet, either a 1-of-N with keys distributed among the current players, or unsigned proof-of-work based (more hassle, but future new players may feel more comfortable joining). Such a network can be kept online definitely and its replacement can be more easily coordinated. Another advantage is that soft fork proposals can be tested, similar to how Inquisition does that on the default signet, but at a pace that matches Bolt spec work.\n\n- Sjors\n\n> Op 31 mrt 2025, om 23:15 heeft Sanket Kanjalkar <sanket1729@gmail•com> het volgende geschreven:\n> \n> Hi Sjors, \n> Thanks for asking. Block/Cashapp relies on testnet3 and can't migrate to testnet4 mostly because of lack of lightning LND peers.\n> I don't think there are any LND Lightning peers on testnet4. We (Block/Cashapp lightning) use LDK for Lightning, but most of our peers run LND. LND support for testnet4 was just merged <https://github.com/lightningnetwork/lnd/pull/9620>, so it’ll likely take time for the LND community to update node infrastructure.\n> We want to catch peering, business logic and lightning implementations interoperability issues in testnet. Even though LDK supports testnet4, switching now isn’t viable for us until our mainnet LND peers migrate. \n> \n\n-- \nYou receiv",
          "drama_signals": {
            "drama_keywords": 1,
            "positive_keywords": 2,
            "text_length": 2050,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 1
      }
    },
    {
      "title": "RE: [bitcoindev] Consensus Cleanup BIP draft",
      "message_count": 1,
      "participants": [],
      "messages": [
        {
          "url": "https://gnusha.org/pi/bitcoindev/009d01dba278$dcde1a00$969a4e00$@voskuil.org",
          "title": "RE: [bitcoindev] Consensus Cleanup BIP draft",
          "author": "<eric@voskuil@org>",
          "date": "Mon, 31 Mar 2025 16:09:51 -0400",
          "body": "> Hi Eric,\n> \n> Thanks for chiming in.\n\nCertainly, thank you as well for your work on this.\n\n> > This kind of discontinuity always comes back to bite eventually. That concern\n> should not be dismissed so casually.\n> \n> I don't think i've dismissed your concern when you brought this up last year. In\n> fact i link to my summary of arguments on both sides of this debate in the BIP:\n> https://delvingbitcoin.org/t/great-consensus-cleanup-revival/710/41.\n\nYou have been fair. I don't mean to imply that you dismissed the points I raised. But it doesn't seem to me that this discontinuity has been given much weight. This was the issue that Jeremy raised.\n\n>>> It's a wart in how transactions work, and future upgrades (especially around tx programmability) might integrate very poorly with this kind of edge condition.\n\nFrom my experience every condition magnifies complexity over time. We are talking about moving a condition from SPV clients into consensus.\n\n> > But more to the point, it does not solve any of the problems that were\n> originally provided as justification, apart from making it slightly simpler to\n> implement an SPV wallet (no need to get the coinbase tx).\n> \n> I did provide an incorrect motivation at some point (caching), and appreciate\n> your correction on this. But the main original motivation for invalidating 64\n> bytes transactions was always to get rid of the footgun for SPV verifiers...\n\nThis thread contains the technical discussion on the question:\nhttps://groups.google.com/g/bitcoindev/c/CAfm7D5ppjo/m/MsOdTqYyCwAJ\n\nYour early response to my query listed:\n(1) make node invalidity caching more performant.\n(2) preclude the need for SPV clients to get the coinbase proof.\n(3) \"Finally, it would get rid of a large footgun in general. Certainly, unique block hashes would be a useful property for Bitcoin to have. It's not far-fetched to expect current or future Bitcoin-related software to rely on this.\"\n\nThe tradeoff was described as:\n\"Outlawing 64-bytes transactio",
          "drama_signals": {
            "drama_keywords": 0,
            "positive_keywords": 1,
            "text_length": 2045,
            "has_nack": false,
            "has_ack": true
          }
        }
      ],
      "drama_signals": {
        "drama_keywords": 0
      }
    }
  ],
  "summary": {
    "total_threads": 38,
    "total_messages": 38,
    "unique_participants": 25
  }
}