{
  "source": "github",
  "repository": "bitcoin/bitcoin",
  "fetched_at": "2026-01-15T19:28:27.084712+00:00",
  "date": "2025-03-28",
  "pull_requests": [
    {
      "number": 32161,
      "title": "Fix legacy migration bug",
      "body": "Fix: Prevent crash on null legacy_spkm in GetDescriptorsForLegacy\r\n\r\nThis pull request resolves a critical issue that caused Bitcoin Core to crash during legacy wallet migration. The 'GetDescriptorsForLegacy' function was not properly handling cases where 'legacy_spkm' was a null pointer, leading to a dereference error.\r\n\r\nThis PR implements the following changes:\r\n\r\n* Adds an explicit null pointer check for 'legacy_spkm'.\r\n* Adds detailed error logging, including the key associated with the null pointer.\r\n* Adds user-facing error messages to inform the user of the migration failure.\r\n* Adds a unit test to 'wallet_tests.cpp' to ensure the fix is robust and to prevent future regressions.\r\n\r\nThis change improves the stability of the wallet migration process and provides better debugging information.",
      "state": "closed",
      "user": "olaristo109",
      "created_at": "2025-03-28T20:12:16Z",
      "updated_at": "2025-03-29T00:53:44Z",
      "comments": 4,
      "url": "https://github.com/bitcoin/bitcoin/pull/32161",
      "labels": [
        "CI failed"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/32161.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\nA summary of reviews will appear here.\n",
          "created_at": "2025-03-28T20:12:19Z"
        },
        {
          "user": "DrahtBot",
          "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Debug: https://github.com/bitcoin/bitcoin/runs/39611305364</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n",
          "created_at": "2025-03-28T20:24:43Z"
        },
        {
          "user": "davidgumberg",
          "body": "Hi @olaristo109!\r\n\r\nThanks for taking a look at this, you mention adding \"a unit test to 'wallet_tests.cpp' to ensure the fix is robust and to prevent future regressions.\", but I don't see that in this  PR, and the PR contains some unnecessary/unrelated changes, like fixing a \"typo\" (which is not a typo) in `release-process.md`, and adding an unnecessary `try` `catch` block and then returning early in `CWallet::ApplyMigrationData()`\r\n\r\nI am also not convinced that this actually solves the underlying issue in #32112, I left a comment above, but I'm not convinced that the existing [`Assume`, comment, and error message](https://github.com/bitcoin/bitcoin/blob/9acc25bcb674c05702d14b65487caeafa5ad549b/src/wallet/wallet.cpp#L4088-L4090) in `GetDescriptorsForLegacy()` are all mistaken that having no `legacy_spkm` there is really a problem and should never happen. \r\n\r\nGiven the format of your PR description, and the fact that it mentions changes not contained in the PR, and your PR makes changes that are totally out of scope and unrelated to the PR, and makes additional changes that don't make any sense, I feel that you have leaned pretty heavily on an LLM to author this PR.  I don't want to discourage you from contributing and from using an LLM as a tool to help you do that, but if you open a PR that makes changes you haven't reviewed and understood yourself, you are wasting your time and the time of reviewers.",
          "created_at": "2025-03-28T22:04:32Z"
        },
        {
          "user": "furszy",
          "body": "The code makes no sense. Time is a scarce resource. Would suggest to just close the PR.",
          "created_at": "2025-03-28T22:18:43Z"
        }
      ]
    },
    {
      "number": 32159,
      "title": "net, pcp: handle multi-part responses and filter for default route while querying default gateway",
      "body": "...for default route in pcp pinholing.\r\n\r\nCurrently we only make a single recv call, which trucates results from large routing tables, or in the case the kernel may split the message into multiple responses (which may happen with `NLM_F_DUMP`).\r\n\r\nWe also do not filter on the default route. For IPv6, this led to selecting the first route with an `RTA_GATEWAY` attribute, often a non-default route instead of the actual default. This caused PCP port mapping failures because the wrong gateway was used.\r\n\r\nFix both issues by adding multi-part handling of responses and filter for the default route.\r\n\r\nLimit responses to ~ 1MB to prevent any router-based DoS.",
      "state": "closed",
      "user": "willcl-ark",
      "created_at": "2025-03-28T14:11:46Z",
      "updated_at": "2025-09-04T15:15:15Z",
      "comments": 19,
      "url": "https://github.com/bitcoin/bitcoin/pull/32159",
      "labels": [
        "P2P"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/32159.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [achow101](https://github.com/bitcoin/bitcoin/pull/32159#issuecomment-3250971643), [davidgumberg](https://github.com/bitcoin/bitcoin/pull/32159#issuecomment-3251165278), [Sjors](https://github.com/bitcoin/bitcoin/pull/32159#issuecomment-3252262528) |\n| Concept ACK | [laanwj](https://github.com/bitcoin/bitcoin/pull/32159#issuecomment-2761607177) |\n\nIf your review is incorrectly listed, please react with ðŸ‘Ž to this comment and the bot will ignore it on the next update.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-03-28T14:11:49Z"
        },
        {
          "user": "willcl-ark",
          "body": "cc @laanwj\r\n\r\nThis patch maintains the FreeBSD-style querying/filtering we have currently, but but increases the size of the response processed to a maximum of 1MB.",
          "created_at": "2025-03-28T14:13:47Z"
        },
        {
          "user": "laanwj",
          "body": "Concept ACK\r\n\r\n~~Adding 29.0 milestone,~~ doesn't need to block the release but it would be nice to backport it.\r\n\r\nEdit: removed, the milestone, i still think it'd be nice to have in next 29.x release, but it turns out more complicated and riskier than expected, better to have no immediate time pressure",
          "created_at": "2025-03-28T14:55:46Z"
        },
        {
          "user": "willcl-ark",
          "body": "Thanks for the review @Sjors & @laanwj.\r\n\r\nGoing to move to draft while I re-work it a little.",
          "created_at": "2025-04-01T09:26:24Z"
        },
        {
          "user": "DrahtBot",
          "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Debug: https://github.com/bitcoin/bitcoin/runs/39838257320</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n",
          "created_at": "2025-04-02T11:05:56Z"
        },
        {
          "user": "willcl-ark",
          "body": "After (additional) further investigation I gained some new insights:\r\n\r\n- This is _not_ a regression from migration from `libnatpmp` as I first thought.\r\n- The extent to which `tailscale` interferes with the routing is more significant than I realised:\r\n  Even if we find the correct  gateway (by handling multi-part messages and filtering properly), the _route_ to the gateway still doesn't return the data we want, specifically the correct interface.\r\n  This causes us to make an invalid request, which gets rejected.\r\n\r\n  This is also observed using the `ip` command:\r\n  ```bash\r\n  $ ip route show\r\n  default via 10.0.0.1 dev wlo1 proto dhcp src 10.0.12.100 metric 600\r\n  10.0.0.0/20 dev wlo1 proto kernel scope link src 10.0.12.100 metric 600\r\n  172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1\r\n  192.168.122.0/24 dev virbr0 proto kernel scope link src 192.168.122.1 linkdown\r\n\r\n  will@ubuntu in â€¦/src/core/bitcoin on î‚  pcp-default-multipart [$?â‡•] : C v19.1.7-clang via â–³ v3.31.6 : ðŸ (core)\r\n  $ ip route get 10.0.0.1\r\n  10.0.0.1 dev tailscale0 table 52 src 100.89.20.73 uid 1000\r\n      cache\r\n  ```\r\n\r\n  Handling this would be quite invasive, require tracking the interface, and I don't think it's in scope for us.\r\n\r\nTherefore I have re-worked and split the remaining changes and into 3 commits:\r\n\r\n1. Filter for the default route in the response. With this change ipv6 pinholing works even with `tailscale up`, which is quite nice.\r\n2. Skip non `NEWROUTE` messages. Although `NLMSG_DONE` is already handled, this is a slight optimisation in protecting against unexpected responses being parsed.\r\n3. Handle single and multi-part messages. Track if `NLM_F_MULTI` was set and if so wait for `NLMSG_DONE`, otherwise break after the first response, assuming a single-part response.\r\n\r\nI think these are all worthwhile, but I could seean argument that what we currently have works \"well enough\" for the most basic use-case; a simple (single) routing table. And we could just consider anything else out-of-scope in this project.\r\n\r\n@Sjors: Ref your comments, the socket is set as `nonblocking` already via the implementation in `CreateSockOS` in https://github.com/bitcoin/bitcoin/blob/74d9598bfbc24c3b7bfe1dad5bf9d988381bf893/src/netbase.cpp#L536-L540 I did [try a commit](https://github.com/bitcoin/bitcoin/commit/2f0b8d61b63edcaa1a9ac06b7e02cd3ea6e1e554) to add a backoff timer and retry mechanism to this for extra safety, but pretty sure it's not worth the added complexity.\r\n",
          "created_at": "2025-04-02T13:56:15Z"
        },
        {
          "user": "fanquake",
          "body": "@laanwj you might be interested in circling back here to review?",
          "created_at": "2025-05-08T15:39:56Z"
        },
        {
          "user": "laanwj",
          "body": "> you might be interested in circling back here to review?\r\n\r\nYes, will look into it.\r\n\r\n> This is not a regression from migration from libnatpmp as I first thought.\r\n\r\nRemoved the backport label as this was confirmed not to be a regression (thanks!).",
          "created_at": "2025-05-13T14:19:39Z"
        },
        {
          "user": "fanquake",
          "body": "Put this on the `v30.0` milestone.",
          "created_at": "2025-07-17T14:51:52Z"
        },
        {
          "user": "achow101",
          "body": "ACK 4c531782569b42fc47478a468f4a79e0e2d93946\r\n\r\nVerified against iproute2 and strace",
          "created_at": "2025-08-18T21:08:30Z"
        },
        {
          "user": "davidgumberg",
          "body": "untested crACK 4c531782569b42fc474\r\n\r\nhttps://github.com/bitcoin/bitcoin/pull/32159/commits/57ce645f05d18d8ad10711c347a5989076f1f788 corrects a bug where `QueryDefaultGatewayImpl` would return *not* default gateways.\r\n\r\nhttps://github.com/bitcoin/bitcoin/pull/32159/commits/42e99ad77396e4e9b02d67daf46349e215e99a0f adds a belt and suspenders check that we have received a sensible reply to our `GETROUTE` message.\r\n\r\nhttps://github.com/bitcoin/bitcoin/pull/32159/commits/4c531782569b42fc47478a468f4a79e0e2d93946 correctly handles multi-part messages, I believe the current implementation would fail e.g. any time the reply to our `GETROUTE` was in excess of [4096 bytes](https://github.com/bitcoin/bitcoin/blob/4c531782569b42fc47478a468f4a79e0e2d93946/src/common/netif.cpp#L89)\r\n\r\nI left a few non-blocking nits, and comments that provide some context that I had to look for when reviewing the changes here.",
          "created_at": "2025-08-28T22:23:17Z"
        },
        {
          "user": "Sjors",
          "body": "utACK 4c531782569b42fc47478a468f4a79e0e2d93946\r\n\r\nI didn't specifically test multipart messages.\r\n\r\nI did test this (rebased) PR with a router running OPNsense 25.7.2 with miniupnpd 2.3.9 using pf backend. \r\n\r\nFrom a macOS 15.6.1 machine and macOS 13.7.8 machine I can see it opens a port and I'm (still) getting inbound connections. This is unsurprising, because the changes here don't impact macOS.\r\n\r\nI also tested on Ubuntu 25.04\r\n\r\n\r\n\r\n",
          "created_at": "2025-09-01T12:35:51Z"
        },
        {
          "user": "hodlinator",
          "body": "Tested but did not dig deep into the code for now. Spent more than a day adding debug code in Bitcoin Core and fighting with my OpenWrt router (https://github.com/openwrt/packages/issues/17871#issuecomment-3243222244). Now that the router has been fully reset without any lingering configs from prior major versions, PCP & NATPMP is actually working.\r\n\r\nOn master (in 7/7 attempts roughly):\r\n```\r\nâ‚¿ cmake --build build -j16 --target=bitcoind && ./build/bin/bitcoind -regtest -debug=net\r\n...\r\nBitcoin Core version v29.99.0-74d9598bfbc2 (release build)\r\n[warning] Option '-upnp=true' is given but UPnP support was dropped in version 29.0. Substituting '-natpmp=true'.\r\n...\r\n[net] portmap: gateway [IPv4]: 192.168.1.1\r\n[net] pcp: Requesting port mapping for addr 0.0.0.0 port 18444 from gateway 192.168.1.1\r\n[net] pcp: Internal address after connect: 192.168.1.201\r\nAddLocal([1111:1111::1]:18444,1)\r\nDiscover: 1111:1111::1\r\nBound to 127.0.0.1:18445\r\nBound to [::]:18444\r\nBound to 0.0.0.0:18444\r\nLoaded 0 addresses from \"anchors.dat\"\r\n0 block-relay-only anchors will be tried for connections.\r\ninit message: Starting network threadsâ€¦\r\nnet thread start\r\ninit message: Done loading\r\nopencon thread start\r\naddcon thread start\r\nmsghand thread start\r\ndnsseed thread start\r\nLoading addresses from DNS seed dummySeed.invalid.\r\n0 addresses found from DNS seeds\r\ndnsseed thread exit\r\n[net] pcp: Received response of 60 bytes: REDACTED...\r\n[net:info] portmap: Added mapping pcp:< REDACTED  >:18450 -> 192.168.1.201:18444 (for 2400s)\r\nAddLocal(< REDACTED  >:18450,3)\r\n[net] portmap: gateway [IPv6]: fe80::REDACTED...\r\n[net] pcp: Requesting port mapping for addr 1111:1111::1 port 18444 from gateway fe80::REDACTED...\r\n[net] pcp: Internal address after connect: 1111:1111::1\r\n[net] pcp: Received response of 60 bytes: REDACTED...\r\n[net:warning] pcp: Mapping failed with result ADDRESS_MISMATCH (code 12)\r\n```\r\nOn the router side:\r\n```\r\n... daemon.err miniupnpd[14402]: PCP: Invalid PCP v2 MAP message.\r\n```\r\nTaking the first commit (57ce645f05d18d8ad10711c347a5989076f1f788) from this PR makes the output towards the end better (my ISP doesn't support IPv6):\r\n```\r\n[net] pcp: Received response of 60 bytes: REDACTED...\r\n[net:info] portmap: Added mapping pcp:< REDACTED  >:18464 -> 192.168.1.201:18444 (for 2400s)\r\nAddLocal(< REDACTED  >:18464,3)\r\n[net] portmap: Could not determine IPv6 default gateway\r\n```\r\nAnd there is no longer any error in the router log.\r\n\r\nSo PCP+IPv4 mostly works regardless of the PR, but at least the failure path for IPv6 is improved by it.\r\n\r\nHaven't really noticed any changes in behavior with my setup from the latter 2 commits.\r\n\r\nMight focus on other things for now as this already has 3 ACKs.",
          "created_at": "2025-09-01T21:41:55Z"
        },
        {
          "user": "Sjors",
          "body": "> Now that the router has been fully reset without any lingering configs from prior major versions, PCP & NATPMP is actually working.\r\n\r\nYou would not be the first person running into router bugs while testing NAT punching functionality :-)",
          "created_at": "2025-09-02T06:47:34Z"
        },
        {
          "user": "achow101",
          "body": "ACK 88db09bafe9ec363525e5e526c5f6cdd13691447",
          "created_at": "2025-09-03T22:09:47Z"
        },
        {
          "user": "davidgumberg",
          "body": "Code Review re-ACK 88db09b\r\n\r\n```console\r\n$ git range-diff 4c53178...88db09b\r\n```\r\n\r\nhttps://github.com/bitcoin/bitcoin/commit/88db09bafe9ec363525e5e526c5f6cdd13691447 takes the [reviewer suggestion](https://github.com/bitcoin/bitcoin/pull/32159#discussion_r2302222710) of moving the `rtmsg*` cast after checking if `hdr->nlmsg_type == NLMSG_DONE`which resolves https://github.com/bitcoin/bitcoin/issues/33245 and implements [a suggested refactor](https://github.com/bitcoin/bitcoin/pull/32159#discussion_r2308655496) that simplifies the multi-message/done state tracking in the `NLMSG_NEXT` loop.",
          "created_at": "2025-09-04T00:00:48Z"
        },
        {
          "user": "Sjors",
          "body": "re-utACK 88db09bafe9ec363525e5e526c5f6cdd13691447",
          "created_at": "2025-09-04T07:18:22Z"
        },
        {
          "user": "ryanofsky",
          "body": "Do we know if this change might fix the integer overflow error reported https://github.com/bitcoin/bitcoin/pull/32345#discussion_r2294091366?",
          "created_at": "2025-09-04T14:00:43Z"
        },
        {
          "user": "willcl-ark",
          "body": "I moved variables as per https://github.com/bitcoin/bitcoin/pull/32159#discussion_r2302222710 to try and fix this in here. I did not verify whether it worked, however.",
          "created_at": "2025-09-04T15:15:15Z"
        }
      ]
    },
    {
      "number": 32158,
      "title": "fuzz: Make partially_downloaded_block more deterministic",
      "body": "This should make the `partially_downloaded_block` fuzz target even more deterministic.\r\n\r\nFollow-up to https://github.com/bitcoin/bitcoin/pull/31841. Tracking issue: https://github.com/bitcoin/bitcoin/issues/29018.\r\n\r\nThis bundles several changes:\r\n\r\n* First, speed up the `deterministic-fuzz-coverage` helper by introducing parallelism.\r\n* Then, a fix to remove spawned test threads or spawn them deterministically. (While testing this, high parallelism and thread contention may be needed)\r\n\r\n### Testing\r\n\r\nIt can be tested via (setting 32 parallel threads):\r\n\r\n```\r\ncargo run --manifest-path ./contrib/devtools/deterministic-fuzz-coverage/Cargo.toml -- $PWD/bld-cmake/ $PWD/../b-c-qa-assets/fuzz_corpora/ partially_downloaded_block 32\r\n```\r\n\r\nLocally, on a failure, the output would look like:\r\n\r\n```diff\r\n ....\r\n-  150|      0|            m_worker_threads.emplace_back([this, n]() {\r\n-  151|      0|                util::ThreadRename(strprintf(\"scriptch.%i\", n));\r\n+  150|      1|            m_worker_threads.emplace_back([this, n]() {\r\n+  151|      1|                util::ThreadRename(strprintf(\"scriptch.%i\", n));\r\n ...\r\n```\r\n\r\nThis excerpt likely indicates that the script threads were started after the fuzz init function returned.\r\n\r\nSimilarly, for the scheduler thread, it would look like:\r\n\r\n```diff\r\n ...\r\n   227|      0|        m_node.scheduler = std::make_unique<CScheduler>();\r\n-  228|      1|        m_node.scheduler->m_service_thread = std::thread(util::TraceThread, \"scheduler\", [&] { m_node.scheduler->serviceQueue(); });\r\n+  228|      0|        m_node.scheduler->m_service_thread = std::thread(util::TraceThread, \"scheduler\", [&] { m_node.scheduler->serviceQueue(); });\r\n   229|      0|        m_node.validation_signals =\r\n ...\r\n```",
      "state": "closed",
      "user": "maflcko",
      "created_at": "2025-03-28T14:04:45Z",
      "updated_at": "2025-10-30T13:59:39Z",
      "comments": 5,
      "url": "https://github.com/bitcoin/bitcoin/pull/32158",
      "labels": [
        "Tests",
        "Fuzzing"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/32158.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [hodlinator](https://github.com/bitcoin/bitcoin/pull/32158#pullrequestreview-2732258794), [janb84](https://github.com/bitcoin/bitcoin/pull/32158#pullrequestreview-2732431160), [Prabhat1308](https://github.com/bitcoin/bitcoin/pull/32158#issuecomment-2770385786) |\n\nIf your review is incorrectly listed, please react with ðŸ‘Ž to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#32113](https://github.com/bitcoin/bitcoin/pull/32113) (fuzz: enable running fuzz test cases in Debug mode by ajtowns)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n",
          "created_at": "2025-03-28T14:04:48Z"
        },
        {
          "user": "maflcko",
          "body": "I've run `cargo run --manifest-path ./contrib/devtools/deterministic-fuzz-coverage/Cargo.toml -- $PWD/bld-cmake/ $PWD/../b-c-qa-assets/fuzz_corpora/ partially_downloaded_block 128` for about 300 times and it passed. So hopefully this is good enough for now. (In theory the scheduler thread may still be woken spuriously, even if there is no work, but the only solution to that would be to disable it completely for all fuzz targets that don't need it.)",
          "created_at": "2025-03-29T10:34:09Z"
        },
        {
          "user": "janb84",
          "body": "The 128 run fails on my machine: `fuzz failed: Too many open files (os error 24)`\r\n\r\nHave used the following command: \r\n```shell\r\n cargo run --manifest-path ./contrib/devtools/deterministic-fuzz-coverage/Cargo.toml -- $PWD/build/ $PWD/qa-assets/fuzz_corpora/ partially_downloaded_block 128\r\n ```\r\n \r\nThe 32 run works. I'm on a M1 MAX, in a nix-shell clang  19.1.7, cargo 1.85.0\r\n\r\nEDIT: the `ulimit` was default 256 on NixOS, have now set it to 4096 and it runs.   `ulimit -n 4096`",
          "created_at": "2025-03-31T19:55:02Z"
        },
        {
          "user": "maflcko",
          "body": "> I'm having issues reproducing diffs containing `m_service_thread|scriptch` without the C++ fix. Managed to produce a `scriptch`-containing diff 1-2 times out of ~40 runs. **Any further tips on which qa-assets commit to use, or any other conditions that might help are welcome.**\r\n\r\nWhat is your clang version and do you mind sharing the cmake configure command and the full diff? I just used the tip of qa-assets.",
          "created_at": "2025-04-01T08:00:16Z"
        },
        {
          "user": "Prabhat1308",
          "body": "re-ACK [`fa51310`](https://github.com/bitcoin/bitcoin/pull/32158/commits/fa513101212327f45965092652f6497aa28362ec)\r\n\r\nTested with various multiple values of parallel threads. All tests passed.",
          "created_at": "2025-04-01T18:46:31Z"
        }
      ]
    }
  ],
  "issues": [
    {
      "number": 32160,
      "title": "Test Package Accept",
      "body": "### Please describe the feature you'd like to see added.\n\n**Description of how the feature should work:**\nThe `testmempoolaccept` RPC should continue to take a list of hex transactions with minimal restrictions (no duplicates, no conflicting transactions, not too many). It should allow singleton transactions, transactions already in mempool, and any topology (multiple disconnected components should be ok). It should attempt to validate as much as possible and return each transaction's validation result. Of course, it should not modify mempool contents while doing so, and most importantly it should simulate the fee-bumping policies like package CPFP and package RBF.\n\n**Problems today:**\nWe added multi-transaction support in `testmempoolaccept` in #20833, before package policies were decided. It enabled some of the validation functionality that package validation uses, but ultimately has a different codepath and thus different interface. It has roughly the input requirements that we want (no duplicates, no conflicts, max 25, topological). Its results array format is also fine in my opinion.\nThe biggest problem is that it doesnâ€™t apply package policies. So if you have a 1p1c package with the parent bumped by the child, `testmempoolaccept` says that the parent has too low feerate, but `submitpackage` says it's accepted. This is confusing.\n\n**Why fixing this is hard:**\n(1) Our method of â€œsplittingâ€ a package is not compatible with test acceptance because it is trial-and-error based. Instead, it should decide what subpackages will be up front.\n(2) We canâ€™t stage and unstage the changes made by each subpackage on top of the changes made by previous subpackages without applying the changes to mempool.\n\nLonger form explanation:\n- Supporting test package acceptance arbitrary lists of transactions, or indeed any list of transactions that isnâ€™t a two-generation tree, requires we first analyze the package and decide what subpackages or chunks to submit together, and in what order. These decisions can very much affect whether/which transactions get in. The decision should involve the fee and vsize of these transactions, which requires fetching UTXOs and linearizing them.\n- Today, we achieve â€œsplittingâ€ through a trial-and-error process. We continuously attempt to submit package subsets in increasing size order (i.e. starting individually), excluding things once they have been successfully submitted. This was the convenient way to implement it because `AcceptPackage`, and itâ€™s not a terrible way to split two generation-packages.\n- Given our current setup, package transactions are either in the mempool or we havenâ€™t yet decided if theyâ€™re valid; we donâ€™t have an intermediate stage of transactions that have been fully â€œapprovedâ€ but not yet submitted. Once something fails, we just quit out and donâ€™t try the rest of the transactions in the package. Often, they get a â€œmissing inputsâ€ error, which is equivalent to â€œdepends on an invalid transactionâ€.\n- In git terms: We want the ability to `git commit` each subpackage, and then merge the branch with multiple commits into master, or just look at the branch log and use it to produce the RPC results. Today, we canâ€™t `git branch`, we can only stage changes and either discard all of them or commit them directly on master.\n\nâ€œBut if itâ€™s so hard to keep going after a failure, why do it? How much do we care about continuing to validate the package after a subpackage has failed?â€ For a package we receive over p2p, we should keep going instead of wasting bandwidth downloading the same transactions until we get the exact right combination.\n\nâ€œDoes it make things easier or more sensible to not support disconnected transactions / distinct clusters?â€ After deduplication, it is possible that our package contains disconnected transactions, even if we define packages as ancestors or prefixes of some target transaction (i.e. the protocol requires the package to be connected when we receive it over p2p). As an example, imagine itâ€™s us + our parent + a sibling in the same chunk, and the parent is deduplicated. Another reason is that weâ€™d like package test acceptance to be as helpful as possible, and potentially accept lists of raw transactions that arenâ€™t all connected. `DepGraph` handles disconnected transactions just the same, so the linearization part is not more difficult.\n\n### Describe the solution you'd like\n\nHere is a proposed solution, which builds off of the package RBF outline in this [delving post](https://delvingbitcoin.org/t/post-clustermempool-package-rbf-per-chunk-processing/190), simplifying out some of the RBF details and focusing on the changeset staging.\n\n1. **Deduplication**: remove transactions that are already in mempool.\n2. **Topological linearization**: sort it topologically.\n3. **UTXO fetching**, in which we learn the fee and virtual sizes of these transactions. This allows us to build a standalone instance of `DepGraph` or a `TxGraph` of the package, i.e. not connected to mempool transactions. This is probably done through a `PreChecks` call, so we can save and exclude any standardness failures.\n4. **Pre-linearization**: linearize the package transactions. This is without mempool transactions. Decide on what the chunks i.e. subpackages will be.\n5. Use `TxGraph::StartStaging` to create a level 1.\n6. **Splitting** for each chunk `CNK`:\n    1. Use `TxGraph::StartStaging` to create a level 2.\n    2. Validate: Limiting, Conflict-finding, Replacement checks, Verification, up to and including `PolicyScriptChecks`. When doing replacement and diagram checks, always compare the top level with the one just below it, not with the Main level.\n    3. Commit these changes using `TxGraph::CommitStaging` to level 1, not level 0 which represents what is in the mempool.\n    4. The chunk can also be discarded if it is invalid or doesnâ€™t pass its RBF requirements, i.e. `TxGraph::AbortStaging`. The other chunksâ€™ changes in the level 1 are retained.\n7. Full Addition and Eviction should happen at the end, i.e. `ConsensusScriptChecks` and `ChangeSet::Apply` and `TxGraph::CommitStaging` applying the changes from level 1 to level 0.\n\n### Please leave any additional context\n\n**Takeaways and open questions:**\n- I think we could do an extremely limited version now by rerouting test-accepts through `AcceptPackage` and making a few logical tweaks (`AcceptSingleTransaction(test_accept=true)` followed by and `AcceptMultipleTransactions(test_accept=true)` works for 1p1c). But I don't think this is worth it.\n- Is there a simple way to implement the full feature without doing the package validation restructuring described above? I don't really think so.\n- Like a lot of things, implementing will be way easier with the cluster mempool changes merged. However, we need to modify `TxGraph` to support up to 3 levels.\n    - An alternative is to try to build an â€œUndoSubpackageChangesâ€ external to `TxGraph`. I think that will be pretty complex and more levels seems more natural.\n- I think we can delete `MiniMiner::Linearize` since it was written for this purpose, and we can now use cluster_linearize instead.\n- Do we need to make a new RPC given weâ€™re changing the interface? Iâ€™d lean towards no since this is a loosening and basically playing catchup for supporting packages.",
      "state": "open",
      "user": "glozow",
      "created_at": "2025-03-28T14:48:58Z",
      "updated_at": "2025-04-23T10:30:12Z",
      "comments": 6,
      "url": "https://github.com/bitcoin/bitcoin/issues/32160",
      "labels": [
        "Feature",
        "Mempool"
      ],
      "comment_list": [
        {
          "user": "ronnakamoto",
          "body": "The proposed solution looks good. But, like you mentioned we could get it done with a few logical tweaks through the `AcceptPackage` and that would allow us to skip waiting for the cluster mempool merge.\n\nI think we can modify the code to have `testmempoolaccept` and `submitpackage` share the same validation logic path, but just differ in whether they apply changes to the mempool.\n\nThe basic idea would be:\n\n- Have both RPCs use `AcceptPackage` instead of the current split where test uses `AcceptMultipleTransactions` and submit uses `AcceptPackage`\n- Add a parameter to control whether package policies (CPFP, RBF) are applied during validation, separate from the existing `test_accept` flag\n- Use the existing `ChangeSet` mechanism but skip the `Apply()` call when in test mode\n\nBut, the downside of course would be that it won't allow complex topologies directly but maybe that could be done if its done in a more generic way. ",
          "created_at": "2025-04-16T18:46:16Z"
        },
        {
          "user": "glozow",
          "body": "@ronnakamoto IIRC we already the param you're talking about (`m_package_feerates`). I haven't tried implementing it yet, let me know if you have a patch that works? An easy way to test would be to add a testmempoolaccept call in front of all the submitpackage tests and check they give equivalent results.",
          "created_at": "2025-04-16T20:54:22Z"
        },
        {
          "user": "ismaelsadeeq",
          "body": "Given that we want `testmempoolaccept` to ~relax the requirement~ that the transaction should be topologically connected due to the reasons discussed above, should we consider extending `submitpackage` to do the same since as you mentioned in practice, some transactions already in the mempool can cause the submitted package to become topological, the submitted package may not appear connected the outset because it was deduplicated (but it is with some in-mempool transaction).\n\n> This allows us to build a standalone instance of DepGraph or a TxGraph of the package, i.e. not connected to mempool transactions. \n\n> Use TxGraph::StartStaging to create a level 1.\n\nCan you clarify which TxGraph you're creating the staging from? IIUC, you want to linearize a newly created transaction graph containing just the new transactions to produce a series of chunks, then attempt to add each chunk to a staging level of the current mempool TxGraph applying a series of checks.\nIf a chunk fails to be added or succeeds, move on to the next.\nFinally, discard the staging level entirely and report reasons for rejecting each chunk in `testmempoolaccept`, whereas in`submitpackage` you apply the staging level to main level.",
          "created_at": "2025-04-17T12:23:02Z"
        },
        {
          "user": "glozow",
          "body": "> Given that we want testmempoolaccept to relax the requirement that the transaction should be topologically connected\n\nThere is already no requirement of connectedness now\n\n> Given that we want testmempoolaccept to relax the requirement that the transaction should be topologically connected due to the reasons discussed above, should we consider extending submitpackage to do the same since as you mentioned in practice, some transactions already in the mempool can cause the submitted package to become topological\n\nWhile it is true that `AcceptPackage` can process a connected package that turns out to not be connected after deduplication, it's not true that it can handle disconnected packages in general. We can add that fairly easily though I think.\n\n> >  Use TxGraph::StartStaging to create a level 1.\n\n> Can you clarify which TxGraph you're creating the staging from?\n\nAll the staging levels are made on the mempool's `TxGraph`. The package doesn't need proposed changes - we'd only use a `TxGraph` for linearization.\n\n>  If a chunk fails to be added or succeeds, move on to the next.\n\nYes, we could use `TxGraph::BlockBuilder` for this, since it can handle skips for us. That's quite neat...\n\n> Finally, discard the staging level entirely and report reasons for rejecting each chunk in testmempoolaccept, whereas insubmitpackage you apply the staging level to main level.\n\nYep!",
          "created_at": "2025-04-17T13:00:05Z"
        },
        {
          "user": "ismaelsadeeq",
          "body": "> There is already no requirement of connectedness now\n\nBut it is currently enforced on master, this test fail\n<details>\n<summary>diff</summary>\n\n```diff\ndiff --git a/test/functional/rpc_packages.py b/test/functional/rpc_packages.py\nindex a2f9210f94d..807ede343a5 100755\n--- a/test/functional/rpc_packages.py\n+++ b/test/functional/rpc_packages.py\n@@ -88,6 +88,7 @@ class RPCPackagesTest(BitcoinTestFramework):\n         self.test_multiple_parents()\n         self.test_conflicting()\n         self.test_rbf()\n+        self.test_submitpackage_connectedness()\n         self.test_submitpackage()\n         self.test_maxfeerate_submitpackage()\n         self.test_maxburn_submitpackage()\n@@ -371,6 +372,16 @@ class RPCPackagesTest(BitcoinTestFramework):\n         peer.wait_for_broadcast([tx[\"tx\"].getwtxid() for tx in package_txns])\n         self.generate(node, 1)\n \n+    def test_submitpackage_connectedness(self):\n+        txs_chain = self.wallet.create_self_transfer_chain(chain_length=2)\n+        txs_chain2 = self.wallet.create_self_transfer_chain(chain_length=1)\n+        txs_list = [txs_chain[0]['hex'], txs_chain[1]['hex'], txs_chain2[0]['hex']]\n+        self.log.info(\"Test that testmempoolaccept does not enforce connectedness\")\n+        test_accept_res = self.nodes[0].testmempoolaccept(txs_list)\n+        [assert_equal(res['allowed'], True) for res in test_accept_res]\n+        self.log.info(\"Test that Submitpackage does not enforce connectedness\")\n+        self.nodes[0].submitpackage(txs_list)\n+\n     def test_submitpackage(self):\n         node = self.nodes[0]\n```\n</details>",
          "created_at": "2025-04-17T14:52:40Z"
        },
        {
          "user": "glozow",
          "body": "I was referring to testmempoolaccept:\n\n>>   Given that we want testmempoolaccept to relax the requirement that the transaction should be topologically connected\n\n> There is already no requirement of connectedness now\n\nSee test in rpc_packages.py:\n\nhttps://github.com/bitcoin/bitcoin/blob/bfeacc18b36132ba8ac70142133cd6c0e63b6763/test/functional/rpc_packages.py#L95-L99",
          "created_at": "2025-04-17T17:06:10Z"
        }
      ]
    }
  ],
  "summary": {
    "pull_requests": 3,
    "issues": 1
  }
}