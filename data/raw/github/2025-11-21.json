{
  "source": "github",
  "repository": "bitcoin/bitcoin",
  "fetched_at": "2026-01-15T20:33:36.471417+00:00",
  "date": "2025-11-21",
  "pull_requests": [
    {
      "number": 33922,
      "title": "mining: add getMemoryLoad() and track template non-mempool memory footprint",
      "body": "Implements a way to track the memory footprint of all non-mempool transactions that are still being referenced by block templates, see discussion in  #33899. It does not impose a limit.\r\n\r\nIPC clients can query this footprint (total, across all clients) using the `getMemoryLoad()` IPC method. Its client-side usage is demonstrated here:\r\n- https://github.com/stratum-mining/sv2-tp/pull/63\r\n\r\nAdditionally, the functional test in `interface_ipc.py` is expanded to demonstrate how template memory management works: templates are not released until the client drops references to them, or calls the template destroy method, or disconnects. The destroy method is called automatically by clients using [libmultiprocess](https://github.com/bitcoin-core/libmultiprocess), as [sv2-tp](https://github.com/stratum-mining/sv2-tp) does. In the Python tests it also happens when references are destroyed or go out of scope.\r\n\r\nThe PR starts with preparation refactor commits:\r\n\r\n1. Tweaks `interface_ipc.py` so `destroy()` calls happen in an order that's useful to later demonstrate memory management\r\n2. Change `std::unique_ptr<BlockTemplate> block_template` from a `static` defined in `rpc/mining.cpp` to `NodeContext`. This prevents a crash when we switch to a non-trivial destructor later (which uses `m_node`).\r\n\r\nThen the main commits:\r\n\r\n3. Add `template_tx_refs` to `NodeContext` to track how many templates contain any given transaction. This map is updated by the `BlockTemplate` constructor and destructor.\r\n4. Add `GetTemplateMemoryUsage()` which loops over this map and sums up the memory footprint for transactions outside the mempool\r\n5. Expose this information to IPC clients via `getMemoryLoad()` and add test coverage\r\n",
      "state": "open",
      "user": "Sjors",
      "created_at": "2025-11-21T15:34:14Z",
      "updated_at": "2026-01-14T11:18:00Z",
      "comments": 14,
      "url": "https://github.com/bitcoin/bitcoin/pull/33922",
      "labels": [
        "Mining"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33922.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| Concept ACK | [ismaelsadeeq](https://github.com/bitcoin/bitcoin/pull/33922#pullrequestreview-3493499544), [ryanofsky](https://github.com/bitcoin/bitcoin/pull/33922#issuecomment-3608940825) |\n\nIf your review is incorrectly listed, please copy-paste <code>&lt;!--meta-tag:bot-skip--&gt;</code> into the comment that the bot should ignore.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#34184](https://github.com/bitcoin/bitcoin/pull/34184) (mining: add cooldown to createNewBlock() immediately after IBD by Sjors)\n* [#34075](https://github.com/bitcoin/bitcoin/pull/34075) (fees: Introduce Mempool Based Fee Estimation to reduce overestimation by ismaelsadeeq)\n* [#33966](https://github.com/bitcoin/bitcoin/pull/33966) (refactor: disentangle miner startup defaults from runtime options by Sjors)\n* [#33965](https://github.com/bitcoin/bitcoin/pull/33965) (mining: fix -blockreservedweight shadows IPC option by Sjors)\n* [#33936](https://github.com/bitcoin/bitcoin/pull/33936) (mining: pass missing context to createNewBlock() and checkBlock() by Sjors)\n* [#33819](https://github.com/bitcoin/bitcoin/pull/33819) (mining: getCoinbase() returns struct instead of raw tx by Sjors)\n* [#33795](https://github.com/bitcoin/bitcoin/pull/33795) (test: Ignore error message give from python because of PYTHON_GIL by kevkevinpal)\n* [#33421](https://github.com/bitcoin/bitcoin/pull/33421) (node: add  `BlockTemplateCache` by ismaelsadeeq)\n* [#32420](https://github.com/bitcoin/bitcoin/pull/32420) (miner: drop dummy extraNonce in coinbase scriptSig for templates requested via IPC by Sjors)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-11-21T15:34:21Z"
        },
        {
          "user": "Sjors",
          "body": "I haven't benchmarked this yet on mainnet, so I'm not sure if checking every (unique) transaction for mempool presence is unacceptably expensive.\r\n\r\nIf people prefer, I could also add a way for the `getblocktemplate` RPC to opt-out of the memory bookkeeping, since it holds on to one template max and no longer than a minute.",
          "created_at": "2025-11-21T15:36:54Z"
        },
        {
          "user": "DrahtBot",
          "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nðŸš§ At least one of the CI tasks failed.\n<sub>Task `tidy`: https://github.com/bitcoin/bitcoin/actions/runs/19575422916/job/56059300316</sub>\n<sub>LLM reason (âœ¨ experimental): clang-tidy flagged fatal errors (loop variable copied for range-based for causing a warnings-as-errors failure) in interfaces.cpp, breaking the CI run.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
          "created_at": "2025-11-21T16:05:43Z"
        },
        {
          "user": "Sjors",
          "body": "> In my opinion, we should not rely on the IPC client to manage our memory.\r\n\r\n> Whenever the memory budget is exhausted, we should release templates in FIFO order\r\n\r\nIt seems counter intuitive, but from a memory management perspective IPC clients are treated no different than our own code. And if we started FIFO deleting templates that are used by our own code, we'd crash.\r\n\r\nSo I think FIFO deletion should be a last resort (not implemented here).\r\n\r\nThere's another reason why we should give clients an opportunity to gracefully release templates in whatever order they prefer. Maybe there's 100 downstream ASIC's, one of which is very slow at loading templates, so it's only given a new template when the tip changes, not when there's a fee change. In that scenario you have a specific template that the client wants to \"defend\" at all cost.\r\n\r\nIn practice I'm hoping none of this matters and we can pick and recommend defaults that make it unlikely to get close to a memory limit, other than during some weird token launch. \r\n\r\n",
          "created_at": "2025-11-21T16:34:13Z"
        },
        {
          "user": "ismaelsadeeq",
          "body": "> It seems counter intuitive, but from a memory management perspective IPC clients are treated no different than our own code. And if we started FIFO deleting templates that are used by our own code, we'd crash.\r\n\r\nIMHO I think we should separate that, and treat clients differently from our own code, because they are different codebases and separate applications with their own memory.\r\n\r\n> Maybe there are 100 downstream ASICs, one of which is very slow at loading templates, so itâ€™s only given a new template when the tip changes, not when thereâ€™s a fee change. In that scenario you have a specific template that the client wants to â€œdefendâ€ at all costs.\r\n\r\nI see your point but I donâ€™t think thatâ€™s a realistic scenario, and I think we shouldnâ€™t design software to be one-size-fits-all.\r\nIf you want to use only single block templates, then use `createnewblock` and create a new block template and mine that continuously until the chain tip changes or you mine a block.\r\n\r\n`waitNext` returning indicates that we assume your miners are switching from the block they are currently mining to the new one they receive.\r\nDepending on the budget (which I assume is large), many templates would need to be returned before we exhaust it.\r\n\r\nDelegating template eviction responsibility to the client can put us in a situation where they handle it poorly and cause us to OOM (but I guess your argument is that we rather take that chance than being in a situation where we make miners potentially lose on rewards).\r\nHowever I think if there is a clean separation of concerns between the Bitcoin Core node and its clients and clear interface definition and expectations that should not happen, and I believe the mining interface should not differ in that respect.\r\nOtherwise, if we do want a one-size-fits-all solution capable of handling the scenario you described, we should rethink the design entirely and revert to an approach where we do not retain block templates.\r\n",
          "created_at": "2025-11-21T17:38:04Z"
        },
        {
          "user": "Sjors",
          "body": "> Delegating template eviction responsibility to the client can put us in a situation where they handle it poorly and cause us to OOM\r\n\r\nNote that it's _already_ the clients responsibility, that's inherent to how multiprocess works.\r\n\r\nIn the scenario where they handle it poorly, we can use FIFO deletion. All `getMemoryLoad()` does is give clients an opportunity to handle it better. If they're fine with FIFO, then they never have to call this method.\r\n\r\n> treat clients differently from our own code\r\n\r\nWe currently don't track whether any given `CBlockTemplate` is owned by an IPC client or by our internal code. Once we introduce FIFO deletion all call sites will have to check if it's been deleted since, or we need to exempt them from the memory accounting.\r\n\r\n> an approach where we do not retain block templates.\r\n\r\nAfaik that means revalidating the block from scratch, removing one advantage the `submitBlock()` approach has over the `submitblock` RPC (I haven't benchmarked this though).",
          "created_at": "2025-11-24T10:49:07Z"
        },
        {
          "user": "Sjors",
          "body": "I tracked the non-mempool transaction memory footprint for half a day on mainnet, using fairly aggressive template update criteria (minimum fee delta 1 sat and no more than once per second). So far the footprint is minuscule, but of course this depends on the mempool weather:\r\n\r\n<img width=\"3167\" height=\"1141\" alt=\"getmemoryload-scatter\" src=\"https://github.com/user-attachments/assets/30a7b90a-5070-40b2-84d7-55922750c8b8\" />\r\n\r\nThe memory spike after each new block is because `sv2-tp` holds on to templates from previous blocks for 10 seconds. Those ~3 MB spikes may look impressive, but keep in mind that the default mempool is 300 MB.",
          "created_at": "2025-11-24T16:56:34Z"
        },
        {
          "user": "Sjors",
          "body": "I restructured the implementation and commits a bit.\r\n\r\n\r\nThe `TxTemplateMap` now lives on the `NodeContext` rather than `MinerImpl` (interface). This reflects the fact that we want to track the global memory footprint instead of per client. It's a lightweight member `template_tx_refs` which should be easy to fold into a block template manager later.\r\n\r\nIt's also [less code churn](https://github.com/bitcoin/bitcoin/compare/3b77529f74b76ea52c1b7b4ac4edacb0947ff202..24592b737fb80f07276a88fbcf8eaf0ee64c7e49#diff-0ef8ae12c6e9ef2accc78537f42612b3267e8a7c45dc7e9eb998f797e79f2e95) because I don't have to touch the `BlockTemplateImpl` constructor.\r\n\r\nIt also made it easier to move `GetTemplateMemoryUsage` from `interface.cpp` to `miner.cpp`, where it's more reusable.\r\n\r\nThis in turn let me split out a separate commit that introduces the actual `getMemoryLoad()` interface method. So even if we decide against including that method, the rest of the PR should be useful. However I do think it's worth keeping, it's already been a helpful debugging and monitoring tool.\r\n\r\nI added some comments to point out that we don't hold a `mempool.cs` lock during the calculation because we don't need an accurate result (mempool drift) and we don't want to bog down transaction relay with a potentially long lock (1-3ms in my testing so far).\r\n\r\n",
          "created_at": "2025-11-25T15:56:12Z"
        },
        {
          "user": "Sjors",
          "body": "`mining_getblocktemplate_longpoll.py` triggered a `stack-use-after-return`, due to `block_template` being `static` (to allow template reuse between RPC calls). I added a commit d752dccaa56b663001d1bb29ab8b9a50628602a9 to move this longpoll template to the node context. This seems more appropriate anyway since `BlockTemplate` has a `m_node` member, so it shouldn't be able to outlive the node.\r\n\r\nOne caveat is that `gbt_template` has to be cleared before `template_tx_refs`, so I swapped them and added a comment (cde248a6613b6e37f7f7e35c1aabeb75347ffe95 -> 9c667c362a1639b48113a3657882b751f475082c.\r\n\r\n---\r\n\r\nExpanded the PR description.",
          "created_at": "2025-11-25T17:22:05Z"
        },
        {
          "user": "Sjors",
          "body": "Here's a slightly more realistic plot from last night on a well connected node running on an Intel i5-8400:\r\n\r\n<img width=\"3842\" height=\"1369\" alt=\"getmemoryload-scatter\" src=\"https://github.com/user-attachments/assets/f1ae2d88-73fa-4d2c-bd5f-bce5a168eeee\" />\r\n\r\nIt's connected to DMND pool, declaring custom templates and getting them approved, but not actually mining. Due to their rate limiting I set `-sv2interval=20`, so if fees go up, it waits at least 20 seconds before generating a new template. It does not wait when the tip changes.\r\n\r\nThe machine also runs a lightning node and BTCPay so the moment block comes in the system is quite busy.",
          "created_at": "2025-12-03T08:19:54Z"
        },
        {
          "user": "ryanofsky",
          "body": "Concept ACK e8f8f7f677bcde0179526be3ed9a657c44998b93. All the changes here seem good and mostly straightforward. The `getMemoryLoad()` function seems useful by itself and the underlying tracking would seem to provide almost everything needed to limit memory used by block templates.\r\n\r\nI am a little concerned about the idea of proactively deleting block templates in FIFO order on behalf of clients, since it seems like this could increase complexity server-side, and client-side if clients have to deal with templates disappearing without being notified. Just not returning new templates after a certain amount of memory has been used would like a simpler approach.\r\n\r\nre: https://github.com/bitcoin/bitcoin/pull/33922#issue-3652141565\r\n\r\n> Additionally, the functional test in `interface_ipc.py` is expanded to demonstrate how template memory management works: templates are not released until the client disconnects or calls the `destroy()` method.\r\n\r\nWould be good if this said templates are also released if the python references are destroyed or go out of scope. (This stood out because I tested this yesterday in https://github.com/bitcoin/bitcoin/issues/33940#issuecomment-3604081211.)",
          "created_at": "2025-12-03T21:36:31Z"
        },
        {
          "user": "Sjors",
          "body": "> Just not returning new templates after a certain amount of memory has been used would like a simpler approach.\r\n\r\nIt is, but refusing to make new templates doesn't stop the footprint of existing templates from growing. The worst case extra memory footprint for _existing_ templates is the full size of the mempool.\r\n\r\nThis is rather unlikely though, it would only happen if between two blocks the entire mempool was gradually RBF'd in such a way that each transaction was at the top of the mempool briefly, and thus made it into a template.\r\n\r\n> Would be good if this said templates are also released\r\n\r\nAdded a sentence to the PR description.",
          "created_at": "2025-12-04T10:46:46Z"
        },
        {
          "user": "Sjors",
          "body": "Rebased after #34003. Dropped c548d6f0e8ecc0da6e29256c7085d48d10e10216 _test: destroy templates more carefully_. That commit also added coverage for `feeThreshold == MAX_MONEY`, so I moved that into a new commit - not really related to this PR though.",
          "created_at": "2025-12-19T10:25:37Z"
        },
        {
          "user": "Sjors",
          "body": "Rebased after #33819",
          "created_at": "2026-01-14T09:54:19Z"
        }
      ]
    },
    {
      "number": 33921,
      "title": "doc: clarify and cleanup macOS fuzzing notes",
      "body": "* Remove or consolidate macOS notes sprinkled throughout the doc into dedicated section\r\n* Note that support for fuzzing on macOS is not maintained\r\n\r\nCloses #33731",
      "state": "closed",
      "user": "dergoegge",
      "created_at": "2025-11-21T14:29:02Z",
      "updated_at": "2025-11-25T17:40:27Z",
      "comments": 5,
      "url": "https://github.com/bitcoin/bitcoin/pull/33921",
      "labels": [
        "Docs"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33921.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [darosior](https://github.com/bitcoin/bitcoin/pull/33921#pullrequestreview-3500924127), [brunoerg](https://github.com/bitcoin/bitcoin/pull/33921#pullrequestreview-3501159396), [frankomosh](https://github.com/bitcoin/bitcoin/pull/33921#issuecomment-3573874026), [rkrux](https://github.com/bitcoin/bitcoin/pull/33921#pullrequestreview-3504404111), [ismaelsadeeq](https://github.com/bitcoin/bitcoin/pull/33921#pullrequestreview-3505882668) |\n| Concept NACK | [l0rinc](https://github.com/bitcoin/bitcoin/pull/33921#issuecomment-3575153013) |\n| Concept ACK | [janb84](https://github.com/bitcoin/bitcoin/pull/33921#pullrequestreview-3500427026) |\n\nIf your review is incorrectly listed, please copy-paste <code>&lt;!--meta-tag:bot-skip--&gt;</code> into the comment that the bot should ignore.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-11-21T14:29:10Z"
        },
        {
          "user": "dergoegge",
          "body": "* removed the macos steps (https://github.com/bitcoin/bitcoin/pull/33921#discussion_r2556067401)\r\n* added a reference to the macos notes section in the quickstart section",
          "created_at": "2025-11-24T12:16:12Z"
        },
        {
          "user": "frankomosh",
          "body": "ACK c34bc01",
          "created_at": "2025-11-25T05:47:00Z"
        },
        {
          "user": "l0rinc",
          "body": "Concept ACK, I agree that we should clarify usage of fuzzing on a Mac.\r\n\r\nHowever, approach NACK, as described in https://github.com/bitcoin/bitcoin/pull/33921#discussion_r2559577489 (which was marked as resolved for some reason, so reposting here for visibility)",
          "created_at": "2025-11-25T11:21:07Z"
        },
        {
          "user": "l0rinc",
          "body": "@fanquake, what was the urgency to merge here?",
          "created_at": "2025-11-25T17:12:22Z"
        }
      ]
    }
  ],
  "issues": [
    {
      "number": 33923,
      "title": "should concurrent IPC requests directed to the same thread cause a crash?",
      "body": "recently I reported https://github.com/bitcoin/bitcoin/issues/33554, which was fixed by the introduction of `interruptWait` via #33575\n\nthen I noticed crashes for similar reasons (although unrelated to `waitNext`), which I explain in detail here: https://github.com/stratum-mining/sv2-apps/issues/88#issuecomment-3558003166\n\nTLDR: I was trying to do a `getBlock` while a `submitSolution` was happening at the same time, both against the same Bitcoin Core thread\n\nthis made me realize that regardless of whether the call is going to block for a long time (like `waitNext`), I simply cannot leave room for concurrent calls against the same Bitcoin Core thread\n\nwhich feels a bit contradictory to what @ryanofsky suggested here: https://github.com/bitcoin/bitcoin/issues/33554#issuecomment-3382354366\n\n> More broadly, I think I'd try just having a c++ \"waiter\" thread dedicated to running waitNext calls, and a c++ \"worker\" thread to run all other IPC operations besides waitNext. The \"waiter\" thread should be mostly blocked monitoring mempool and network, and the \"worker\" thread should be available to do anything else you might need like fetching and submitting block data.\n\nand it's making me re-evaluate some assumptions I had when I started https://github.com/stratum-mining/sv2-apps/pull/59\n\noverall, I'm getting to a place where I'm having to go great lengths in terms of defensive programming just to avoid crashing Bitcoin Core\n\nI'm still evaluating the trade-offs of potential defensive strategies, namely:\n- having synchronization primitives that avoid overlapping requests against the same Bitcoin Core thread\n- instantiating multiple Bitcoin Core threads, one dedicated for each potentially concurrent request\n\nbut I digress... the main point I wanted to articulate here was: shouldn't Bitcoin Core simply not crash if two requests arrive for the same thread?\n\nideally, a naive client should simply be forced to wait a bit longer if they send concurrent requests against the same Bitcoin Core thread, instead of being forced to avoid doing this at all cost because it could cause havoc on the other side of the IPC connection",
      "state": "open",
      "user": "plebhash",
      "created_at": "2025-11-21T22:05:01Z",
      "updated_at": "2026-01-15T09:08:52Z",
      "comments": 4,
      "url": "https://github.com/bitcoin/bitcoin/issues/33923",
      "labels": [
        "Brainstorming",
        "Bug",
        "interfaces"
      ],
      "comment_list": [
        {
          "user": "ryanofsky",
          "body": "> shouldn't Bitcoin Core simply not crash if two requests arrive for the same thread?\n\nYes this shouldn't crash. Hopefully, if you are using a version of bitcoin after https://github.com/bitcoin-core/libmultiprocess/pull/214 (part of #33518 in master and part of #33519 in 30.x branch) you should just see \"thread busy\" errors instead of crashes, and it is a bug if there are still crashes.\n\n> ideally, a naive client should simply be forced to wait a bit longer if they send concurrent requests against the same Bitcoin Core thread\n\nThis is reasonable and would be pretty easy to implement, but it raises the question of how many requests should be allowed? Should it allow 5, 10, or 100 requests before returning \"thread busy\"? Or an arbitrary amount? Or a configurable amount?\n\nMy thinking has been that if a client needs a request queue, it is probably better for the client implement the queue, than to have the server provide one because the client should know its own needs better. Also, not every client needs a queue. For example, Sjor's SV2 client is multithreaded and only makes blocking requests. It just creates one server thread for each client thread, so every server thread is guaranteed to not be busy when a request comes in.\n\nSince the rust client is single threaded and nonblocking, it needs to create different server threads for those requests to execute in parallel like the c++ client does, or it needs to have a queue so requests created in parallel can be executed serially on a single server thread.\n\nIn practice, I think it make sense for the rust client to just create 2 server threads: a waiting thread to execute `waitNext()` calls, and a worker thread using a queue to execute all other calls.\n\nIt if would help, I could add a `enableRequestQueue()` or similar method to the [`Thread`](https://github.com/bitcoin-core/libmultiprocess/blob/470fc518d4be83649fce9ad71e6d32536ffa1aac/include/mp/proxy.capnp#L50-L54) interface so the rust client can ask for the requests sent to a thread to be queued. \n\nHowever, I think it would probably be straightforward to implement a queue in rust on the client side instead. And I wouldn't want queuing to be enabled on the server by default because it could mask other problems. Like if a request was accidentally sent to the waiting thread rather than the worker thread, it could just sit there forever if queuing was enabled on the waiting thread, instead of returning an error.\n\nThanks for reporting the problem here and I hope this can lead to a good solution.",
          "created_at": "2025-11-21T23:29:12Z"
        },
        {
          "user": "plebhash",
          "body": "I guess the main thing I wanted to report here is a duplicate of https://github.com/bitcoin-core/libmultiprocess/pull/214, so it's good to know these crashes won't happen on `v30.x`!\n\n> how many requests should be allowed? Should it allow 5, 10, or 100 requests before returning \"thread busy\"? Or an arbitrary amount? Or a configurable amount?\n\nit would be up to the client to know what are the reasonable bounds for backpressure so that it can avoid the need to handle errors, so I'd say that a configurable amount with a reasonably large default\n\nbut since you also mentioned:\n\n> And I wouldn't want queuing to be enabled on the server by default because it could mask other problems.\n\nI wouldn't necessarily frame this as an actual feature request, mainly because we're working around this without having to resort to server-side queueing.\n\n---\n\n> Since the rust client is single threaded and nonblocking, it needs to create different server threads for those requests to execute in parallel like the c++ client does, or it needs to have a queue so requests created in parallel can be executed serially on a single server thread.\n\ncurrently we're going with the first approach, so now we create 5 server threads, one dedicated for each potentially concurrent call:\n- `submitSolution`\n- `getHeader`\n- `getCoinbaseTx`\n- `getCoinbaseMerklePath`\n- `waitNext`\n\nplus some ad-hoc threads that are created ephemerally whenever we need to do a `getBlock` (either to reply to a `RequestTransactionData` or because we want to dump a valid solution to disk)\n\nto be honest, we could have gotten away with only 2 by forcing `getHeader`, `getCoinbaseTx`, `getCoinbaseMerklePath` and `waitNext` to be done sequentially under the same server thread\n\nbut we're trying to squeeze out every possible micro/nano/pico second out of the way with concurrent execution of `getHeader`, `getCoinbaseTx`, `getCoinbaseMerklePath` so we can craft a `NewTemplate` message ASAP (the ones for mempool updates are actually rate-limited, so we're not really in a race... but for chain tip updates we do want this to happen as fast as possible)\n\nwith this approach, queuing requests on the server side is not needed at all.\n\nbut it made me wonder about something (which I was eventually going to be forced to consider anyways):\n\nwe eventually want to adapt this code so that it can become a sidecar that's attached to Bitcoin Core, which then acts as a Sv2 Template Provider, listening on a TCP port and catering for as many clients as possible... so now, for every client that connects to it, we create 5 new threads on Bitcoin Core\n\nwhether we create 1, 2 or 5 threads for each client is not too relevant, but my main question is whether there are there protection mechanisms in place in case we try to create too many threads at once? if so, what happens once Bitcoin Core is no longer willing to create new threads?",
          "created_at": "2025-11-22T16:18:56Z"
        },
        {
          "user": "Sjors",
          "body": "> to be honest, we could have gotten away with only 2 by forcing `getHeader`, `getCoinbaseTx`, `getCoinbaseMerklePath` and waitNext to be done sequentially under the same server thread\n\nI think you should bench this before deciding if it needs optimising and also check whether it's _actually_ faster and not e.g. slowing the node responses down with overhead.\n\nIf `getHeader`, `getCoinbase(Tx)` and `getCoinbaseMerklePath` really need to be called in parallel, then I think it would be better if the `BlockTemplate` interface is somehow pre-populated with those values - avoiding these round trips entirely.",
          "created_at": "2025-11-24T10:11:41Z"
        },
        {
          "user": "ryanofsky",
          "body": "re: https://github.com/bitcoin/bitcoin/issues/33923#issuecomment-3566852691\n\n> my main question is whether there are there protection mechanisms in place in case we try to create too many threads at once?\n\nThere aren't any currently, and making a lot of threads is probably the easiest way an IPC client could DoS the node.\n\nIt wouldn't be hard to create a limit though, if there is a use-case.\n\nI do think creating 5 threads for each client that needs to receive templates sounds like overkill, and would suggest trying to implement an approach with less overhead. Ideally the SV2 template provider be able to take a single bitcoin core template and broadcast it out to many clients, instead of each client needing unique templates.\n\nI also agree with sjors it doesn't seem ideal to be calling getters like getHeader, getCoinbaseTx, and getCoinbaseMerklePath in parallel. If we can change the interface to provide a single method that will return all the information needed so you don't need to make multiple calls, that would be better.\n\nre: https://github.com/bitcoin/bitcoin/issues/33923#issuecomment-3564979973\n\n> My thinking has been that if a client needs a request queue, it is probably better for the client implement the queue, than to have the server provide one because the client should know its own needs better.\n\nReplying to myself, I now am rethinking my previous thinking. One case where a server queue is clearly better than a client queue is when a client wants to request multiple pieces of data and have the data sent back sequentially. Without a server queue, the client needs to wait for each piece of data to be received before requesting the next piece of data, which is not efficient. With a server queue, data can be streamed back much more nicely. So now I am thinking about ways to implement a queue. And I think it might be possible to do without creating an separate data structure or explicit queue limit by simply attaching data to capnproto promises. This would get rid of the \"thread busy\" error entirely.\n",
          "created_at": "2025-12-03T16:31:04Z"
        }
      ]
    }
  ],
  "summary": {
    "pull_requests": 2,
    "issues": 1
  }
}