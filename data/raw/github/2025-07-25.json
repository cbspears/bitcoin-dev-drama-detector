{
  "source": "github",
  "repository": "bitcoin/bitcoin",
  "fetched_at": "2026-01-15T20:01:16.207425+00:00",
  "date": "2025-07-25",
  "pull_requests": [
    {
      "number": 33066,
      "title": "p2p: never check tx rejections by txid",
      "body": "This PR removes the rejection cache filtering part of all txid-based tx requests. In practice, this seems to only be used for orphan resolution because everybody supports wtxidrelay. And so in essence, this PR removes the logic that stops us from attempting orphan resolution when parents are found in the rejection filter.\r\n\r\nBackground:\r\nWe have 2 bloom filters for remembering transactions that we've rejected so we don't redownload them, `RecentRejectsFilter` and `RecentRejectsReconsiderableFilter`. This lets us save a little bit of bandwidth on rejected transactions, particularly if we have policy differences. It's not designed to stop attackers from wasting our download bandwidth, as they can create as many policy-invalid transactions with different witnesses as they want. We generally only put wtxids and not txids in them (see #18044), except for these cases:\r\n(A) When we specifically know that the rejection reason is not due to the witness (however, this is only done for `!AreInputsStandard`, even though there are other cases we could apply)\r\n(B) When the transaction has no witness, so its txid == wtxid\r\n(C) (With #32379) When the transaction's witness has been stripped, so txid == wtxid\r\nWe check the filters to decide whether to send a getdata for an inv, whether we should validate a tx we just downloaded, and whether we should keep an orphan: we look the missing parents up by (prevout) txid and throw the orphan away if its parents were already rejected. That means there are very few cases where we save bandwidth by finding a txid in the filter.\r\n\r\nRationale: mainly that the additional complexity is not worth the bandwidth savings. TLDR: this case does not seem to ever hit in practice. Even if that is circumstantial, the number of transactions this filter could apply to is extremely small.\r\n\r\nI collected some stats over a couple of weeks, setting mempoolexpiry to 1 hour to try to artificially increase orphan rates (though I don't know whether the effect is significant):\r\n- I'm seeing 100% of peers support wtxidrelay. Bitcoin Core has been doing this since ~5 years ago. I'm sure there are some nodes that don't do it, but it'll probably be rare that we are surrounded by txidrelay peers and that we have a policy difference causing us to reject the transaction that they all send us.\r\n- Orphan parent fetching was 3.64% of my transaction requests.\r\n- 93.77% of all transactions I receive have witnesses (includes accepted and rejected ones). 96.20% of orphan parents I fetched had witnesses.\r\n- I found no cases of already-rejected parent txids in the past week. This could be because all my peers have the same policy as me (which might not always be true), but the number of nonsegwit orphan parents in general is just so tiny - a few dozen requests per day.",
      "state": "closed",
      "user": "glozow",
      "created_at": "2025-07-25T20:47:00Z",
      "updated_at": "2025-09-02T14:08:34Z",
      "comments": 20,
      "url": "https://github.com/bitcoin/bitcoin/pull/33066",
      "labels": [
        "P2P",
        "Needs rebase"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33066.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| Concept ACK | [darosior](https://github.com/bitcoin/bitcoin/pull/33066#issuecomment-3137446026), [sipa](https://github.com/bitcoin/bitcoin/pull/33066#issuecomment-3161635101) |\n| User requested bot ignore | [cedwies](https://github.com/bitcoin/bitcoin/pull/33066#pullrequestreview-3056948992) |\n\nIf your review is incorrectly listed, please react with üëé to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#33116](https://github.com/bitcoin/bitcoin/pull/33116) (refactor: Convert uint256 to Txid by marcofleon)\n* [#29060](https://github.com/bitcoin/bitcoin/pull/29060) (Policy: Report reason inputs are non standard by ismaelsadeeq)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T20:47:05Z"
        },
        {
          "user": "glozow",
          "body": "cc @darosior",
          "created_at": "2025-07-25T20:47:26Z"
        },
        {
          "user": "darosior",
          "body": "Concept ACK",
          "created_at": "2025-07-25T21:27:47Z"
        },
        {
          "user": "glozow",
          "body": ">  MempoolRejectedTx still inserts a tx-id into RecentRejectsFilter for TX_INPUTS_NOT_STANDARD, but After this patch AlreadyHaveTx no longer consults the filter by tx-id. Is that entry now redundant, or do other call-sites still depend on it?\r\n\r\nGood question. I think we can remove that actually, since we are no longer interested in whether a transaction's txid is in the cache ü§î ",
          "created_at": "2025-07-28T19:31:16Z"
        },
        {
          "user": "ajtowns",
          "body": "> TLDR, this PR removes the rejection cache filtering part of all txid-based tx requests.\r\n\r\nThere's three cases here I think:\r\n\r\n * orphan resolution from wtxidrelay peers (WTXIDRELAY)\r\n * tx relay from segwit-supporting, non-wtxidrelay peers (NODE_WITNESS, no WTXIDRELAY, 0.13.1 to 0.20.x, Jan 2021)\r\n * tx relay from non-segwit peers\r\n\r\nThe last case case is trivial -- non-segwit peers can be treated as doing wtxid relay for caching because all the txs they relay will have the same value for txid and wtxid.\r\n\r\nFor orphan resolution, caching bad txids seems mostly undesirable: we can cache INPUTS_NON_STANDARD since that will fail repeatedly, but can't cache anything much else, as different witness could make an acceptable transaction. I think it should be possible to detect INPUTS_NON_STANDARD versus WITNESS_STRIPPED or other failures, so I think that behaviour could actually be retained? Something like:\r\n\r\n```c++\r\nstatic bool RequiresWitnessData(TxoutType txo)\r\n{\r\n    switch(txo) {\r\n    case WITNESS_V0_SCRIPTHASH:\r\n    case WITNESS_V0_KEYHASH:\r\n    case WITNESS_V1_TAPROOT:\r\n        return true;\r\n    default: // should list all cases for completeness and compiler checks\r\n         break;\r\n    }\r\n    return false;\r\n}\r\n\r\nbool AreInputsStandard(const CTransaction& tx, const CCoinsViewCache& mapInputs, bool& is_stripped)\r\n{\r\n    is_stripped = false;\r\n    ...\r\n    const bool has_witness_data = tx.HasWitness();\r\n    for (unsigned int i = 0; i < tx.vin.size(); i++) {\r\n        const CTxOut& prev = mapInputs.AccessCoin(tx.vin[i].prevout).out;\r\n\r\n        std::vector<std::vector<unsigned char> > vSolutions;\r\n        TxoutType whichType = Solver(prev.scriptPubKey, vSolutions);\r\n        if (!has_witness_data && !is_stripped && RequiresWitnessData(whichType)) {\r\n            is_stripped = true;\r\n        }\r\n        if (whichType == TxoutType::NONSTANDARD || whichType == TxoutType::WITNESS_UNKNOWN) {\r\n        ...\r\n    }\r\n    if (is_stripped) return false;\r\n    return true;\r\n}\r\n\r\n    bool is_stripped;\r\n    if (m_pool.m_opts.require_standard && !AreInputsStandard(tx, m_view, is_strippped)) {\r\n        if (is_stripped) {\r\n            return state.Invalid(TxValidationResult::TX_WITNESS_STRIPPED, \"bad-txns-missing-witness\");\r\n        } else { \r\n            return state.Invalid(TxValidationResult::TX_INPUTS_NOT_STANDARD, \"bad-txns-nonstandard-inputs\");\r\n         }\r\n    }\r\n```\r\n\r\n(just passing `state` through probably would be better than the bool ref)\r\n\r\n`WITNESS_STRIPPED` would indicate you should retry requesting by txid for orphan resolution; `INPUTS_NOT_STANDARD` means there's no point retrying. Other errors also indicate you should retry -- a tx with the same txid but different witness data may pass validation.\r\n\r\nIn that case, I believe adding the wtxid to the reject filter, and `INPUTS_NOT_STANDARD` txids to the reject filter, and checking the reject filter when requestion both by wtxid and txid would give good/correct behaviour for wtxidrelay and non-segwit peers, and I think best-possible behavour for non-wtxidrelay segwit peers?",
          "created_at": "2025-07-30T08:03:18Z"
        },
        {
          "user": "darosior",
          "body": "Yes, we could do that. I suppose the minimal way to do so today on master would be to simply check whether we are spending any Segwit input while the transaction has no witness after `CheckInputScripts` failed:\r\n<details>\r\n<summary>Expand patch</summary>\r\n\r\n```diff\r\ndiff --git a/src/validation.cpp b/src/validation.cpp\r\nindex 09e04ff0ddb..8f86b630ef5 100644\r\n--- a/src/validation.cpp\r\n+++ b/src/validation.cpp\r\n@@ -1254,13 +1254,17 @@ bool MemPoolAccept::PolicyScriptChecks(const ATMPArgs& args, Workspace& ws)\r\n     // Check input scripts and signatures.\r\n     // This is done last to help prevent CPU exhaustion denial-of-service attacks.\r\n     if (!CheckInputScripts(tx, state, m_view, scriptVerifyFlags, true, false, ws.m_precomputed_txdata, GetValidationCache())) {\r\n-        // SCRIPT_VERIFY_CLEANSTACK requires SCRIPT_VERIFY_WITNESS, so we\r\n-        // need to turn both off, and compare against just turning off CLEANSTACK\r\n-        // to see if the failure is specifically due to witness validation.\r\n-        TxValidationState state_dummy; // Want reported failures to be from first CheckInputScripts\r\n-        if (!tx.HasWitness() && CheckInputScripts(tx, state_dummy, m_view, scriptVerifyFlags & ~(SCRIPT_VERIFY_WITNESS | SCRIPT_VERIFY_CLEANSTACK), true, false, ws.m_precomputed_txdata, GetValidationCache()) &&\r\n-                !CheckInputScripts(tx, state_dummy, m_view, scriptVerifyFlags & ~SCRIPT_VERIFY_CLEANSTACK, true, false, ws.m_precomputed_txdata, GetValidationCache())) {\r\n-            // Only the witness is missing, so the transaction itself may be fine.\r\n+        // CheckInputScripts filled the spent outputs. Detect whether this transaction's witness was stripped by checking\r\n+        // whether this transaction spends a Segwit output but does not have a witness.\r\n+        Assert(ws.m_precomputed_txdata.m_spent_outputs_ready);\r\n+        const auto& spent_txos{ws.m_precomputed_txdata.m_spent_outputs};\r\n+        Assert(spent_txos.size() == tx.vin.size());\r\n+        int ver;\r\n+        std::vector<uint8_t> prog;\r\n+        const bool spends_segwit{std::any_of(spent_txos.begin(), spent_txos.end(), [&ver, &prog](const CTxOut& txo) {\r\n+            return txo.scriptPubKey.IsWitnessProgram(ver, prog);\r\n+        })};\r\n+        if (!tx.HasWitness() && spends_segwit) {\r\n             state.Invalid(TxValidationResult::TX_WITNESS_STRIPPED,\r\n                     state.GetRejectReason(), state.GetDebugMessage());\r\n         }\r\n```\r\n\r\n</details>\r\n\r\nHowever it seemed cleaner to me to get rid of the WITNESS_STRIPPED edge case detection in the first place, which was always meant to go?",
          "created_at": "2025-07-30T18:38:33Z"
        },
        {
          "user": "glozow",
          "body": "> However it seemed cleaner to me to get rid of the WITNESS_STRIPPED edge case detection in the first place, which was always meant to go?\r\n\r\nI didn't realize it was always meant to go - how do you know that?\r\n\r\nFwiw, I do think that being able to detect `WITNESS_STRIPPED` without triple validation is the main thing we want, so would prioritize that kind of solution. At the same time, my main point in the OP is that being able to cache `INPUTS_NOT_STANDARD` isn't very helpful to us in practice, so I would still be weakly in favor of this PR.",
          "created_at": "2025-07-30T18:43:49Z"
        },
        {
          "user": "darosior",
          "body": "> I didn't realize it was always meant to go - how do you know that?\r\n\r\nIt was introduced in https://github.com/bitcoin/bitcoin/pull/18044 as a hack until the network upgrades to wtxid relay with an explicit mention it can be (according to author, [should be](https://github.com/bitcoin/bitcoin/pull/18044#discussion_r388445400)) removed afterward:\r\nhttps://github.com/bitcoin/bitcoin/blob/8a94cf8efebc3177effcfc1160560735b8caf34b/src/node/txdownloadman_impl.cpp#L452-L454\r\n\r\nOf course that it was *meant to* go then does not implies it *needs to* go now. But i think this still holds. It is a weird special case that is not necessary post wtxid relay (and post this PR).",
          "created_at": "2025-07-30T18:55:06Z"
        },
        {
          "user": "darosior",
          "body": "I opened https://github.com/bitcoin/bitcoin/pull/33105, which ended up implementing a variant of @ajtowns' suggestion, because as pointed out the resource consumption gains can be achieved independently of this work (which i still think is desirable) as a much smaller patch which i think would be nice to get in before the feature freeze.",
          "created_at": "2025-07-30T20:19:45Z"
        },
        {
          "user": "ajtowns",
          "body": "> However it seemed cleaner to me to get rid of the WITNESS_STRIPPED edge case detection in the first place, which was always meant to go?\r\n\r\nI don't think it makes sense to get rid of WITNESS_STRIPPED while we still care about resolving orphans via their missing parents' txids. If/when we have protocol support for receiver-initiated package relay by wtxid, then I think it could make sense to treat every request as being by wtxid -- so a witness-stripped response from a non-wtxid-relay peer would mean not requesting that tx from any other non-wtxid-relay peer, but wouldn't prevent requesting the same tx from wtxid-relay peers.",
          "created_at": "2025-07-31T01:07:29Z"
        },
        {
          "user": "sipa",
          "body": "Do we have numbers on how often the rejection filter catches things by txid? I suspect that in practice that will be just due to fetches of orphan parents which are (policy) invalid, due to non-witness reasons?",
          "created_at": "2025-08-04T18:31:30Z"
        },
        {
          "user": "glozow",
          "body": "> Do we have numbers on how often the rejection filter catches things by txid? \r\n\r\nI didn't see any in a 2-week period üòÖ ",
          "created_at": "2025-08-04T18:34:38Z"
        },
        {
          "user": "darosior",
          "body": "I still think this PR is preferable to #33105. The latter will inevitably introduce more false-positive witness stripped errors, whereby we won't add some transactions with consensus/standardness errors to the reject filter. Since we already don't add all transactions with consensus/standardness errors to the reject filter, if we also don't care about these additional false positives, we might as well just to the cleaner thing and get rid of this filter entirely as is done here.",
          "created_at": "2025-08-05T15:08:41Z"
        },
        {
          "user": "ajtowns",
          "body": "> I still think this PR is preferable to #33105. The latter will inevitably introduce more false-positive witness stripped errors,\r\n\r\nI don't think false-positive witness stripped errors are harmful, apart from the CPU they required to be detected in the first place.\r\n\r\nOnly \"misbehaving\" peers will send us witness stripped txs in the first place, so the only benefit caching an error does (which is what we'd do if we replaced the \"false\" witness stripped result with something else) is only to prevent us from requesting the invalid tx from some other peer, but the only way any other peer would give us the tx in that case is if they were advertising and relaying invalid txs themselves. If we do have such peers, requesting the tx again by txid doesn't cost much if we get a witness-stripped version and detect that cheaply/quickly; and if we don't get a witness-stripped version we at least make some progress by being able to cache rejection by wtxid. If we have many peers relaying invalid txs to us, that will still be costly, but spending a lot of cpu/bandwidth doing validation is exactly what we'd expected in that scenario anyway.\r\n\r\nWhen we have almost entirely honest peers, we'll never see witness stripped errors in the first place; and aside from that we would expect our rejection caches to only see reconsiderable rejections (due to double spends and fee rate differences), and policy rejections (when we have different policy configuration to our peers). I think the only policy rejection you'd hit here that has any significant use in the network is if you were running with p2a validation disabled. So I don't think stats will be informative here -- this code aims to lower the impact of buggy clients, so you need buggy peers for it to have any impact.",
          "created_at": "2025-08-06T10:41:51Z"
        },
        {
          "user": "sipa",
          "body": "Concept ACK.\r\n\r\nFirst of all, I'm convinced by the rationale for #33050 and #33105, and if we do (at least) the latter, then this PR isn't necessary anymore to get rid of the triple-validation costs, which would make it low-urgency. I think it's still a nice cleanup, as I don't think the code does much right now (see below).\r\n\r\nAside, I don't think we need to worry about the impact it may have on pre-segwit or pre-wtxidrelay peers; given how widespread wtxidrelay peers are, I think we can reasonably add/increase a fetching delay by a few seconds from non-wtxidrelay peers to minimize their impact, and/or consider preferentially peering with wtxidrelay peers (they have no service flag, but we could kick+cycle random outbound non-wtxidrelay peers if we have under some threshold).\r\n\r\n@ajtowns It's fair to say we shouldn't judge the quality of protection against buggy clients based on statistics, because all they might tell us that there currently are no relevant buggy clients. But @glozow is not seeing any hits on the txid rejection cache at all - not just no witness-stripped cases. And the txid rejection cache is there (I think) primarily to protect against bandwidth waste due to repeated downloading of rejected transactions from a (multitude of) policy-diverging peers, not buggy peers. The lack of such hits on the txid filter may of course also mean there are currently no such peers, but I think there are additional reasons why it doesn't do much.\r\n\r\nIf we exclude pre-wtxidrelay peers, the use of the txid rejection filter is limited to cases where all of these hold:\r\n* For consensus-valid transactions, as honest peers never create consensus-invalid transactions (because it is protection against redownloading from honest peers, not attackers, which can waste our bandwidth in much easier ways).\r\n* For policy-invalid transactions, where we have many peers which consider it policy-valid regardless.\r\n* For parents of orphans, because that's the only context in which we just know a transaction's txid.\r\n* For **a specific, small subset** of policy-invalidity reasons that do not involve the witness (namely: nonstandard input types, because that's currently the only thing where we assign failure to the txid, not the wtxid) or are non-segwit.\r\n\r\nFor it to matter, we'd need to be in a regime where there are lots of policy-diverging peers with a more liberal relay policy (... may happen), with a deployed-at-scale use case that causes such transactions (... might happen), that involve dependent transactions (... less likely), and where the invalidity is due to non-standard script input types or are non-segwit (... pretty unlikely).\r\n\r\nAs an alternative, it is possible to expand the number of validation failures that get attributed to txids, as there are more than just non-standard script input types in theory. Others include base size > 100k, non-standard output types, min feerate not met (when counting just base size), too many sigops, and probably a few more. I think those are still unlikely candidates of being things people build at scale, in dependent transactions, but if we think that's possible, I think expanding those to be txid-rejectable is a reasonable alternative to this PR.\r\n\r\nAbsent that alternative, I feel the hypothetical scenario where this matters is just too obscure to have a whole piece of net_processing state dedicated too. It uses memory too; without inserting txids in the rejection filter, we could shrink the filters, or improve their reliability.",
          "created_at": "2025-08-06T21:11:50Z"
        },
        {
          "user": "glozow",
          "body": "I've removed #32379 and mention of witness-stripping from the PR description; I think we can regard this as irrelevant for removing the triple validation (though it doesn't hurt).\r\n\r\nThe primary motivation now is to clean up logic that doesn't really get used.\r\n\r\n> Others include base size > 100k, non-standard output types, min feerate not met (when counting just base size), too many sigops, and probably a few more.\r\n\r\nAlso: large scriptSig, nonstandard output type, dust, OP_RETURN size and count (assuming this node's policy is more restrictive than its peers'). I would guess that if we added these, they would similarly be very rare and not really worth the added complexity.\r\n\r\nWe can wait until we're using something like BIP331 for orphan resolution (when txid requests are even rarer), but I think there's sufficient evidence this is already vestigal today.",
          "created_at": "2025-08-07T12:48:55Z"
        },
        {
          "user": "ajtowns",
          "body": "sipa wrote:\r\n\r\n> * For **a specific, small subset** of policy-invalidity reasons that do not involve the witness (namely: nonstandard input types, because that's currently the only thing where we assign failure to the txid, not the wtxid) or are non-segwit.\r\n\r\nI believe you'd see that for new segwit spend types when you're not running an upgraded node (eg, taproot, p2a, perhaps p2qrh), which might help reduce your wasted bandwidth if you're running behind network consensus/policy changes as adoption increases.\r\n\r\n> As an alternative, it is possible to expand the number of validation failures that get attributed to txids, as there are more than just non-standard script input types in theory. Others include base size > 100k, non-standard output types, min feerate not met (when counting just base size), too many sigops, and probably a few more. I think those are still unlikely candidates of being things people build at scale, in dependent transactions, but if we think that's possible, I think expanding those to be txid-rejectable is a reasonable alternative to this PR.\r\n\r\nBumping tx version (TRUC), creating dust outputs (ephemeral dust), and increased OP_RETURN output count/size are all pretty recent examples of where we've loosened standardness rules in ways that could be assigned to the txid and that presumably we're hoping might get built on at scale. I don't see why we'd necessary stop doing that any time soon.\r\n\r\nOf course, all those things will only show up in normal usage if your mempool rules are stricter than what's being commonly seen on the network, and stricter than your peers, which is a situation we generally try to avoid. So even then, I don't think you'll see much effect in normal usage -- it's only defensive against future changes to policy that you don't adopt in sync with your peers, or if there's something of a schism in the p2p network and we care about the people adopting more restrictive policies.\r\n\r\nIt might be interesting to try getting similar stats on a Knots node with its more restrictive mempool policies -- potentially both just seeing how many times rejected txs get redundantly downloaded due to orphan resolution attempts, and tweaking it so that (some of) the errors that can be assigned to the txid are (which could catch the lower datacarrier limits, though not the inscription ones)... Alternatively maybe you could get similar stats from a post-wtxidrelay but pre-taproot node who might see child spends of taproot parents.\r\n\r\nThat doesn't help for non-standardness issues we can't assign to the txid -- so script upgrades and forbidding inscriptions and they like aren't helped by this mechanism, and can't be helped without some form of explicit package relay afaics.\r\n\r\nThe bad case there is if we get a child from many peers whose parent we've already probably rejected (by wtxid). If we can also reject the txid, then we save ourselves some bandwidth and perhaps validation costs; if we can't reject the txid, we likely have to redundantly request it from each peer in case many of our peers are dishonest, but one is honest and has a version of the tx that we'll accept. So rather than downloading it once, we're downloading it up to 8 or 120 times if all our peers have looser standardness policies than we do? We already check the wtxid against RecentRejects via AlreadyHaveTx via ReceivedTx, so we won't revalidate afaics.\r\n\r\nAs far as the adversarial case goes -- the worst case would be that in an environment where your rules are stricter than many of your peers, an adversary could force you to redownload/revalidate a large tx from many peers with you rejecting it each time. If your peers announced the tx by wtxid, you'd only do that once, and things would be fine. To trigger it happening by txid, they would need to use orphan resolution and actually have each of your peers announce the child (in order for you to believe its worth getting the parent from them). But that's just normal behaviour -- you're sending a real child tx through the network?\r\n\r\nSo I think the only potential benefit here is saving ourselves from redownloading a transaction ~10x or ~100x times more than we should, and agree that this is only in the cases where we're enforcing \"special\" standardness rules, and those rules can be assigned independent of the witness data, and only in cases where we have a child of the non-standard tx.\r\n\r\n> Absent that alternative, I feel the hypothetical scenario where this matters is just too obscure to have a whole piece of net_processing state dedicated too.\r\n\r\nI don't really think this change is much of a win -- the original motivation of avoiding the triple-script-check stuff is, but that can be avoided just by rejecting witness-stripped txs asap, independent of this change.\r\n\r\n>  It uses memory too; without inserting txids in the rejection filter, we could shrink the filters, or improve their reliability.\r\n\r\nI don't think that's quite true in practice? The logic in txdownloadman_impl.h for the the filter size is based on 1000 txs per second for 2 minutes creating 120000 entries; but that should presumably be doubled if we're assuming an attacker might add minimal witness data to invalid non-standard input txs as well in order to overflow the filter as quickly as possible in order to trick us into re-requesting txs from other peers? If we're approximately never seeing spends of non-standard inputs, then we also already have the reliability benefits of never adding them. Either way, 1.3MB, 2.6MB or 650kB of filters doesn't seem like a big deal to me. If we really cared about minimising the filter size we could probably rate-limit peers to a target of 10 or 20 rejected txs per second or similar.\r\n\r\nglozow wrote:\r\n\r\n> We can wait until we're using something like BIP331 for orphan resolution (when txid requests are even rarer), but I think there's sufficient evidence this is already vestigal today.\r\n\r\nI think the main reason it seems vestigial is dependent on running a node with policy rules at least as loose as (almost) all your peers, and assuming that everyone else who isn't doing the same now, will do so in short order.",
          "created_at": "2025-08-08T17:55:44Z"
        },
        {
          "user": "ajtowns",
          "body": "> and/or consider preferentially peering with wtxidrelay peers\r\n\r\nIt would probably be good to be able to preferentially peer with package-relay peers when they exist, so even if peering with wtxidrelay peers is easy now, having the code in a way that's reusable for package-relay peers in future might be worthwhile.",
          "created_at": "2025-08-08T18:01:58Z"
        },
        {
          "user": "DrahtBot",
          "body": "<!--cf906140f33d8803c4a75a2196329ecb-->\nüêô This pull request conflicts with the target branch and [needs rebase](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#rebasing-changes).\n",
          "created_at": "2025-08-13T20:30:41Z"
        },
        {
          "user": "glozow",
          "body": "Closing for now. We can revisit this cleanup later.",
          "created_at": "2025-09-02T14:08:34Z"
        }
      ]
    },
    {
      "number": 33065,
      "title": "rpc, wallet: replace remaining hardcoded output types with `FormatAllOutputTypes`",
      "body": "This PR takes use of the `FormatAllOutputTypes` helper (introduced in PR #32432, commit 8cc9845b8ddf4f93a02c622e7df8d1095dc1a640) to get rid of the remaining hardcoded output types in wallet RPC and command line arguments documentation [1]. Note that it can't be used in the [`createmultisig` RPC](https://github.com/bitcoin/bitcoin/blob/fc162299f0cc5b61bbb55736fe85e27b705f78cc/src/rpc/output_script.cpp#L100), as this one is only for pre-taproot output types and hence doesn't contain \"bech32m\" in the list.\r\n\r\n[1] instances were found via `$ git grep legacy.*p2sh-segwit ./src/rpc/ ./src/wallet/`",
      "state": "closed",
      "user": "theStack",
      "created_at": "2025-07-25T16:56:47Z",
      "updated_at": "2025-07-28T12:53:14Z",
      "comments": 5,
      "url": "https://github.com/bitcoin/bitcoin/pull/33065",
      "labels": [],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33065.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [pablomartin4btc](https://github.com/bitcoin/bitcoin/pull/33065#pullrequestreview-3056964820), [nervana21](https://github.com/bitcoin/bitcoin/pull/33065#issuecomment-3122169008), [maflcko](https://github.com/bitcoin/bitcoin/pull/33065#issuecomment-3126557564), [rkrux](https://github.com/bitcoin/bitcoin/pull/33065#pullrequestreview-3061836848) |\n\nIf your review is incorrectly listed, please react with üëé to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#32966](https://github.com/bitcoin/bitcoin/pull/32966) (Silent Payments: Receiving by Eunovo)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T16:56:51Z"
        },
        {
          "user": "theStack",
          "body": "> What about these 2 (`-addresstype` and `-changetype`) in `src/wallet/init.cpp`?\r\n\r\nThanks, missed those due to `grep`ping too tightly, added another commit.\r\n",
          "created_at": "2025-07-25T22:29:40Z"
        },
        {
          "user": "nervana21",
          "body": "tACK [251d020](https://github.com/bitcoin/bitcoin/commit/251d02084688c67523e9ec92ec79ee657454ab93)\r\n\r\nI ran all affected help commands and confirmed that all updated outputs are as expected",
          "created_at": "2025-07-26T17:21:21Z"
        },
        {
          "user": "maflcko",
          "body": "review ACK 251d02084688c67523e9ec92ec79ee657454ab93 üå®\r\n\r\n<details><summary>Show signature</summary>\r\n\r\nSignature:\r\n\r\n```\r\nuntrusted comment: signature from minisign secret key on empty file; verify via: minisign -Vm \"${path_to_any_empty_file}\" -P RWTRmVTMeKV5noAMqVlsMugDDCyyTSbA3Re5AkUrhvLVln0tSaFWglOw -x \"${path_to_this_whole_four_line_signature_blob}\"\r\nRUTRmVTMeKV5npGrKx1nqXCw5zeVHdtdYURB/KlyA/LMFgpNCs+SkW9a8N95d+U4AP1RJMi+krxU1A3Yux4bpwZNLvVBKy0wLgM=\r\ntrusted comment: review ACK 251d02084688c67523e9ec92ec79ee657454ab93 üå®\r\nne4xj6IYoPFwPiqSeFarPo3YE5F3okDnDRwUE/1k0dqtdcV76FVysxYZ/2G0wPWvIrMWHvvmfi4iF5GvheCxCQ==\r\n```\r\n\r\n</details>\r\n",
          "created_at": "2025-07-28T10:21:18Z"
        },
        {
          "user": "theStack",
          "body": "> Nit: can update the grep command in the PR description.\r\n\r\nDone.",
          "created_at": "2025-07-28T12:43:06Z"
        }
      ]
    },
    {
      "number": 33064,
      "title": "test: fix RPC coverage check",
      "body": "This is #27593 cleaned up / rebased, now that the legacy wallet has been dropped.\r\n\r\nCloses #27593.",
      "state": "closed",
      "user": "fanquake",
      "created_at": "2025-07-25T14:02:51Z",
      "updated_at": "2025-07-28T09:53:37Z",
      "comments": 3,
      "url": "https://github.com/bitcoin/bitcoin/pull/33064",
      "labels": [
        "Tests"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33064.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [cedwies](https://github.com/bitcoin/bitcoin/pull/33064#pullrequestreview-3059599768), [maflcko](https://github.com/bitcoin/bitcoin/pull/33064#issuecomment-3126161329) |\n\nIf your review is incorrectly listed, please react with üëé to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#31668](https://github.com/bitcoin/bitcoin/pull/31668) (Added rescan option for import descriptors by saikiran57)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T14:02:56Z"
        },
        {
          "user": "maflcko",
          "body": "lgtm ACK 8aed477c3322212a636ab69d4923f89e2d9a63a2",
          "created_at": "2025-07-28T08:41:09Z"
        },
        {
          "user": "fanquake",
          "body": "> Question: would it make sense to also test \"abortrescan\" during an active rescan to hit the True path and ensure the scan halts as expected?\r\n\r\nFeel free to open a new PR, adding additional test changes.",
          "created_at": "2025-07-28T09:40:15Z"
        }
      ]
    },
    {
      "number": 33063,
      "title": "util: Revert \"common: Close non-std fds before exec in RunCommandJSON\"",
      "body": "After a fork() in a multithreaded program, the child can safely\r\ncall only async-signal-safe functions (see [signal-safety(7)](https://www.man7.org/linux/man-pages/man7/signal-safety.7.html))\r\nuntil such time as it calls execv.\r\n\r\nThe standard library (`std` namespace) is not async-signal-safe. Also, `throw`, isn't.\r\n\r\nThere was an alternative implementation using `readdir` (https://github.com/bitcoin/bitcoin/pull/32529), but that isn't async-signal-safe either, and that implementation was still using `throw`.\r\n\r\nSo temporarily revert this feature.\r\n\r\nA follow-up in the future can add it back, using only async-signal-safe functions, or by using a different approach.\r\n\r\n\r\nFixes https://github.com/bitcoin/bitcoin/issues/32524\r\nFixes https://github.com/bitcoin/bitcoin/issues/33015\r\nFixes https://github.com/bitcoin/bitcoin/issues/32855\r\n\r\n\r\n\r\nFor reference, a failure can manifest in the GCC debug mode:\r\n\r\n* While `fork`ing, a debug mode mutex is held (by any other thread).\r\n* The `fork`ed child tries to use the stdard libary before `execv` and deadlocks.\r\n\r\nThis may look like the following:\r\n\r\n```\r\n(gdb) thread apply all bt \r\n\r\nThread 1 (Thread 0xf58f4b40 (LWP 774911) \"b-httpworker.2\"):\r\n#0  0xf7f4f589 in __kernel_vsyscall ()\r\n#1  0xf79e467e in ?? () from /lib32/libc.so.6\r\n#2  0xf79eb582 in pthread_mutex_lock () from /lib32/libc.so.6\r\n#3  0xf7d93bf2 in ?? () from /lib32/libstdc++.so.6\r\n#4  0xf7d93f36 in __gnu_debug::_Safe_iterator_base::_M_attach(__gnu_debug::_Safe_sequence_base*, bool) () from /lib32/libstdc++.so.6\r\n#5  0x5668810a in __gnu_debug::_Safe_iterator_base::_Safe_iterator_base (this=0xf58f13ac, __seq=0xf58f13f8, __constant=false) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_base.h:91\r\n#6  0x56ddfb50 in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::forward_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:162\r\n#7  0x56ddfacb in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::bidirectional_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:539\r\n#8  0x56ddfa5b in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::random_access_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:687\r\n#9  0x56ddd3f6 in std::__debug::vector<int, std::allocator<int> >::begin (this=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/vector:300\r\n#10 0x57d83701 in subprocess::detail::Child::execute_child (this=0xf58f156c) at ./util/subprocess.h:1372\r\n#11 0x57d80a7c in subprocess::Popen::execute_process (this=0xf58f1cd8) at ./util/subprocess.h:1231\r\n#12 0x57d6d2b4 in subprocess::Popen::Popen<subprocess::input, subprocess::output, subprocess::error, subprocess::close_fds> (this=0xf58f1cd8, cmd_args=\"fake.py enumerate\", args=..., args=..., args=..., args=...) at ./util/subprocess.h:964\r\n#13 0x57d6b597 in RunCommandParseJSON (str_command=\"fake.py enumerate\", str_std_in=\"\") at ./common/run_command.cpp:27\r\n#14 0x57a90547 in ExternalSigner::Enumerate (command=\"fake.py\", signers=std::__debug::vector of length 0, capacity 0, chain=\"regtest\") at ./external_signer.cpp:28\r\n#15 0x56defdab in enumeratesigners()::$_0::operator()(RPCHelpMan const&, JSONRPCRequest const&) const (this=0xf58f2ba0, self=..., request=...) at ./rpc/external_signer.cpp:51\r\n...\r\n(truncated, only one thread exists)\r\n```",
      "state": "closed",
      "user": "maflcko",
      "created_at": "2025-07-25T13:42:07Z",
      "updated_at": "2025-10-23T13:18:58Z",
      "comments": 10,
      "url": "https://github.com/bitcoin/bitcoin/pull/33063",
      "labels": [
        "Utils/log/libs"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33063.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [darosior](https://github.com/bitcoin/bitcoin/pull/33063#pullrequestreview-3055837132), [fanquake](https://github.com/bitcoin/bitcoin/pull/33063#issuecomment-3121554126) |\n| Concept ACK | [Sjors](https://github.com/bitcoin/bitcoin/pull/33063#issuecomment-3118320711), [naiyoma](https://github.com/bitcoin/bitcoin/pull/33063#pullrequestreview-3057157243) |\n\nIf your review is incorrectly listed, please react with üëé to this comment and the bot will ignore it on the next update.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#32577](https://github.com/bitcoin/bitcoin/pull/32577) (subprocess: Let shell parse command on non-Windows systems by hebasto)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T13:42:13Z"
        },
        {
          "user": "fanquake",
          "body": "ACK - to stop the flow of CI failures.\r\n\r\ncc @hebasto @laanwj.",
          "created_at": "2025-07-25T13:49:44Z"
        },
        {
          "user": "Sjors",
          "body": "> call only async-signal-safe functions\r\n\r\nIs this related? https://github.com/arun11299/cpp-subprocess/issues/53",
          "created_at": "2025-07-25T14:30:56Z"
        },
        {
          "user": "maflcko",
          "body": "> Is this related? [arun11299/cpp-subprocess#53](https://github.com/arun11299/cpp-subprocess/issues/53)\r\n\r\nYes. My recommendation would be to fix this upstream. I currently don't plan to do it, so anyone else is free to pick it up.",
          "created_at": "2025-07-25T14:39:13Z"
        },
        {
          "user": "Sjors",
          "body": "Concept ACK\r\n\r\nI agree it makes sense to fix upstream first.\r\n\r\nHow do you verify a reverted merge commit? I guess this worked:\r\n\r\n```sh\r\ngit checkout maflcko/2507-tempoary-revert\r\ngit cherry-pick 4f5e04da135080291853f71e6f81dd0302224c3a^..a0eed55398f882d9390e50582b10272d18f2b836\r\ngit diff maflcko/2507-tempoary-revert~1\r\n```\r\n\r\nSo do I understand correctly from the man page you linked to that `close()` and `getpid` and are already signal safe, and it's just `throw` and `sysconf` that are the problem?\r\n\r\n",
          "created_at": "2025-07-25T14:54:12Z"
        },
        {
          "user": "maflcko",
          "body": "> it's just `throw` and `sysconf` that are the problem?\r\n\r\nNo, all of the C++ standard libary is problematic as well. (See the pull description and the bt)\r\n\r\n\r\n\r\n> How do you verify a reverted merge commit? I guess this worked:\r\n\r\nI typed `git revert -m1 31d3eebfb92ae0521e18225d69be95e78fb02672`, but `git` is very flexible and you can type many different things to arrive at the same result.",
          "created_at": "2025-07-25T14:59:38Z"
        },
        {
          "user": "darosior",
          "body": "Concept ACK...",
          "created_at": "2025-07-25T15:01:51Z"
        },
        {
          "user": "fanquake",
          "body": "ACK faa1c3e80d95552bdc2c0e717065ebf8d510138f",
          "created_at": "2025-07-26T09:17:28Z"
        },
        {
          "user": "laanwj",
          "body": "Posthumous ACK\r\n\r\n> After a fork() in a multithreaded program, the child can safely\r\n> call only async-signal-safe functions (see [signal-safety(7)](https://www.man7.org/linux/man-pages/man7/signal-\r\n> safety.7.html))\r\n> until such time as it calls execv.\r\n\r\nTIL\r\n",
          "created_at": "2025-10-22T15:06:49Z"
        },
        {
          "user": "laanwj",
          "body": "Note that strictly, the current (inefficient loop) subprocess implementation of fd closing in upstream isn't async signal safe as it calls `sysconf(_SC_OPEN_MAX)` in the child process ( https://github.com/arun11299/cpp-subprocess/blob/master/cpp-subprocess/subprocess.hpp#L1941 ).\r\n\r\nSadly:\r\n\r\n> POSIX.1-2001  and POSIX.1-2001 TC2 required the functions fpathconf(3), pathconf(3), and sysconf(3) to be async-signal-safe, but this requirement was removed in POSIX.1-2008.\r\n\r\nIt also throws in case `sysconf` fails, which is even worse. As the maximum fd limit value is inherited to subprocesses, it would be valid to move the call to `sysconf` to before the `fork()` to fix this.\r\n\r\n---\r\n\r\nThis may be interesting to port over: https://docs.rs/close_fds/latest/close_fds/#async-signal-safety-in-this-crate\r\n(implementation is here: https://docs.rs/close_fds/latest/src/close_fds/closefds/close.rs.html)\r\n\r\nIt is a rust implementation of \"close all FDs\" which is claimed to be efficient on all common platforms, as well as async signal safe. It implements this in terms of direct kernel calls, which are (when used carefully enough) async signal safe.\r\n\r\n",
          "created_at": "2025-10-23T13:18:58Z"
        }
      ]
    },
    {
      "number": 33062,
      "title": "truc: optimize the in package relation calculation",
      "body": "In PackageTRUCChecks(), we calculate the in-package-parents for an in package tx, which results in the total time complexisity being O(n^2), n is the number of Txs in the package. Let's precompute the overall relationships between all transactions to make it be O(n).",
      "state": "closed",
      "user": "HowHsu",
      "created_at": "2025-07-25T11:47:14Z",
      "updated_at": "2025-10-15T17:46:34Z",
      "comments": 3,
      "url": "https://github.com/bitcoin/bitcoin/pull/33062",
      "labels": [
        "Refactoring"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33062.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\nA summary of reviews will appear here.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#33629](https://github.com/bitcoin/bitcoin/pull/33629) (Cluster mempool by sdaftuar)\n* [#33591](https://github.com/bitcoin/bitcoin/pull/33591) (Cluster mempool followups by sdaftuar)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T11:47:18Z"
        },
        {
          "user": "HowHsu",
          "body": "> My understanding is that this isn't a bottleneck, optimizing it without a benchmark or an easily reproducible usecase seems like it's a solution begging for a problem - I speak from personal experience, that's how I started as well :)\r\n> \r\n> I left a few comments while reviewing anyway, but without a concept ack on the idea itself from those who are more familiar with it, it likely won't get merged.\r\n\r\nThanks, l0rinc. I'll leave this patch alone for now.",
          "created_at": "2025-08-05T05:15:44Z"
        },
        {
          "user": "glozow",
          "body": "There's not much activity on this PR and this refactors code that will be refactored again in #33629. I think it's best to close this. Please leave a comment if you think this is a mistake.",
          "created_at": "2025-10-15T17:07:47Z"
        }
      ]
    },
    {
      "number": 33061,
      "title": "subprocess: always check result of close()",
      "body": "Suggested in https://github.com/bitcoin/bitcoin/issues/32524#issuecomment-3071393448\r\n\r\nNeeds upstream PR before merging here: https://github.com/arun11299/cpp-subprocess",
      "state": "closed",
      "user": "Sjors",
      "created_at": "2025-07-25T08:20:05Z",
      "updated_at": "2025-07-25T14:57:05Z",
      "comments": 10,
      "url": "https://github.com/bitcoin/bitcoin/pull/33061",
      "labels": [
        "CI failed"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33061.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\nA summary of reviews will appear here.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-07-25T08:20:09Z"
        },
        {
          "user": "Sjors",
          "body": "I suppose we should catch `OSError` and not crash if this ever happens...",
          "created_at": "2025-07-25T08:23:07Z"
        },
        {
          "user": "DrahtBot",
          "body": "<!--85328a0da195eb286784d51f73fa0af9-->\nüöß At least one of the CI tasks failed.\n<sub>Task `CentOS, depends, gui`: https://github.com/bitcoin/bitcoin/runs/46711064321</sub>\n<sub>LLM reason (‚ú® experimental): Linker error due to multiple definitions of subprocess functions in util/subprocess.h, causing build failure.</sub>\n\n<details><summary>Hints</summary>\n\nTry to run the tests locally, according to the documentation. However, a CI failure may still\nhappen due to a number of reasons, for example:\n\n* Possibly due to a silent merge conflict (the changes in this pull request being\nincompatible with the current code in the target branch). If so, make sure to rebase on the latest\ncommit of the target branch.\n\n* A sanitizer issue, which can only be found by compiling with the sanitizer and running the\n  affected test.\n\n* An intermittent issue.\n\nLeave a comment here, if you need help tracking down a confusing failure.\n\n</details>\n\n",
          "created_at": "2025-07-25T08:30:10Z"
        },
        {
          "user": "fanquake",
          "body": "Have you also sent this change upstream? https://github.com/arun11299/cpp-subprocess",
          "created_at": "2025-07-25T08:32:33Z"
        },
        {
          "user": "fanquake",
          "body": "cc @hebasto ",
          "created_at": "2025-07-25T08:33:35Z"
        },
        {
          "user": "Sjors",
          "body": "> This \"fix\" is just introducing other bugs down the line, no?\r\n\r\nThat's possible, though in general it seems not ignoring errors is a good thing.\r\n\r\n> Have you also sent this change upstream? https://github.com/arun11299/cpp-subprocess\r\n\r\nNot yet, will do depending on feedback here. Marking as draft.\r\n",
          "created_at": "2025-07-25T08:34:15Z"
        },
        {
          "user": "maflcko",
          "body": "> I suppose we should catch `OSError` and not crash if this ever happens...\r\n\r\nThe rpc doesn't crash on exceptions, no?\r\n\r\n\r\n\r\n> That's possible, though in general it seems not ignoring errors is a good thing.\r\n\r\nYes, but it depends on the context. As mentioned above, most of the places intentionally and correctly ignore the errors, as I understand it? Blindly throwing exceptions without looking at the context doesn't seem the right approach to me.",
          "created_at": "2025-07-25T08:49:33Z"
        },
        {
          "user": "Sjors",
          "body": "Having gone through the code a bit more, it seems that throwing `OSError` is problematic for at least a few reasons:\r\n\r\n1. It can obfuscate other errors, since `close` is often called as part of error handling\r\n2. It makes errors out of things that are almost never an actual problem\r\n3. If we upstream the change, it's a breaking change, requiring callers to catch and handle `OSError` in more scenarios\r\n\r\nA better approach is probably to log (a narrow subset of) `close()` failures. There's no logging functionality at all upstream, so that would be just for us. I don't know if we want to have Bitcoin Core specific code at all in this `subprocess.h`?\r\n\r\nIf we go that route, I could at least upstream the first commit since it gives us access to the return value.",
          "created_at": "2025-07-25T09:28:20Z"
        },
        {
          "user": "maflcko",
          "body": "Also, it would be good to have evidence that the underlying bug is related to the close at all.\r\n\r\nEven with code added to throw on a failed close, the error keeps happening for me:\r\n\r\n\r\ndiff:\r\n\r\n\r\n```diff\r\ndiff --git a/ci/test/00_setup_env_i686_multiprocess.sh b/ci/test/00_setup_env_i686_multiprocess.sh\r\nindex e19a45d..4a7c3ea 100755\r\n--- a/ci/test/00_setup_env_i686_multiprocess.sh\r\n+++ b/ci/test/00_setup_env_i686_multiprocess.sh\r\n@@ -16,6 +16,8 @@ export GOAL=\"install\"\r\n export TEST_RUNNER_EXTRA=\"--v2transport --usecli\"\r\n export BITCOIN_CONFIG=\"\\\r\n  -DCMAKE_BUILD_TYPE=Debug \\\r\n+ -DCMAKE_C_FLAGS_DEBUG='-g2 -O0' \\\r\n+ -DCMAKE_CXX_FLAGS_DEBUG='-g2 -O0' \\\r\n  -DCMAKE_C_COMPILER='clang;-m32' \\\r\n  -DCMAKE_CXX_COMPILER='clang++;-m32' \\\r\n  -DAPPEND_CPPFLAGS='-DBOOST_MULTI_INDEX_ENABLE_SAFE_MODE' \\\r\ndiff --git a/ci/test/03_test_script.sh b/ci/test/03_test_script.sh\r\nindex b136762..a601e77 100755\r\n--- a/ci/test/03_test_script.sh\r\n+++ b/ci/test/03_test_script.sh\r\n@@ -122,7 +122,7 @@ if [[ \"${RUN_TIDY}\" == \"true\" ]]; then\r\n   BITCOIN_CONFIG_ALL=\"$BITCOIN_CONFIG_ALL -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\"\r\n fi\r\n \r\n-bash -c \"cmake -S $BASE_ROOT_DIR -B ${BASE_BUILD_DIR} $BITCOIN_CONFIG_ALL $BITCOIN_CONFIG || ( (cat $(cmake -P \"${BASE_ROOT_DIR}/ci/test/GetCMakeLogFiles.cmake\")) && false)\"\r\n+bash -c \"cmake --fresh -S $BASE_ROOT_DIR -B ${BASE_BUILD_DIR} $BITCOIN_CONFIG_ALL $BITCOIN_CONFIG || ( (cat $(cmake -P \"${BASE_ROOT_DIR}/ci/test/GetCMakeLogFiles.cmake\")) && false)\"\r\n \r\n # shellcheck disable=SC2086\r\n cmake --build \"${BASE_BUILD_DIR}\" \"$MAKEJOBS\" --target all $GOAL || (\r\ndiff --git a/src/util/subprocess.h b/src/util/subprocess.h\r\nindex ff812d7..d0ab14e 100644\r\n--- a/src/util/subprocess.h\r\n+++ b/src/util/subprocess.h\r\n@@ -1232,7 +1232,17 @@ inline void Popen::execute_process() noexcept(false)\r\n   }\r\n   else\r\n   {\r\n-    subprocess_close(err_wr_pipe);// close child side of pipe, else get stuck in read below\r\n+    //subprocess_close(err_wr_pipe);// close child side of pipe, else get stuck in read below\r\n+        if (subprocess_close(err_wr_pipe) == -1) {\r\n+        // Based on the close(2) man page, retrying is not safe, especially\r\n+        // on Linux, as the file descriptor is released even when an error is\r\n+        // returned. The error indicates a problem (e.g., I/O error), but\r\n+        // the descriptor is gone. The primary risk of a hanging read() is averted.\r\n+        // We should treat this as a fatal error for the operation.\r\n+        //subprocess_close(err_rd_pipe); // Best-effort cleanup of the read end.\r\n+        //stream_.close_child_fds();\r\n+        throw OSError(\"failed to close child error pipe writer\", errno);\r\n+    }\r\n \r\n     stream_.close_child_fds();\r\n \r\n```\r\n\r\n(inside the ci):\r\n\r\n`while ( date && /ci_container_base/ci/scratch/build-i686-pc-linux-gnu/test/functional/test_runner.py --ci -j12 --tmpdirprefix /ci_container_base/ci/scratch/test_runner/ --ansi --combinedlogslen=99999999 --timeout-factor=40 --v2transport --usecli --quiet --failfast rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer  rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer   rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer rpc_signer )   ; do true ; done`\r\n\r\n(then wait a few hours)\r\n\r\nBt parent:\r\n\r\n```\r\nThread 33 (Thread 0xf58f4b40 (LWP 773609) \"b-httpworker.2\"):\r\n#0  0xf7f4f589 in __kernel_vsyscall ()\r\n#1  0xf7a6fac7 in read () from /lib32/libc.so.6\r\n#2  0x57d6c736 in subprocess::util::read_atmost_n (fp=0x592995e0, buf=0xf58f15fc \"\", read_upto=1024) at ./util/subprocess.h:437\r\n#3  0x57d80dde in subprocess::Popen::execute_process (this=0xf58f1cd8) at ./util/subprocess.h:1257\r\n#4  0x57d6d2b4 in subprocess::Popen::Popen<subprocess::input, subprocess::output, subprocess::error, subprocess::close_fds> (this=0xf58f1cd8, cmd_args=\"fake.py enumerate\", args=..., args=..., args=..., args=...) at ./util/subprocess.h:964\r\n#5  0x57d6b597 in RunCommandParseJSON (str_command=\"fake.py enumerate\", str_std_in=\"\") at ./common/run_command.cpp:27\r\n#6  0x57a90547 in ExternalSigner::Enumerate (command=\"fake.py\", signers=std::__debug::vector of length 0, capacity 0, chain=\"regtest\") at ./external_signer.cpp:28\r\n#7  0x56defdab in enumeratesigners()::$_0::operator()(RPCHelpMan const&, JSONRPCRequest const&) const (this=0xf58f2ba0, self=..., request=...) at ./rpc/external_signer.cpp:51\r\n```\r\n\r\nBt child:\r\n\r\n```\r\n(gdb) thread apply all bt \r\n\r\nThread 1 (Thread 0xf58f4b40 (LWP 774911) \"b-httpworker.2\"):\r\n#0  0xf7f4f589 in __kernel_vsyscall ()\r\n#1  0xf79e467e in ?? () from /lib32/libc.so.6\r\n#2  0xf79eb582 in pthread_mutex_lock () from /lib32/libc.so.6\r\n#3  0xf7d93bf2 in ?? () from /lib32/libstdc++.so.6\r\n#4  0xf7d93f36 in __gnu_debug::_Safe_iterator_base::_M_attach(__gnu_debug::_Safe_sequence_base*, bool) () from /lib32/libstdc++.so.6\r\n#5  0x5668810a in __gnu_debug::_Safe_iterator_base::_Safe_iterator_base (this=0xf58f13ac, __seq=0xf58f13f8, __constant=false) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_base.h:91\r\n#6  0x56ddfb50 in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::forward_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:162\r\n#7  0x56ddfacb in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::bidirectional_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:539\r\n#8  0x56ddfa5b in __gnu_debug::_Safe_iterator<__gnu_cxx::__normal_iterator<int*, std::__cxx1998::vector<int, std::allocator<int> > >, std::__debug::vector<int, std::allocator<int> >, std::random_access_iterator_tag>::_Safe_iterator (this=0xf58f13a8, __i=3, __seq=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/safe_iterator.h:687\r\n#9  0x56ddd3f6 in std::__debug::vector<int, std::allocator<int> >::begin (this=0xf58f13f8) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/debug/vector:300\r\n#10 0x57d83701 in subprocess::detail::Child::execute_child (this=0xf58f156c) at ./util/subprocess.h:1372\r\n#11 0x57d80a7c in subprocess::Popen::execute_process (this=0xf58f1cd8) at ./util/subprocess.h:1231\r\n#12 0x57d6d2b4 in subprocess::Popen::Popen<subprocess::input, subprocess::output, subprocess::error, subprocess::close_fds> (this=0xf58f1cd8, cmd_args=\"fake.py enumerate\", args=..., args=..., args=..., args=...) at ./util/subprocess.h:964\r\n#13 0x57d6b597 in RunCommandParseJSON (str_command=\"fake.py enumerate\", str_std_in=\"\") at ./common/run_command.cpp:27\r\n#14 0x57a90547 in ExternalSigner::Enumerate (command=\"fake.py\", signers=std::__debug::vector of length 0, capacity 0, chain=\"regtest\") at ./external_signer.cpp:28\r\n#15 0x56defdab in enumeratesigners()::$_0::operator()(RPCHelpMan const&, JSONRPCRequest const&) const (this=0xf58f2ba0, self=..., request=...) at ./rpc/external_signer.cpp:51\r\n#16 0x56def98d in std::__invoke_impl<UniValue, enumeratesigners()::$_0&, RPCHelpMan const&, JSONRPCRequest const&>(std::__invoke_other, enumeratesigners()::$_0&, RPCHelpMan const&, JSONRPCRequest const&) (__f=..., __args=..., __args=...) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:61\r\n#17 0x56def8ad in std::__invoke_r<UniValue, enumeratesigners()::$_0&, RPCHelpMan const&, JSONRPCRequest const&>(enumeratesigners()::$_0&, RPCHelpMan const&, JSONRPCRequest const&) (__fn=..., __args=..., __args=...) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:114\r\n#18 0x56def703 in std::_Function_handler<UniValue (RPCHelpMan const&, JSONRPCRequest const&), enumeratesigners()::$_0>::_M_invoke(std::_Any_data const&, RPCHelpMan const&, JSONRPCRequest const&) (__functor=..., __args=..., __args=...) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:290\r\n#19 0x57b8665c in std::function<UniValue (RPCHelpMan const&, JSONRPCRequest const&)>::operator()(RPCHelpMan const&, JSONRPCRequest const&) const (this=0xf58f2ba0, __args=..., __args=...) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:591\r\n#20 0x57b787f3 in RPCHelpMan::HandleRequest (this=0xf58f2b88, request=...) at ./rpc/util.cpp:663\r\n#21 0x56da2c29 in CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}::operator()(JSONRPCRequest const&, UniValue&, bool) const (this=0x58b10ce8 <RegisterSignerRPCCommands(CRPCTable&)::commands+48>, request=..., result=...) at ./rpc/server.h:60\r\n#22 0x56da2b75 in std::__invoke_impl<bool, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool>(std::__invoke_other, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool&&) (__f=..., __args=@0xf58f2d37: true, __args=@0xf58f2d37: true, __args=@0xf58f2d37: true) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:61\r\n#23 0x56da2a8f in std::__invoke_r<bool, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool>(CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool&&) (__fn=..., __args=@0xf58f2d37: true, __args=@0xf58f2d37: true, __args=@0xf58f2d37: true) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:114\r\n#24 0x56da28cd in std::_Function_handler<bool (JSONRPCRequest const&, UniValue&, bool), CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}>::_M_invoke(std::_Any_data const&, JSONRPCRequest const&, UniValue&, bool&&) (__functor=..., __args=@0xf58f2d37: true, __args=@0xf58f2d37: true, __args=@0xf58f2d37: true) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:290\r\n#25 0x56b3e86f in std::function<bool (JSONRPCRequest const&, UniValue&, bool)>::operator()(JSONRPCRequest const&, UniValue&, bool) const (this=0x58b10ce8 <RegisterSignerRPCCommands(CRPCTable&)::commands+48>, __args=true, __args=true, __args=true) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:591\r\n#26 0x56fdd861 in ExecuteCommand (command=..., request=..., result=..., last_handler=true) at ./rpc/server.cpp:506\r\n#27 0x56fd9e05 in ExecuteCommands (commands=std::__debug::vector of length 1, capacity 1 = {...}, request=..., result=...) at ./rpc/server.cpp:471\r\n#28 0x56fd9afd in CRPCTable::execute (this=0x58b12bd4 <tableRPC>, request=...) at ./rpc/server.cpp:491\r\n#29 0x56fd91c3 in JSONRPCExec (jreq=..., catch_errors=true) at ./rpc/server.cpp:347\r\n#30 0x572b255a in HTTPReq_JSONRPC (context=std::any containing node::NodeContext * = {...}, req=0x59277460) at ./httprpc.cpp:165\r\n#31 0x572b17ea in StartHTTPRPC(std::any const&)::$_0::operator()(HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const (this=0x5927c870, req=0x59277460) at ./httprpc.cpp:337\r\n#32 0x572b1783 in std::__invoke_impl<bool, StartHTTPRPC(std::any const&)::$_0&, HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>(std::__invoke_other, StartHTTPRPC(std::any const&)::$_0&, HTTPRequest*&&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (__f=..., __args=\"\", __args=\"\") at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:61\r\n#33 0x572b16b1 in std::__invoke_r<bool, StartHTTPRPC(std::any const&)::$_0&, HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>(StartHTTPRPC(std::any const&)::$_0&, HTTPRequest*&&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (__fn=..., __args=\"\", __args=\"\") at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:114\r\n--Type <RET> for more, q to quit, c to continue without paging--c\r\n#34 0x572b13d3 in std::_Function_handler<bool (HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), StartHTTPRPC(std::any const&)::$_0>::_M_invoke(std::_Any_data const&, HTTPRequest*&&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (__functor=..., __args=\"\", __args=\"\") at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:290\r\n#35 0x572e016c in std::function<bool (HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>::operator()(HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const (this=0x592916d0, __args=\"\", __args=\"\") at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_function.h:591\r\n#36 0x572dfeea in HTTPWorkItem::operator() (this=0x592916b0) at ./httpserver.cpp:62\r\n#37 0x572ea7f1 in WorkQueue<HTTPClosure>::Run (this=0x5902b720) at ./httpserver.cpp:117\r\n#38 0x572cac42 in HTTPWorkQueueRun (queue=0x5902b720, worker_num=2) at ./httpserver.cpp:419\r\n#39 0x572efc55 in std::__invoke_impl<void, void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> (__f=@0x5904efdc: 0x572cabc0 <HTTPWorkQueueRun(WorkQueue<HTTPClosure>*, int)>, __args=@0x5904efd4: 2, __args=@0x5904efd4: 2) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:61\r\n#40 0x572efac5 in std::__invoke<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> (__fn=@0x5904efdc: 0x572cabc0 <HTTPWorkQueueRun(WorkQueue<HTTPClosure>*, int)>, __args=@0x5904efd4: 2, __args=@0x5904efd4: 2) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/invoke.h:96\r\n#41 0x572efa54 in std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> >::_M_invoke<0u, 1u, 2u> (this=0x5904efd4) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_thread.h:292\r\n#42 0x572ef9b2 in std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> >::operator() (this=0x5904efd4) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_thread.h:299\r\n#43 0x572ef635 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> > >::_M_run (this=0x5904efd0) at /bin/../lib/gcc/x86_64-linux-gnu/13/../../../../include/c++/13/bits/std_thread.h:244\r\n#44 0xf7d9ad21 in ?? () from /lib32/libstdc++.so.6\r\n#45 0xf79e8137 in ?? () from /lib32/libc.so.6\r\n#46 0xf7a7cde8 in ?? () from /lib32/libc.so.6\r\n```\r\n\r\nSo it seems like this is a bug in our code (taking a lock before execv)",
          "created_at": "2025-07-25T12:24:40Z"
        },
        {
          "user": "Sjors",
          "body": "It appears that underlying issue is now understood to be signal safety, see #33063. So improving `close` error reporting and handling isn't a priority.",
          "created_at": "2025-07-25T14:57:05Z"
        }
      ]
    }
  ],
  "issues": [],
  "summary": {
    "pull_requests": 6,
    "issues": 0
  }
}