{
  "source": "github",
  "repository": "bitcoin/bitcoin",
  "fetched_at": "2026-01-15T20:24:00.408139+00:00",
  "date": "2025-10-17",
  "pull_requests": [
    {
      "number": 33646,
      "title": "log: check fclose() results and report safely in logging.cpp",
      "body": "`fclose()` can report write errors (for example if the disk is full or the filesystem has a problem). Right now, some `fclose()` calls in `src/logging.cpp` ignore the return value. This means errors might go unnoticed and log lines could be lost without warning.\r\n\r\n## What this PR does:\r\n- Add a small helper that prints `fclose()` errors to `stderr` (with path and errno).\r\n- In shutdown: close `m_fileout` safely and report errors.\r\n- In reopen: open the new file, swap it in, close the old one, and report errors if closing fails.\r\n- In shrink/rotate: check all `fclose(file)` calls and report failures.\r\n\r\nNo other behavior changes. Normal logging, rotation, and console output remain unchanged.",
      "state": "open",
      "user": "cedwies",
      "created_at": "2025-10-17T19:06:08Z",
      "updated_at": "2025-12-20T10:54:45Z",
      "comments": 1,
      "url": "https://github.com/bitcoin/bitcoin/pull/33646",
      "labels": [
        "Utils/log/libs"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33646.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\nA summary of reviews will appear here.\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#34038](https://github.com/bitcoin/bitcoin/pull/34038) (logging: API improvements by ajtowns)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-10-17T19:06:14Z"
        }
      ]
    },
    {
      "number": 33645,
      "title": "refactor: optimize: avoid allocations in script & policy verification",
      "body": "Currently, some policy and script related methods are inefficiently allocating/reallocating containers where it is completely unnecessary. \r\n\r\nThis PR aims at optimizing policy verifications by reducing redundant heap allocations without losing performance even in worst case scenarios, effectively reducing the overall memory footprint.",
      "state": "open",
      "user": "Raimo33",
      "created_at": "2025-10-17T18:43:21Z",
      "updated_at": "2025-11-30T15:56:36Z",
      "comments": 21,
      "url": "https://github.com/bitcoin/bitcoin/pull/33645",
      "labels": [
        "Refactoring"
      ]
    },
    {
      "number": 33644,
      "title": "fuzz: don't pass (maybe) nullptr to memcpy()",
      "body": "If `ConsumeBytes()` returns an empty vector, then its `data()` method may or may not return a null pointer [1]. Its `size()` method will return 0 and `memcpy(dst, maybenull, 0)` will be called from `FuzzedSock::Accept()`.\r\n\r\nGiven that the `len` argument is 0, `memcpy()` should not try to dereference the maybenull argument, but nevertheless the sanitizer is upset:\r\n\r\n```\r\n./src/test/fuzz/util/net.cpp:337:43: runtime error: null pointer passed\r\nas argument 2, which is declared to never be null\r\n```\r\n\r\nFix this by avoiding the call to `memcpy()` if an empty vector is returned. The full target buffer is zeroed upfront.\r\n\r\n[1] https://en.cppreference.com/w/cpp/container/vector/data\r\n\r\nResolves: https://github.com/bitcoin/bitcoin/issues/33643\r\n\r\n<!--\r\n*** Please remove the following help text before submitting: ***\r\n\r\nPull requests without a rationale and clear improvement may be closed\r\nimmediately.\r\n\r\nGUI-related pull requests should be opened against\r\nhttps://github.com/bitcoin-core/gui\r\nfirst. See CONTRIBUTING.md\r\n-->\r\n\r\n<!--\r\nPlease provide clear motivation for your patch and explain how it improves\r\nBitcoin Core user experience or Bitcoin Core developer experience\r\nsignificantly:\r\n\r\n* Any test improvements or new tests that improve coverage are always welcome.\r\n* All other changes should have accompanying unit tests (see `src/test/`) or\r\n  functional tests (see `test/`). Contributors should note which tests cover\r\n  modified code. If no tests exist for a region of modified code, new tests\r\n  should accompany the change.\r\n* Bug fixes are most welcome when they come with steps to reproduce or an\r\n  explanation of the potential issue as well as reasoning for the way the bug\r\n  was fixed.\r\n* Features are welcome, but might be rejected due to design or scope issues.\r\n  If a feature is based on a lot of dependencies, contributors should first\r\n  consider building the system outside of Bitcoin Core, if possible.\r\n* Refactoring changes are only accepted if they are required for a feature or\r\n  bug fix or otherwise improve developer experience significantly. For example,\r\n  most \"code style\" refactoring changes require a thorough explanation why they\r\n  are useful, what downsides they have and why they *significantly* improve\r\n  developer experience or avoid serious programming bugs. Note that code style\r\n  is often a subjective matter. Unless they are explicitly mentioned to be\r\n  preferred in the [developer notes](/doc/developer-notes.md), stylistic code\r\n  changes are usually rejected.\r\n-->\r\n\r\n<!--\r\nBitcoin Core has a thorough review process and even the most trivial change\r\nneeds to pass a lot of eyes and requires non-zero or even substantial time\r\neffort to review. There is a huge lack of active reviewers on the project, so\r\npatches often sit for a long time.\r\n-->\r\n",
      "state": "closed",
      "user": "vasild",
      "created_at": "2025-10-17T10:25:53Z",
      "updated_at": "2025-10-30T10:11:28Z",
      "comments": 5,
      "url": "https://github.com/bitcoin/bitcoin/pull/33644",
      "labels": [
        "Tests"
      ],
      "comment_list": [
        {
          "user": "DrahtBot",
          "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--006a51241073e994b41acfe9ec718e94-->\n### Code Coverage & Benchmarks\nFor details see: https://corecheck.dev/bitcoin/bitcoin/pulls/33644.\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\nA summary of reviews will appear here.\n<!--5faf32d7da4f0f540f40219e4f7537a3-->",
          "created_at": "2025-10-17T10:25:59Z"
        },
        {
          "user": "maflcko",
          "body": "> Given that the `len` argument is 0, `memcpy()` should not try to dereference the maybenull argument\r\n\r\nThat is right and it was already fixed upstream, see also https://github.com/bitcoin/bitcoin/issues/32016#issuecomment-2759479042.\r\n\r\nHistorically this was a GCC bug, but I was using clang, so I wonder why this somehow changed in the wrong direction. I'll try to take a closer look next week.",
          "created_at": "2025-10-17T11:20:15Z"
        },
        {
          "user": "vasild",
          "body": "> Historically this was a GCC bug, but I was using clang, so I wonder why this somehow changed in the wrong direction.\r\n\r\nI think this is not so much about the compiler but about the nonnull attribute found in `/usr/include/string.h`, which is used by both gcc and clang:\r\n\r\n```\r\n/* Copy N bytes of SRC to DEST.  */\r\nextern void *memcpy (void *__restrict __dest, const void *__restrict __src,\r\n                     size_t __n) __THROW __nonnull ((1, 2));\r\n```\r\nFreeBSD does not have such a nonnull attribute, so this could explain why I did not reproduce it on FreeBSD.\r\n\r\nLoong time ago I had a very frustrating and unproductive bug-chase in another project. It boiled down to this nonnull attribute. It turned out that the compiler, seeing the nonnull attribute, removed (optimized away) parts of the function body that contained `if (arg == nullptr) { handle and return from the function; }` because it assumed that the argument will never be null.",
          "created_at": "2025-10-17T12:08:00Z"
        },
        {
          "user": "purpleKarrot",
          "body": "> Given that the len argument is 0, memcpy() should not try to dereference the maybenull argument\r\n\r\nAccording to the C standard (ยง7.26.1), the behaviour of `memcpy`is undefined if either `src`or `dst`are null. So it is not a bug.",
          "created_at": "2025-10-18T06:39:03Z"
        },
        {
          "user": "maflcko",
          "body": "> > Given that the len argument is 0, memcpy() should not try to dereference the maybenull argument\r\n> \r\n> According to the C standard (ยง7.26.1), the behaviour of `memcpy`is undefined if either `src`or `dst`are null. So it is not a bug.\r\n\r\nApart from https://www.open-std.org/JTC1/SC22/WG14/www/docs/n3466.pdf , see also https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3322.pdf , which says:\r\n\r\n> Modify 7.26.1p3:\r\nWhere an argument declared as size_t n specifies the length of the array for a function, n can\r\nhave the value zero on a call to that function. Unless explicitly stated otherwise in the\r\ndescription of a particular function in this subclause, pointer arguments on such a call shall ... may be null pointers.",
          "created_at": "2025-10-22T07:49:54Z"
        }
      ]
    }
  ],
  "issues": [
    {
      "number": 33647,
      "title": "[`v30.0`] `createNewBlock` never returns",
      "body": "while connected to `testnet4` and letting the current implementation of SRI client connected for a while, `bitcoin-node` stops responding to IPC calls\n\nsteps to reproduce:\n- build `bitcoin-node` from `v30.0` tag\n- clone https://github.com/plebhash/sv2-bitcoin-core\n- check out `2025-10-17-hanging-ipc` branch\n- launch `bitcoin-node` with `-testnet4 -ipc-bind=unix -debug=ipc`\n- launch `sv2-bitcoin-core` with `RUST_LOG=debug cargo run --example logger \"/path/to/node.sock\"`\n- let it run for a while (for me it took ~25 minutes)\n\neventually, the logs on the rust client start to look like this:\n```\n2025-10-17T15:29:29.614817Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:29:29.614853Z DEBUG bitcoin_core_sv2: Received: CoinbaseOutputConstraints: CoinbaseOutputConstraints(coinbase_output_max_additional_size: 2, coinbase_output_max_additional_sigops: 2)\n2025-10-17T15:29:29.614934Z DEBUG bitcoin_core_sv2: monitor_incoming_messages() processing message\n2025-10-17T15:29:29.614973Z DEBUG bitcoin_core_sv2: Received CoinbaseOutputConstraints - max_additional_size: 2, max_additional_sigops: 2\n2025-10-17T15:29:29.615022Z DEBUG bitcoin_core_sv2: handle_coinbase_output_constraints() called\n2025-10-17T15:29:29.615058Z DEBUG bitcoin_core_sv2: Cancelling template_ipc_client_cancellation_token\n2025-10-17T15:29:29.615099Z DEBUG bitcoin_core_sv2: Creating new template IPC client with new constraints\n2025-10-17T15:29:29.615139Z DEBUG bitcoin_core_sv2: new_template_ipc_client() called - max_size: 2, max_sigops: 2\n2025-10-17T15:29:29.615219Z DEBUG bitcoin_core_sv2: Setting block_reserved_weight: 2000\n2025-10-17T15:29:29.615255Z DEBUG bitcoin_core_sv2: Sending createNewBlock request to Bitcoin Core\n2025-10-17T15:29:39.616976Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:29:49.619034Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:29:59.621747Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:30:09.624253Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:30:19.625848Z  INFO logger: Sent new CoinbaseOutputConstraints\n2025-10-17T15:30:29.627359Z  INFO logger: Sent new CoinbaseOutputConstraints\n```\n\nthis is a clear indication that `createNewBlock` IPC call got stuck and never returned\n\nthe rust client becomes unkillable via ctrl+c, since there's hanging futures inside... so the process must be killed with other methods\n\nif we restart the rust client, the normal bootstrapping process doesn't go through, which indicates that `bitcoin-node` is no longer able to respond to any IPC calls whatsoever\n\nadditionally, `bitcoin-node` also becomes unkillable via ctrl+c\n\n---\n\nhere's logs of `bitcoin-node` around the timestamp where `createNewBlock` IPC call got stuck:\n\n```\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server send response #347 BlockTemplate.waitNext$Results (result = <external capability>)\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server send response #349 BlockTemplate.waitNext$Results (result = <external capability>)\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server recv request  #350 BlockTemplate.getBlock$Params (context = (thread = <external capability>))\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server post request  #350 {bitcoin-node-58573/26538479 (from )}\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server recv request  #351 BlockTemplate.getBlock$Params (context = (thread = <external capability>))\n2025-10-17T15:29:24Z [ipc] {bitcoin-node-58573/b-capnp-loop-26537354} IPC server post request  #351 {bitcoin-node-58573/26538479 (from )}\n2025-10-17T15:42:11Z Saw new header hash=000000001fe51f6e5b13b64e87e1c66f475adc2b4fa97b0b39c7b9a20fe0ea0e height=106954 peer=5\n2025-10-17T15:42:11Z UpdateTip: new best=000000001fe51f6e5b13b64e87e1c66f475adc2b4fa97b0b39c7b9a20fe0ea0e height=106954 version=0x20000000 log2_work=74.802497 tx=12113955 date='2025-10-17T17:42:11Z' progress=1.000000 cache=0.3MiB(337txo)\n2025-10-17T15:42:11Z Saw new header hash=00000000e206db80ad182ffdabc05bf9f6a1e13bd62b5ec4a51750c42e456648 height=106954 peer=8\n2025-10-17T15:45:11Z New block-relay-only v2 peer connected: version: 70016, blocks=106954, peer=15\n2025-10-17T15:58:34Z New block-relay-only v2 peer connected: version: 70016, blocks=106954, peer=16\n2025-10-17T15:59:44Z New block-relay-only v2 peer connected: version: 70016, blocks=106954, peer=17\n2025-10-17T16:02:12Z Saw new cmpctblock header hash=000000009a3bbd6b55b974200199e2cb7272deb8c892d2ee7b4215ec9b1e0876 height=106955 peer=4\n2025-10-17T16:02:12Z UpdateTip: new best=000000009a3bbd6b55b974200199e2cb7272deb8c892d2ee7b4215ec9b1e0876 height=106955 version=0x20000000 log2_work=74.802497 tx=12113988 date='2025-10-17T18:02:12Z' progress=1.000000 cache=0.3MiB(342txo)\n2025-10-17T16:04:58Z Flushed fee estimates to fee_estimates.dat.\n2025-10-17T16:22:13Z Saw new header hash=0000000073d29bfc7123c09a0dda5e64bd3e58383d85621c64625fad817215fa height=106956 peer=5\n2025-10-17T16:22:13Z Saw new header hash=0000000001f79e1b92f6f254cc5a5ff72bb8ce76731c53d50c28176663949972 height=106956 peer=1\n2025-10-17T16:22:13Z UpdateTip: new best=0000000001f79e1b92f6f254cc5a5ff72bb8ce76731c53d50c28176663949972 height=106956 version=0x20000000 log2_work=74.802497 tx=12114006 date='2025-10-17T18:22:13Z' progress=1.000000 cache=0.3MiB(391txo)\n2025-10-17T16:22:13Z Saw new header hash=00000000a820139f0791d0a2994bec73a29cb8563c34f4a68b96d7fe31cac7ef height=106956 peer=10\n2025-10-17T16:35:29Z New block-relay-only v2 peer connected: version: 70016, blocks=106956, peer=19\n2025-10-17T16:36:29Z New block-relay-only v2 peer connected: version: 70016, blocks=106956, peer=20\n2025-10-17T16:39:45Z Saw new cmpctblock header hash=00000000000000015ef791c938c1399989dcc68ead8057c508e03e585d2110c0 height=106957 peer=4\n2025-10-17T16:39:45Z UpdateTip: new best=00000000000000015ef791c938c1399989dcc68ead8057c508e03e585d2110c0 height=106957 version=0x200f2000 log2_work=74.803065 tx=12114029 date='2025-10-17T16:42:09Z' progress=1.000000 cache=0.3MiB(429txo)\n```\n\ncc @ryanofsky ",
      "state": "closed",
      "user": "plebhash",
      "created_at": "2025-10-17T20:42:18Z",
      "updated_at": "2025-10-20T21:33:28Z",
      "comments": 4,
      "url": "https://github.com/bitcoin/bitcoin/issues/33647",
      "labels": [
        "interfaces"
      ],
      "comment_list": [
        {
          "user": "fanquake",
          "body": "cc @Sjors ",
          "created_at": "2025-10-18T09:59:24Z"
        },
        {
          "user": "Sjors",
          "body": "And it was not syncing new blocks during `createNewBlock()`? That's the only thing it's expect to wait for, but only once at startup:\n\n```h\n   /**\n     * Construct a new block template.\n     *\n     * During node initialization, this will wait until the tip is connected.\n     *\n     * @param[in] options options for creating the block\n     * @retval BlockTemplate a block template.\n     * @retval std::nullptr if the node is shut down.\n     */\n    virtual std::unique_ptr<BlockTemplate> createNewBlock(const node::BlockCreateOptions& options = {}) = 0;\n```\n\ncc @ryanofsky ",
          "created_at": "2025-10-18T10:41:07Z"
        },
        {
          "user": "ryanofsky",
          "body": "Thanks for the clear steps to reproduce. I was able to see the rust client make the bitcoin node IPC hang very quickly (after around a minute) following them.\n\nIt seems like rust client is able to trigger a deadlock bug that was fixed in https://github.com/bitcoin-core/libmultiprocess/pull/201, and was backported in https://github.com/bitcoin/bitcoin/pull/33519 in the [30.x](https://github.com/bitcoin/bitcoin/commits/30.x) branch that was made after the [v30.0](https://github.com/bitcoin/bitcoin/commits/v30.0) tag.\n\nIf you build with the [30.x](https://github.com/bitcoin/bitcoin/commits/30.x) branch instead of the [v30.0](https://github.com/bitcoin/bitcoin/commits/v30.0) tag, I think it should fix this issue.\n\nI debugged the hang attaching with gdb (`sudo gdb build/bin/bitcoin-node <bitcoin-node pid>`) and running `thread apply all bt`. \n\nThe stack trace is below and shows the event loop thread (Thread 13) stuck trying to post an incoming request to worker thread (Thread 5), waiting to acquire the worker thread's `Waiter::m_mutex` mutex. It also shows the worker thread holding on to `Waiter::m_mutex` trying to run code on the event loop to destroy a `ProxyClient<Thread>` object.\n\nSo it's just a deadlock with two threads stuck waiting for each other, and it's the same deadlock that was fixed in https://github.com/bitcoin-core/libmultiprocess/pull/201.\n\n<details><summary>stack trace</summary>\n<p>\n\n```\nThread 13 (Thread 0x7f67fe9fe6c0 (LWP 3342614) \"b-capnp-loop\"):\n#0  0x00007f67ff69762f in __lll_lock_wait () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#1  0x00007f67ff69e1a1 in pthread_mutex_lock@@GLIBC_2.2.5 () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#2  0x000055977887f71c in __gthread_mutex_lock (__mutex=0x7f6774000e60) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/x86_64-unknown-linux-gnu/bits/gthr-default.h:762\n#3  0x00005597788a7306 in std::mutex::lock (this=0x7f6774000e60) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_mutex.h:113\n#4  0x00005597788c6b99 in std::unique_lock<std::mutex>::lock (this=0x7f67fe9faeb8) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/unique_lock.h:147\n#5  0x000055977907d519 in std::unique_lock<std::mutex>::unique_lock (this=0x7f67fe9faeb8, __m=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/unique_lock.h:73\n#6  0x0000559779207982 in post<(lambda at ./ipc/libmultiprocess/include/mp/type-context.h:67:19)> (this=0x7f6774000e60, fn=...) at ./ipc/libmultiprocess/include/mp/proxy-io.h:288\n\n   285      template <typename Fn>\n   286      void post(Fn&& fn)\n   287      {\n>  288          const std::unique_lock<std::mutex> lock(m_mutex);\n   289          assert(!m_fn);\n   290          m_fn = std::forward<Fn>(fn);\n   291          m_cv.notify_all();\n   292      }\n\n#7  0x0000559779207790 in operator() (this=0x7f67f0017950, perhaps=...) at ./ipc/libmultiprocess/include/mp/type-context.h:145\n\n   136      return server.m_context.connection->m_threads.getLocalServer(thread_client)\n   137          .then([&server, invoke = kj::mv(invoke), req](const kj::Maybe<Thread::Server&>& perhaps) mutable {\n   138              // Assuming the thread object is found, pass it a pointer to the\n   139              // `invoke` lambda above which will invoke the function on that\n   140              // thread.\n   141              KJ_IF_MAYBE (thread_server, perhaps) {\n   142                  const auto& thread = static_cast<ProxyServer<Thread>&>(*thread_server);\n   143                  server.m_context.loop->log()\n   144                      << \"IPC server post request  #\" << req << \" {\" << thread.m_thread_context.thread_name << \"}\";\n>  145                  thread.m_thread_context.waiter->post(std::move(invoke));\n   146              } else {\n   147                  server.m_context.loop->log()\n   148                      << \"IPC server error request #\" << req << \", missing thread to execute request\";\n   149                  throw std::runtime_error(\"invalid thread handle\");\n   150              }\n   151          })\n   152          // Wait for the invocation to finish before returning to the caller.\n   153          .then([invoke_wait = kj::mv(future.promise)]() mutable { return kj::mv(invoke_wait); });\n\n\n#8  0x000055977920c29e in apply<(lambda at ./ipc/libmultiprocess/include/mp/type-context.h:137:15)> (func=..., in=...) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/async-prelude.h:179\n\n>  137          .then([&server, invoke = kj::mv(invoke), req](const kj::Maybe<Thread::Server&>& perhaps) mutable {\n\n#9  0x000055977920be8e in getImpl (this=0x7f67f0017930, output=...) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/async-inl.h:739\n#10 0x00007f67fff18b4d in kj::_::TransformPromiseNodeBase::get(kj::_::ExceptionOrValue&) () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#11 0x00007f67fff18f81 in kj::_::TransformPromiseNodeBase::getDepResult(kj::_::ExceptionOrValue&) () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#12 0x000055977920ce0e in getImpl (this=0x7f67f0017900, output=...) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/async-inl.h:733\n#13 0x00007f67fff18b4d in kj::_::TransformPromiseNodeBase::get(kj::_::ExceptionOrValue&) () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#14 0x00007f67fff1a249 in kj::_::ChainPromiseNode::fire() () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#15 0x00007f67fff1a9d2 in non-virtual thunk to kj::_::ChainPromiseNode::fire() () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#16 0x00007f67fff1de8c in kj::_::waitImpl(kj::Own<kj::_::PromiseNode, kj::_::PromiseDisposer>&&, kj::_::ExceptionOrValue&, kj::WaitScope&, kj::SourceLocation)::$_2::operator()() const () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#17 0x00007f67fff16dd8 in kj::_::waitImpl(kj::Own<kj::_::PromiseNode, kj::_::PromiseDisposer>&&, kj::_::ExceptionOrValue&, kj::WaitScope&, kj::SourceLocation) () from /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/lib/libkj-async.so.1.2.0\n#18 0x000055977963860c in kj::Promise<unsigned long>::wait (this=0x7f67fe9fd620, waitScope=..., location=...) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/async-inl.h:1357\n#19 0x0000559779632555 in mp::EventLoop::loop (this=0x55979fb711b8) at ./ipc/libmultiprocess/src/mp/proxy.cpp:231\n\n   230      for (;;) {\n>  231          const size_t read_bytes = wait_stream->read(&buffer, 0, 1).wait(m_io_context.waitScope);\n   232          if (read_bytes != 1) throw std::logic_error(\"EventLoop wait_stream closed unexpectedly\");\n\n#20 0x000055977906e799 in ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}::operator()() const (this=0x55979fb7cf98) at ./ipc/capnp/protocol.cpp:96\n\n    91          m_loop_thread = std::thread([&] {\n    92              util::ThreadRename(\"capnp-loop\");\n    93              m_loop.emplace(exe_name, &IpcLogFn, &m_context);\n    94              m_loop_ref.emplace(*m_loop);\n    95              promise.set_value();\n>   96              m_loop->loop();\n    97              m_loop.reset();\n    98          });\n\n#21 0x000055977906e672 in std::__invoke_impl<void, ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}>(std::__invoke_other, ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}&&) (__f=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:61\n#22 0x000055977906e5d2 in std::__invoke<ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}>(ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}&&) (__fn=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:96\n#23 0x000055977906e58a in std::thread::_Invoker<std::tuple<ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}> >::_M_invoke<0ul>(std::_Index_tuple<0ul>) (this=0x55979fb7cf98) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:301\n#24 0x000055977906e532 in std::thread::_Invoker<std::tuple<ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}> >::operator()() (this=0x55979fb7cf98) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:308\n#25 0x000055977906e3da in std::thread::_State_impl<std::thread::_Invoker<std::tuple<ipc::capnp::(anonymous namespace)::CapnpProtocol::startLoop(char const*)::{lambda()#1}> > >::_M_run() (this=0x55979fb7cf90) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:253\n#26 0x00007f67ffaed064 in execute_native_thread_routine () from /nix/store/41ym1jm1b7j3rhglk82gwg9jml26z1km-gcc-14.3.0-lib/lib/libstdc++.so.6\n#27 0x00007f67ff69a97a in start_thread () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#28 0x00007f67ff722d2c in __clone3 () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n\nThread 5 (Thread 0x7f677a7fc6c0 (LWP 3343266) \"b-capnp-loop\"):\n#0  0x00007f67ff697389 in __futex_abstimed_wait_common () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#1  0x00007f67ff699e1e in pthread_cond_wait@@GLIBC_2.3.2 () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#2  0x0000559779632ecb in std::condition_variable::wait<mp::EventLoop::post(kj::Function<void ()>)::$_2>(std::unique_lock<std::mutex>&, mp::EventLoop::post(kj::Function<void ()>)::$_2) (this=0x55979fb71230, __lock=..., __p=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/condition_variable:105\n#3  0x0000559779632cb7 in mp::EventLoop::post (this=0x55979fb711b8, fn=...) at ./ipc/libmultiprocess/src/mp/proxy.cpp:273\n\n   258  void EventLoop::post(kj::Function<void()> fn)\n   259  {\n   260      if (std::this_thread::get_id() == m_thread_id) {\n   261          fn();\n   262          return;\n   263      }\n   264      Lock lock(m_mutex);\n   265      EventLoopRef ref(*this, &lock);\n   266      m_cv.wait(lock.m_lock, [this]() MP_REQUIRES(m_mutex) { return m_post_fn == nullptr; });\n   267      m_post_fn = &fn;\n   268      int post_fd{m_post_fd};\n   269      Unlock(lock, [&] {\n   270          char buffer = 0;\n   271          KJ_SYSCALL(write(post_fd, &buffer, 1));\n   272      });\n>  273      m_cv.wait(lock.m_lock, [this, &fn]() MP_REQUIRES(m_mutex) { return m_post_fn != &fn; });\n   274  }\n\n#4  0x0000559779641ea7 in mp::EventLoop::sync<mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}::operator()() const::{lambda()#1}>(mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}::operator()() const::{lambda()#1}&&) (this=0x55979fb711b8, callable=...) at ./ipc/libmultiprocess/include/mp/proxy-io.h:192\n\n   186      //! Wrapper around EventLoop::post that takes advantage of the\n   187      //! fact that callable will not go out of scope to avoid requirement that it\n   188      //! be copyable.\n   189      template <typename Callable>\n   190      void sync(Callable&& callable)\n   191      {\n>  192          post(std::forward<Callable>(callable));\n   193      }\n\n#5  0x0000559779641df9 in mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}::operator()() const (this=0x7f675c004110) at ./ipc/libmultiprocess/include/mp/proxy-io.h:444\n\n   435      m_context.cleanup_fns.emplace_front([this, destroy_connection, disconnect_cb]{\n   436      {\n   437          // If the capnp interface defines a destroy method, call it to destroy\n   438          // the remote object, waiting for it to be deleted server side. If the\n   439          // capnp interface does not define a destroy method, this will just call\n   440          // an empty stub defined in the ProxyClientBase class and do nothing.\n   441          Sub::destroy(*this);\n   442\n   443          // FIXME: Could just invoke removed addCleanup fn here instead of duplicating code\n>  444          m_context.loop->sync([&]() {\n\n#6  0x0000559779641d66 in std::__invoke_impl<void, mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}&>(std::__invoke_other, mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}&) (__f=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:61\n#7  0x0000559779641cb6 in std::__invoke_r<void, mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}&>(mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}&) (__fn=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:111\n#8  0x0000559779641ade in std::_Function_handler<void (), mp::ProxyClientBase<mp::Thread, capnp::Void>::ProxyClientBase(mp::Thread::Client, mp::Connection*, bool)::{lambda()#2}>::_M_invoke(std::_Any_data const&) (__functor=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_function.h:290\n#9  0x0000559778b04a31 in std::function<void()>::operator() (this=0x7f677a7faec8) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_function.h:591\n#10 0x000055977907f2e9 in mp::CleanupRun (fns=empty std::__cxx11::list) at ./ipc/libmultiprocess/include/mp/proxy.h:43\n\n    39  inline void CleanupRun(CleanupList& fns) {\n    40      while (!fns.empty()) {\n    41          auto fn = std::move(fns.front());\n    42          fns.pop_front();\n>   43          fn();\n    44      }\n    45  }\n\n#11 0x0000559779638e3e in mp::ProxyClientBase<mp::Thread, capnp::Void>::~ProxyClientBase (this=0x7f6774000fb8) at ./ipc/libmultiprocess/include/mp/proxy-io.h:470\n\n   467  template <typename Interface, typename Impl>\n   468  ProxyClientBase<Interface, Impl>::~ProxyClientBase() noexcept\n   469  {\n>  470      CleanupRun(m_context.cleanup_fns);\n   471  }\n\n#12 0x00005597796335ba in mp::ProxyClient<mp::Thread>::~ProxyClient (this=0x7f6774000fb8) at ./ipc/libmultiprocess/src/mp/proxy.cpp:341\n\n   333  ProxyClient<Thread>::~ProxyClient()\n   334  {\n   335      // If thread is being destroyed before connection is destroyed, remove the\n   336      // cleanup callback that was registered to handle the connection being\n   337      // destroyed before the thread being destroyed.\n   338      if (m_disconnect_cb) {\n   339          m_context.connection->removeSyncCleanup(*m_disconnect_cb);\n   340      }\n>  341  }\n\n#13 0x00005597790dfd9a in std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >::~pair (this=0x7f6774000fb0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_iterator.h:3013\n#14 0x00005597790dfd46 in std::destroy_at<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > (__location=0x7f6774000fb0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_construct.h:88\n#15 0x00005597790dfbe6 in std::allocator_traits<std::allocator<std::_Rb_tree_node<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > > >::destroy<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > (__a=..., __p=0x7f6774000fb0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/alloc_traits.h:599\n#16 std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::_M_destroy_node (this=0x7f677a7fc5f8, __p=0x7f6774000f90) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:621\n#17 0x00005597790dfb52 in std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::_M_drop_node (this=0x7f677a7fc5f8, __p=0x7f6774000f90) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:629\n#18 0x00005597790dfaef in std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::_M_erase (this=0x7f677a7fc5f8, __x=0x7f6774000f90) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:1934\n#19 0x00005597790df956 in std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::clear (this=0x7f677a7fc5f8) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:1251\n#20 0x00005597790df13a in std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::_M_erase_aux (this=0x7f677a7fc5f8, __first={...}, __last={...}) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:2505\n#21 0x00005597790dee4a in std::_Rb_tree<mp::Connection*, std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> >, std::_Select1st<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > >, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::erase (this=0x7f677a7fc5f8, __x=@0x7f675c006e98: 0x7f67f0001dc0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_tree.h:2519\n#22 0x00005597790ded9e in std::map<mp::Connection*, mp::ProxyClient<mp::Thread>, std::less<mp::Connection*>, std::allocator<std::pair<mp::Connection* const, mp::ProxyClient<mp::Thread> > > >::erase (this=0x7f677a7fc5f8, __x=@0x7f675c006e98: 0x7f67f0001dc0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/stl_map.h:1118\n#23 0x0000559779209e1f in operator() (this=0x7f677a7fb248) at ./ipc/libmultiprocess/include/mp/type-context.h:103\n\n>  103                      KJ_DEFER(if (erase_thread) {\n   104                          std::unique_lock<std::mutex> lock(thread_context.waiter->m_mutex);\n   105                          // Call erase here with a Connection* argument instead\n   106                          // of an iterator argument, because the `request_thread`\n   107                          // iterator may be invalid if the connection is closed\n   108                          // during this function call. More specifically, the\n   109                          // iterator may be invalid because SetThread adds a\n   110                          // cleanup callback to the Connection destructor that\n   111                          // erases the thread from the map, and also because the\n   112                          // ProxyServer<Thread> destructor calls\n   113                          // request_threads.clear().\n   114                          request_threads.erase(server.m_context.connection);\n   115                      });\n   116                      fn.invoke(server_context, args...);\n   117                  }\n\n#24 0x0000559779209bad in run (this=0x7f677a7fb3b0) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/common.h:2010\n#25 0x000055977920865a in ~Deferred (this=0x7f677a7fb3b0) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/common.h:1999\n#26 0x0000559779208182 in operator() (this=0x7f6760001088) at ./ipc/libmultiprocess/include/mp/type-context.h:117\n\n   116                      fn.invoke(server_context, args...);\n>  117                  }\n\n#27 0x0000559779207f5a in operator() (this=0x7f6760001080) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/function.h:142\n#28 0x0000559779097881 in kj::Function<void()>::operator() (this=0x7f677a7fb878) at /nix/store/6inpywqa7f4njlq1i0bmkznxn5y5x69g-capnproto-1.2.0/include/kj/function.h:119\n#29 0x0000559779097567 in mp::Unlock<std::unique_lock<std::mutex>, kj::Function<void()>&> (lock=..., callback=...) at ./ipc/libmultiprocess/include/mp/util.h:198\n#30 0x00005597796367c6 in mp::Waiter::wait<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1}>(std::unique_lock<std::mutex>&, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1})::{lambda()#1}::operator()() const (this=0x7f677a7fb8e0) at ./ipc/libmultiprocess/include/mp/proxy-io.h:306\n\n   294      template <class Predicate>\n   295      void wait(std::unique_lock<std::mutex>& lock, Predicate pred)\n   296      {\n   297          m_cv.wait(lock, [&] {\n   298              // Important for this to be \"while (m_fn)\", not \"if (m_fn)\" to avoid\n   299              // a lost-wakeup bug. A new m_fn and m_cv notification might be sent\n   300              // after the fn() call and before the lock.lock() call in this loop\n   301              // in the case where a capnp response is sent and a brand new\n   302              // request is immediately received.\n   303              while (m_fn) {\n   304                  auto fn = std::move(*m_fn);\n   305                  m_fn.reset();\n>  306                  Unlock(lock, fn);\n   307              }\n   308              const bool done = pred();\n   309              return done;\n   310          });\n   311      }\n\n#31 0x0000559779636706 in std::condition_variable::wait<mp::Waiter::wait<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1}>(std::unique_lock<std::mutex>&, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1})::{lambda()#1}>(std::unique_lock<std::mutex>&, mp::Waiter::wait<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1}>(std::unique_lock<std::mutex>&, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1})::{lambda()#1}) (this=0x7f6774000e88, __lock=..., __p=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/condition_variable:104\n#32 0x0000559779636637 in mp::Waiter::wait<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1}>(std::unique_lock<std::mutex>&, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const::{lambda()#1}) (this=0x7f6774000e60, lock=..., pred=...) at ./ipc/libmultiprocess/include/mp/proxy-io.h:297\n#33 0x00005597796364e9 in mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0::operator()() const (this=0x7f67f00188c8) at ./ipc/libmultiprocess/src/mp/proxy.cpp:404\n#34 0x0000559779636332 in std::__invoke_impl<void, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0>(std::__invoke_other, mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0&&) (__f=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:61\n#35 0x0000559779636292 in std::__invoke<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0>(mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0&&) (__fn=...) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/invoke.h:96\n#36 0x000055977963624a in std::thread::_Invoker<std::tuple<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0> >::_M_invoke<0ul> (this=0x7f67f00188c8) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:301\n#37 0x00005597796361f2 in std::thread::_Invoker<std::tuple<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0> >::operator() (this=0x7f67f00188c8) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:308\n#38 0x0000559779635efa in std::thread::_State_impl<std::thread::_Invoker<std::tuple<mp::ProxyServer<mp::ThreadMap>::makeThread(capnp::CallContext<mp::ThreadMap::MakeThreadParams, mp::ThreadMap::MakeThreadResults>)::$_0> > >::_M_run (this=0x7f67f00188c0) at /nix/store/82kmz7r96navanrc2fgckh2bamiqrgsw-gcc-14.3.0/include/c++/14.3.0/bits/std_thread.h:253\n#39 0x00007f67ffaed064 in execute_native_thread_routine () from /nix/store/41ym1jm1b7j3rhglk82gwg9jml26z1km-gcc-14.3.0-lib/lib/libstdc++.so.6\n#40 0x00007f67ff69a97a in start_thread () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n#41 0x00007f67ff722d2c in __clone3 () from /nix/store/776irwlgfb65a782cxmyk61pck460fs9-glibc-2.40-66/lib/libc.so.6\n```\n\n</p>\n</details>\n",
          "created_at": "2025-10-18T13:39:55Z"
        },
        {
          "user": "plebhash",
          "body": "running against `30.x` branch made it go away, thanks!",
          "created_at": "2025-10-20T21:33:28Z"
        }
      ]
    },
    {
      "number": 33643,
      "title": "fuzz: connman fuzz target: runtime error: null pointer passed as argument 2, which is declared to never be null",
      "body": "```\r\n# echo 'XGFkZAAAAGRkZWXuXP/fcGcqb2hlcirYfg9D/uXc5eXcRZJ55eXl5eXl5eXlIiL19QAFABD3XERc\r\nAVxhYQcAAADl5f//5eVhYWHl5eX//+Xl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl\r\n5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eX/Km8xMTQyMjgxMUMKYWFhYWFhYQAAAAAA\r\nYWFhYWFhYWFhYWFhYWFhe2FhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFh8mWkovx0AAAA\r\nAAAAAGFhYWFhYWFhYWFhgKoL//v/Kv/////l5eXl5f//ZGRy5eX//2Ry5eX///9kZHLl5f//ZHLl\r\n5f//5eXl5eXl5eXl5Wfl//9kZHLl5f//ZHLl5f///2RkcuXl//9kcuXl//8=' | base64 --decode > ./crash_cm_1cfcffc33a\r\n\r\n# UBSAN_OPTIONS=\"suppressions=$(pwd)/test/sanitizer_suppressions/ubsan:print_stacktrace=1:halt_on_error=1:report_error_type=1\" FUZZ=connman ./bld/bin/fuzz -runs=1  ./crash_cm_1cfcffc33a \r\nINFO: Running with entropic power schedule (0xFF, 100).\r\nINFO: Seed: 2899209193\r\nINFO: Loaded 1 modules   (597578 inline 8-bit counters): 597578 [0x62ee33b00588, 0x62ee33b923d2), \r\nINFO: Loaded 1 PC tables (597578 PCs): 597578 [0x62ee33b923d8,0x62ee344b0878), \r\n./bld/bin/fuzz: Running 1 inputs 1 time(s) each.\r\nRunning: ./crash_cm_1cfcffc33a\r\n./src/test/fuzz/util/net.cpp:337:43: runtime error: null pointer passed as argument 2, which is declared to never be null\r\n```\r\n\r\n_Originally posted by @maflcko in https://github.com/bitcoin/bitcoin/pull/28584#discussion_r2438644126_\r\n            ",
      "state": "closed",
      "user": "maflcko",
      "created_at": "2025-10-17T07:19:08Z",
      "updated_at": "2025-10-31T10:02:53Z",
      "comments": 5,
      "url": "https://github.com/bitcoin/bitcoin/issues/33643",
      "labels": [
        "Tests",
        "Fuzzing"
      ],
      "comment_list": [
        {
          "user": "fanquake",
          "body": "cc @vasild ",
          "created_at": "2025-10-17T08:33:38Z"
        },
        {
          "user": "vasild",
          "body": "Couldn't reproduce, but is pretty obvious, _should_ be fixed by https://github.com/bitcoin/bitcoin/pull/33644\n\nDid I base64 decode wrongly in some way (I had to manually remove the newlines from the command above)?\n\n```\nSHA256 (crash_cm_1cfcffc33a) = 4ac50f0fa637d94fa48430e371f51ae97bb34fd99261a11e78daaa283f620a3b\n```",
          "created_at": "2025-10-17T10:28:36Z"
        },
        {
          "user": "maflcko",
          "body": "The sha256 looks right. Maybe the newlines are interacting somehow with your terminal or they are not stripped by your base64?\n\n```\n$ echo 'XGFkZAAAAGRkZWXuXP/fcGcqb2hlcirYfg9D/uXc5eXcRZJ55eXl5eXl5eXlIiL19QAFABD3XERc\nAVxhYQcAAADl5f//5eVhYWHl5eX//+Xl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl\n5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eXl5eX/Km8xMTQyMjgxMUMKYWFhYWFhYQAAAAAA\nYWFhYWFhYWFhYWFhYWFhe2FhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFh8mWkovx0AAAA\nAAAAAGFhYWFhYWFhYWFhgKoL//v/Kv/////l5eXl5f//ZGRy5eX//2Ry5eX///9kZHLl5f//ZHLl\n5f//5eXl5eXl5eXl5Wfl//9kZHLl5f//ZHLl5f///2RkcuXl//9kcuXl//8=' | base64 --decode | sha256sum \n4ac50f0fa637d94fa48430e371f51ae97bb34fd99261a11e78daaa283f620a3b  -\n",
          "created_at": "2025-10-17T11:24:45Z"
        },
        {
          "user": "vasild",
          "body": "If the checksum of the binary, base64 decoded, stuff is the same then I must have done it properly... or at least in the same way as you :)\n\nA possible explanation why this might only be observed in some platforms: https://github.com/bitcoin/bitcoin/pull/33644#issuecomment-3415282002",
          "created_at": "2025-10-17T12:11:59Z"
        },
        {
          "user": "maflcko",
          "body": "Just to copy the background details here, mentioned earlier:\n\nApart from https://www.open-std.org/JTC1/SC22/WG14/www/docs/n3466.pdf , see also https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3322.pdf , which says:\n\n> Modify 7.26.1p3:\nWhere an argument declared as size_t n specifies the length of the array for a function, n can\nhave the value zero on a call to that function. Unless explicitly stated otherwise in the\ndescription of a particular function in this subclause, pointer arguments on such a call shall ... may be null pointers.",
          "created_at": "2025-10-30T10:14:34Z"
        }
      ]
    }
  ],
  "summary": {
    "pull_requests": 3,
    "issues": 2
  }
}